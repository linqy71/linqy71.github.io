{"meta":{"title":"Qingyin Lin","subtitle":"","description":"SYSU Ph.D. student. <br> “吾生也有涯，而知也无涯”","author":"林清音","url":"https://linqy71.github.io","root":"/"},"pages":[{"title":"个人简介 Personal Resume","date":"2025-02-24T07:22:27.000Z","updated":"2025-02-25T05:56:54.146Z","comments":true,"path":"index.html","permalink":"https://linqy71.github.io/index.html","excerpt":"","text":"关于我 About me中山大学计算机科学与技术博士在读，导师为肖侬教授和陈志广教授。研究方向为大数据存储系统、机器学习训练/推理系统。 Hi, I am currently a Ph.D student in Computer Science, Sun Yat-sen University(National SuperComputer Center in Guangzhou), advised by Nong Xiao and Zhiguang Chen. My current research includes Storage System and ML Training/Inference System. 时间 Year 学校 University 阶段 Degree 专业 Major 2022 - Now 中山大学 SYSU 博士 Ph.D. 计算机科学与技术 Computer Science 2020 - 2022 中山大学 SYSU 硕士 M.S. 计算机技术 Computer Science 2016 - 2020 中山大学 SYSU 本科 B.S. 软件工程 Software Engineering 联系我 Emaillinqy35@mail2.sysu.edu.cn 成果 Publications [VLDB 2025] Qingyin Lin, Jiangsu Du，Rui Li, Zhiguang Chen, Wenguang Chen, and Nong Xiao, “IncrCP: Decomposing and Orchestrating Incremental Checkpoints for Effective Recommendation Model Training”. [大数据 2023] 林清音, 陈志广, “基于更新热点感知的 LSM-Tree 查询优化” [Electronics Letters 2020] Lingyu Zhu, Qingyin Lin, Fang Liu, “Energy analysis for internet of things software: A simulator approach” 兴趣爱好 Interests and Hobbies羽毛球 Badminton ; 书法 Calligraphy ; 滑雪 Snowboarding ; 音乐 Music ; 文学 Chinese Literature 博客记录 Posts分类 Categories"},{"title":"about","date":"2018-07-29T04:43:34.000Z","updated":"2025-02-24T12:08:16.437Z","comments":true,"path":"about/index.html","permalink":"https://linqy71.github.io/about/index.html","excerpt":"","text":"关于我 时间 学校 阶段 专业 2022 - ? 中山大学 博士 计算机科学与技术 2020 - 2022 中山大学 硕士 计算机技术 2016 - 2020 中山大学 本科 软件工程 研究方向：大数据存储系统 联系我linqy35@mail2.sysu.edu.cn"},{"title":"catalogue","date":"2018-07-29T04:43:23.000Z","updated":"2025-02-24T12:08:16.437Z","comments":true,"path":"catalogue/index.html","permalink":"https://linqy71.github.io/catalogue/index.html","excerpt":"","text":"这是目录"},{"title":"categories","date":"2018-07-29T01:30:45.000Z","updated":"2025-02-24T12:08:16.437Z","comments":true,"path":"categories/index.html","permalink":"https://linqy71.github.io/categories/index.html","excerpt":"","text":"UWP"}],"posts":[{"title":"个人简介 Personal Resume","slug":"personal-resume","date":"2025-02-24T07:22:27.000Z","updated":"2025-02-24T12:08:16.429Z","comments":true,"path":"2025/02/24/personal-resume/","link":"","permalink":"https://linqy71.github.io/2025/02/24/personal-resume/","excerpt":"","text":"关于我 About me中山大学计算机科学与技术博士在读，导师为肖侬教授和陈志广教授。研究方向为大数据存储系统、机器学习训练/推理系统。 Hi, I am currently a Ph.D student in Computer Science, Sun Yat-sen University((National SuperComputer Center in Guangzhou), advised by Nong Xiao and Zhiguang Chen. My current research includes Storage System and ML Training/Inference System. 时间 Time 学校 University 阶段 Degree 专业 Major 2022 - Now 中山大学 SYSU 博士 Ph.D. 计算机科学与技术 Computer Science 2020 - 2022 中山大学 SYSU 硕士 M.S. 计算机技术 Computer Science 2016 - 2020 中山大学 SYSU 本科 B.S. 软件工程 Software Engineering 联系我 Emaillinqy35@mail2.sysu.edu.cn 成果 Publications [VLDB 2025] Qingyin Lin, Jiangsu Du，Rui Li, Zhiguang Chen, Wenguang Chen, and Nong Xiao, “IncrCP: Decomposing and Orchestrating Incremental Checkpoints for Effective Recommendation Model Training”.","categories":[],"tags":[]},{"title":"安装python-rocksdb","slug":"install-python-rocksdb","date":"2023-10-12T05:48:39.000Z","updated":"2025-02-24T12:08:16.424Z","comments":true,"path":"2023/10/12/install-python-rocksdb/","link":"","permalink":"https://linqy71.github.io/2023/10/12/install-python-rocksdb/","excerpt":"","text":"安装rocksdb (twmht不需要这一步)1234567891011# latest version 8.6.7git clone https://github.com/facebook/rocksdb.gitcd rocksdbmkdir buildcd buildcmake ..make -jcd ..export CPLUS_INCLUDE_PATH=$&#123;CPLUS_INCLUDE_PATH&#125;$&#123;CPLUS_INCLUDE_PATH:+:&#125;`pwd`/include/export LD_LIBRARY_PATH=$&#123;LD_LIBRARY_PATH&#125;$&#123;LD_LIBRARY_PATH:+:&#125;`pwd`/build/export LIBRARY_PATH=$&#123;LIBRARY_PATH&#125;$&#123;LIBRARY_PATH:+:&#125;`pwd`/build/ 从源码安装python-rocksdb因为用pip install python-rocksdb一直失败，用源码安装成功 123git clone https://github.com/twmht/python-rocksdb.git --recursive -b pybind11cd python-rocksdbpython setup.py install 如果import出现报错1undefined symbol _ZN7rocksdb22GetLengthPrefixedSliceEPKc 原本使用gcc4.8.5，改为gcc7.5.0后就没问题了 faust-streaming-rocksdb 亲测不行。1pip install git+https://github.com/faust-streaming/python-rocksdb.git#egg=faust-streaming-rocksdb twmht python-rocksdb 文档 简单使用1234567891011121314151617181920212223import pyrocksdbdb = pyrocksdb.DB()opts = pyrocksdb.Options()# for multi-threadopts.IncreaseParallelism()opts.OptimizeLevelStyleCompaction()opts.create_if_missing = Trues = db.open(opts, &apos;/path/to/db&apos;)assert(s.ok())# putopts = pyrocksdb.WriteOptions()s = db.put(opts, b&quot;key1&quot;, b&quot;value1&quot;)assert (s.ok())# getopts = pyrocksdb.ReadOptions()blob = db.get(opts, b&quot;key1&quot;)print (blob.data) # b&quot;value1&quot;print (blob.status.ok()) # true#deleteopts = pyrocksdb.WriteOptions()s = db.delete(opts, b&quot;key1&quot;)assert(s.ok())db.close() 列族的使用12345678910111213141516171819202122232425262728293031323334353637import rocksdb# 打开或创建一个RocksDB数据库db_options = rocksdb.Options(create_if_missing=True)column_options = rocksdb.Options()# 创建一个RocksDB数据库，包含两个列族db = rocksdb.DB(&quot;mydb_with_column_families&quot;, db_options, column_families=[&quot;cf1&quot;, &quot;cf2&quot;])# 列族名称必须与上面的列表匹配cf1 = db.column_family_handles[&quot;cf1&quot;]cf2 = db.column_family_handles[&quot;cf2&quot;]# 写入数据到列族 cf1db.put(b&quot;key1&quot;, b&quot;value1&quot;, column_family=cf1)db.put(b&quot;key2&quot;, b&quot;value2&quot;, column_family=cf1)# 写入数据到列族 cf2db.put(b&quot;key1&quot;, b&quot;valueA&quot;, column_family=cf2)db.put(b&quot;key2&quot;, b&quot;valueB&quot;, column_family=cf2)# 从列族 cf1 读取数据value1_cf1 = db.get(b&quot;key1&quot;, column_family=cf1)value2_cf1 = db.get(b&quot;key2&quot;, column_family=cf1)# 从列族 cf2 读取数据value1_cf2 = db.get(b&quot;key1&quot;, column_family=cf2)value2_cf2 = db.get(b&quot;key2&quot;, column_family=cf2)print(&quot;cf1 key1:&quot;, value1_cf1.decode(&quot;utf-8&quot;))print(&quot;cf1 key2:&quot;, value2_cf1.decode(&quot;utf-8&quot;))print(&quot;cf2 key1:&quot;, value1_cf2.decode(&quot;utf-8&quot;))print(&quot;cf2 key2:&quot;, value2_cf2.decode(&quot;utf-8&quot;)# 关闭数据库db.close()","categories":[{"name":"coding","slug":"coding","permalink":"https://linqy71.github.io/categories/coding/"}],"tags":[{"name":"python; rocksdb;","slug":"python-rocksdb","permalink":"https://linqy71.github.io/tags/python-rocksdb/"}]},{"title":"EuroSys'22-Fleche：an efficient GPU embedding cache for personalized recommendations","slug":"FLECHE","date":"2023-07-25T11:02:59.000Z","updated":"2025-02-24T12:08:16.407Z","comments":true,"path":"2023/07/25/FLECHE/","link":"","permalink":"https://linqy71.github.io/2023/07/25/FLECHE/","excerpt":"","text":"一、背景 DLRM由 稀疏的嵌入层 和密集的全连接层 组成 由嵌入表的不规则访问和稀疏访问导致的CPU端的DRAM带宽稀缺已经成为DLRM的主要性能瓶颈 现有缓存方案（static per-table cache structure）没有很好地利用GPU端cache。该缓存方案为每个嵌入表维护一个固定大小的cache table，以防止表重新分区期间发生大量数据移动。 对NVIDIA HugeCTR-inference进行了测试，主要问题来源： 缓存利用率不足：static per-table structure带来的缺陷 内核维护开销：small cache-query内核过多，导致70%的缓存查询时间花费在kernel execution以外的任务上。 针对缓存利用率不足的问题：采用flat cache：与其对每个嵌入表的cache table进行分区，flat cache对所有嵌入表重新编码，使其能够共享一个全局缓存。 针对内核维护开销过大的问题：由于大多数的内核启动请求是针对同样的function，只是输入的参数不同，因此文章采用了self-identified kernel fusion：将小型内核调用合并为单一调用，并让内核中的每个线程识别它最初应该服务的内核调用。 这种方法大大减少了内核查询数，减轻了内核维护开销，同时保留了多缓存表查询的语义。 优化缓存查询流程： 将hit embedding与 indexing FC解耦 -&gt; 使得GPU-HBM与CPU DRAM可以高度并行。即：当发生miss时，可以直接从CPU DRAM加载embedding，无需等待 复制hit embedding的完成 采用统一索引技术，将CPU-DRAM层的部分索引卸载到GPU -&gt; 进一步减少了cache miss的开销，且能够利用GPU的涡轮增加提升查找性能。 二、DLRM详解 类别input(通常是ID list) 是one-hot 或者multi-hot的高维特征 嵌入表类似于哈希表，对于每个类别的特征维护一个嵌入表 嵌入表查询类似于哈希表查询，其中，key是input ID，value 是d-维 embedding vector 嵌入表查询完成之后，将得到的vector通过池化操作压缩成密集向量 最后所有池化向量与原始输入的密集向量一起输入MLP 存在的问题： 嵌入层的随机查找会导致大量的 cache miss 多个线程同时访问多个嵌入表会耗尽DRAM带宽 直观的解决方案： 将hot embedding缓存在GPU 三、现有缓存机制详解 CPU内存中保存的是embedding full table，GPU内存中保存的是cache table(比full table更小) 当查询缓存时，现有的机制会启动一个kernel（每个cache table对应1个kernel），kernel会先将所有cache hit的embedding加载到输出矩阵，然后kernel执行完毕，随后CPU从GPU那获得cache miss 的ID list，查询embedding table，再将所需要的embedding加载到输出矩阵。在这个过程中，n个kernel可以放到n个cudaStream中进行并发。 HugeCTR为每个embedding table静态设置了相同size的cache table。然而，由于热度不同，这种静态缓存只能缓存下每个embedding table内部的热点，而无法将全局的embedding 热点很好地缓存。 所谓内核维护时间，可以分为：CPU启动、上下文初始化、CPU同步、CPU-GPU通信。缓存表数量越多，启动kernel数越多，内核维护所需时间更长。 四、设计 4.1 flat cache cache table 结构 采用KV分离的形式，内存池存储来自不同缓存表的所有value，GPU侧的索引维护从flat key到内存池 location的映射。 最小化元数据信息：不存储size相关信息，因为key是id，value是embedding table，通过value也能知道size；存储了时间戳充当版本号，能够进行并发读写控制，不需要额外的元数据。 flat key格式 所有的cache table实际上公用一个全局cache 简单采用固定长度的table id与固定长度feature id拼接的形式，容易产生大量哈希冲突，因为key的数量不同。例如，city的数量很少但是user的数量很多，所以user表会有大量哈希冲突但是city表就很空 因此文章采用了size-aware encoding：将较短的id分配给较大的table。根据embedding table的大小，计算出可以容纳所有feature所需的bit之后，剩余的bit全部用来存储table id。 缓存替换和驱逐 基于概率的过滤策略：每个embedding有1/p的概率会放入cache，因此读取次数大于p的特征一定会放入缓存，这样就能够让缓存尽可能多地保存热数据。 缓存驱逐时尽可能驱逐cold embedding。epoch-based space reclamation：声明某个embedding被驱逐时并没有实际从cache中移除，而是等到所有线程都不需要读取这个embedding才真正回收空间。 4.2 self-identified kernel fusion 初始化阶段：CPU初始化1个数组用于存放原始n个kernel的参数，并计算一个scan数据，计算前i个kernel的线程数总和，然后启动1个kernel，这个kernel具有原本n个kernel线程数总和的线程。 识别阶段：在这个阶段，每个GPU线程需要确定原本n个内核的时候自己对应哪个位置，可以通过scan数组来确定。由于所有的线程共享scan和args数组，所以它们可以缓存在GPU的SM共享内存中，加速重复访问。 执行阶段：读取到参数之后就可以像原来那样执行查询了。由此，原来的多kernel启动减少到了单kernel启动。 4.3 优化cache查询流程 将copy和indexing解耦：当有2个wrap同时访问同一个KV对时，wrap1会将该表项上锁，进行index、从GPU全局内存copy，然后解锁，wrap2必须等待此过程。从全局内存copy是耗时的过程，将index与copy解耦之后，只需要启动1个额外的kernel去进行copy，此后1个kernel执行index，另一个kernel执行copy。而copy kenel无需担心线程安全问题，因为有epoch-based space reclamation。 绕过DRAM层索引：将DRAM层的索引信息加入统一索引层，在GPU就可以获取到DRAM location信息，GPU的查找速度也比CPU更快，但是这样会占用额外的GPU内存空间，本来可以用于缓存embedding，因此这两者之间需要权衡。 五、实现采用cudaMemcpy是很慢的，大概6-7 us。使用GDRCopy库，可以把HBM暴露给CPU，基于GPUDirect RDMA技术使用CPU驱动的拷贝方式，将small copy加速到0.1us 六、不足 只考虑单机情况，多机情况下DRAM也只是一个缓存层，因此指向DRAM的指针可能会失效 只考虑了单GPU情况。多GPU情况下缓存空间会更大，且模型并行消除了GPU之间的冗余。 注意：persistent kernel虽然可以通过轮询减少内核维护开销，但持久地占用了SM资源会导致后续的MLP层性能大幅降低。 注意：NLP和GNN中也有embedding table。NLP的嵌入表比较小，可以完全缓存在GPU中。GNN的嵌入表则与DLRM类似。 baseline ： HugeCTR from NVIDIA","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://linqy71.github.io/categories/论文阅读/"}],"tags":[{"name":"DLRM, HugeCTR, embedding cache","slug":"DLRM-HugeCTR-embedding-cache","permalink":"https://linqy71.github.io/tags/DLRM-HugeCTR-embedding-cache/"}]},{"title":"读《且介亭杂文》","slug":"且介亭杂文","date":"2023-05-24T07:28:38.000Z","updated":"2025-02-24T12:08:16.432Z","comments":true,"path":"2023/05/24/且介亭杂文/","link":"","permalink":"https://linqy71.github.io/2023/05/24/且介亭杂文/","excerpt":"","text":"《且介亭杂文》未完待续 读书人常常看轻别人，以为较新，较难的字句，自己能懂，大众却不能懂，所以为大众计，是必须彻底扫荡的，说话作文，越俗，就越好。这意见发展开来，他就要不自觉的成为新国粹派。或则希图大众语文在大众中推行得快，主张什么都要配大众的胃口，甚至于说要“迎合大众”，故意多骂几句，以搏大众的欢心。这当然自有他的苦心孤诣，但这样下去，可要成为大众的新帮闲的。（门外文谈） 我们从古以来，就有埋头苦干的人，有拼命硬干的人，有为民请命的人，有舍身求法的人……虽是等于为帝王将相作家谱的所谓“正史”，也往往掩不住他们的光耀，这就是中国的脊梁。要论中国人，必须不被搽在表面的自欺欺人的脂粉所诓骗，却看看他的筋骨和脊梁。自信力的有无，状元宰相的文章是不足为据的，要自己去看地底下。（中国人失掉自信力了吗） 群众，是英雄的大炮的食料，而英雄，从群众看来，不过是余兴。在其间，正义就占了胜利，而幕也垂下来了。（“以眼还眼”） 长谷川如是闲说“盗泉”云：“古之君子，恶其名而不饮，今之君子，改其名而饮之。”（说“面子”） 浊世少见“雅人”，少有“韵事”。但是，没有浊到彻底的时候，雅人却也并非全没有，不过因为“伤雅”的人们多，也累得他们“雅”不彻底了。（论俗人应避雅人） 隐士，历来算是一个美名，但有时也当作一个笑柄。最显著的，则有刺陈眉公的“翩然一只云中鹤，飞去飞来宰相衙”的诗，至今也还有人提及。我以为这是一种误解。因为一方面，是“自视太高”，于是别方面也就“求之太高”，彼此“忘其所以”，不能“心照”，而又不能“不宣”，从此口舌也多了起来。（隐士） 现在的报章不能像个报章，是真的；评论不能逞心而谈，失了威力，也是真的，明眼人绝不会过分的责备新闻记者。但是，新闻的威力其实是并未全盘坠地的，它对甲无损，对乙却会有伤；对强者它是弱者，但对更弱者它却还是强者，所以有时虽然吞声忍气，有时仍可以耀武扬威。（论“人言可畏”） 单就版画而论，使我们看起来，它不像法国木刻的多为纤美，也不像德国木刻的多为豪放；然而它真挚，却非固执，美丽，却非淫艳，愉快，却非狂欢，有力，却非粗暴；但又不是静止的，它令人觉得一种震动——这震动，恰如用坚实的步法，一步一步，踏着坚实的广大的黑土进向建设的路的大队友军的足音。（记苏联版画展览会）","categories":[{"name":"文学","slug":"文学","permalink":"https://linqy71.github.io/categories/文学/"}],"tags":[{"name":"鲁迅 且介亭杂文","slug":"鲁迅-且介亭杂文","permalink":"https://linqy71.github.io/tags/鲁迅-且介亭杂文/"}]},{"title":"k8s+openfaas运行自定义函数--tfserving prediction","slug":"deploy-openfaas-functions","date":"2023-05-23T06:59:12.000Z","updated":"2025-02-24T12:08:16.424Z","comments":true,"path":"2023/05/23/deploy-openfaas-functions/","link":"","permalink":"https://linqy71.github.io/2023/05/23/deploy-openfaas-functions/","excerpt":"","text":"基于k8s部署openfaas,并启动tensorflow-serving函数作为服务响应请求 部署k8s用kubeadm部署k8s并检测GPU 上一篇博客记录了部署过程，在其基础上进行下一步。 部署openfaas参考openfaas部署 12345678910111213141516171819202122#安装client$ curl -Lo faas-cli https://github.com/openfaas/faas-cli/releases/download/0.12.8/faas-cli \\ &amp;&amp; chmod +x faas-cli &amp;&amp; sudo mv faas-cli /usr/local/bin/#安装server$ cd faas-netes #进入faas-netes 仓库$ kubectl apply -f namespaces.yml #创建2个namespace$ kubectl -n openfaas create secret generic basic-auth \\ --from-literal=basic-auth-user=admin \\ --from-literal=basic-auth-password=&quot;admin&quot;$ kubectl apply -f ./yaml/#确认所有组件正常运行$ kubectl get pods -n openfaasNAME READY STATUS RESTARTS AGEalertmanager-67f5ff98d4-lpr5f 1/1 Running 0 2d21hgateway-6f47b5c9b4-5szwn 2/2 Running 1 (2d21h ago) 2d21hnats-85dc667985-drw9x 1/1 Running 0 2d21hprometheus-6b76879cd6-x5z7m 1/1 Running 0 2d21hqueue-worker-648c8c8c6f-vvj6x 1/1 Running 0 2d21h 成功运行后可继续参考openfaas部署写一个基础go函数或参考First Python Function写一个基础python函数 编写函数模板由于faas-cli提供的模板库有限，需要自行编写运行tfserving镜像的模板。 仿照python模板，创建tfserving模板文件夹 12345678910111213141516.├── template│ ├── python│ │ ├── Dockerfile│ │ ├── function│ │ ├── index.py│ │ ├── requirements.txt│ │ └── template.yml│ └── tfserving│ ├── Dockerfile│ ├── entrypoint.sh│ ├── function│ ├── index.py│ ├── requirements.txt│ ├── serving_models│ └── template.yml template/tfserving/Dockerfile内容如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273FROM --platform=$&#123;TARGETPLATFORM:-linux/amd64&#125; ghcr.io/openfaas/of-watchdog:0.9.10 as watchdogFROM --platform=$&#123;TARGETPLATFORM:-linux/amd64&#125; tensorflow/serving:latestCOPY --from=watchdog /fwatchdog /usr/bin/fwatchdogRUN chmod +x /usr/bin/fwatchdog###安装python3###RUN apt-get -qy updateRUN apt-get install -y libgl1-mesa-dev libglib2.0-dev wgetRUN yes | apt-get install python3 python3-pipRUN ln -s /usr/bin/python3 /usr/bin/python###安装python3#### Add non root userRUN addgroup --system app &amp;&amp; adduser app --system --ingroup appRUN chown app /home/appUSER appENV PATH=$PATH:/home/app/.local/binWORKDIR /home/app/COPY --chown=app:app index.py .COPY --chown=app:app requirements.txt .USER rootRUN pip3 install --upgrade pipRUN pip3 install --no-cache-dir -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/# Build the function directory and install any user-specified componentsUSER appRUN mkdir -p functionRUN touch ./function/__init__.pyUSER rootWORKDIR /home/app/function/COPY --chown=app:app function/requirements.txt .RUN pip3 install --no-cache-dir --verbose -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/#下载一张图片作为模型的inputRUN wget https://img-blog.csdnimg.cn/575dd33e3cc74ad7bd4ebed9d4f68362.png#pic_centerRUN mv *.png test.pngRUN cp ./test.png ../#install function codeUSER rootCOPY --chown=app:app function/ .ARG MODEL# FROM build as shipWORKDIR /home/app/###复制模型镜像###COPY ./serving_models/$MODEL /models/$MODELENV MODEL_NAME=$MODEL###复制模型镜像######复制entrypoint脚本，启动tfserving的关键###COPY ./entrypoint.sh ./entrypoint.shRUN chmod +x ./entrypoint.sh###复制entrypoint脚本####configure WSGI server and healthcheck# USER appENV fprocess=&quot;python index.py&quot;ENV cgi_headers=&quot;true&quot;ENV mode=&quot;http&quot;ENV upstream_url=&quot;http://127.0.0.1:5000&quot;ENTRYPOINT [&quot;./entrypoint.sh&quot;] entrypoint.sh内容如下： 12345#!/bin/bash#启动tensorflow-serving/usr/bin/tf_serving_entrypoint.sh &amp; fwatchdog 其中/usr/bin/tf_serving_entrypoint.sh脚本是拉取的tensorflow/serving:latest镜像自带的，具体内容为启动tensorflow_model_server监听：1tensorflow_model_server --port=8600 --rest_api_port=8601 --model_name=$&#123;MODEL_NAME&#125; --model_base_path=$&#123;MODEL_BASE_PATH&#125;/$&#123;MODEL_NAME&#125; &quot;$@&quot; requirements.txt 123flaskwaitresstox==3.* template.yml 12language: tfserving #定义language类型，用于创建函数fprocess: python3 index.py index.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344# Copyright (c) Alex Ellis 2017. All rights reserved.# Licensed under the MIT license. See LICENSE file in the project root for full license information.from flask import Flask, requestfrom function import handlerfrom waitress import serveimport osapp = Flask(__name__)# or set a default timeoutapp.config[&apos;TIMEOUT&apos;] = 60# distutils.util.strtobool() can throw an exceptiondef is_true(val): return len(val) &gt; 0 and val.lower() == &quot;true&quot; or val == &quot;1&quot;@app.before_requestdef fix_transfer_encoding(): &quot;&quot;&quot; Sets the &quot;wsgi.input_terminated&quot; environment flag, thus enabling Werkzeug to pass chunked requests as streams. The gunicorn server should set this, but it&apos;s not yet been implemented. &quot;&quot;&quot; transfer_encoding = request.headers.get(&quot;Transfer-Encoding&quot;, None) if transfer_encoding == u&quot;chunked&quot;: request.environ[&quot;wsgi.input_terminated&quot;] = True@app.route(&quot;/&quot;, defaults=&#123;&quot;path&quot;: &quot;&quot;&#125;, methods=[&quot;POST&quot;, &quot;GET&quot;])@app.route(&quot;/&lt;path:path&gt;&quot;, methods=[&quot;POST&quot;, &quot;GET&quot;])def main_route(path): raw_body = os.getenv(&quot;RAW_BODY&quot;, &quot;false&quot;) as_text = True if is_true(raw_body): as_text = False ret = handler.handle(request.get_data(as_text=as_text)) return retif __name__ == &apos;__main__&apos;: serve(app, host=&apos;0.0.0.0&apos;, port=5000) function文件夹下的内容与python模板中的function文件夹相同 serving_models文件夹用于存放后续tensorflow_model_server要运行的模型 根据模板创建函数并调用 创建新函数resnet152 1faas-cli new --lang tfserving resnet152 确保resnet152模型存放在serving_models文件夹中 1cp -r ./serving_models/resnet152 ./template/tfserving/serving_models/ 修改resnet152/handler.py 12345678910111213141516171819202122232425262728293031323334import timedef handle(req): \\&quot;\\&quot;\\&quot;handle a request to the function Args: req (str): request body \\&quot;\\&quot;\\&quot; err = \\&quot;$func_name: error nont found\\&quot; a = \\&quot;\\&quot; import os import cv2 import numpy as np import requests import json url = &apos;http://127.0.0.1:8501/v1/models/$model:predict&apos; image = cv2.imread(\\&quot;test.png\\&quot;) image = cv2.resize(image, (1024, 1024)) image = image.astype(np.uint8) / 255 image = np.uint8(image) image = image.tolist() headers = &#123;\\&quot;content-type\\&quot;: \\&quot;application/json\\&quot;&#125; body = &#123; \\&quot;signature_name\\&quot;: \\&quot;serving_default\\&quot;, \\&quot;inputs\\&quot;: [ image ] &#125; beginTime = time.perf_counter() r = requests.post(url, data = json.dumps(body), headers = headers) endTime = time.perf_counter() totalTime = (endTime-beginTime)*1000 req += \\&quot;耗时%f毫秒\\&quot;%totalTime+\\&quot;\\n\\&quot; print(req) return req 添加环境依赖 12echo &quot;opencv-pythonrequests&quot; &gt; ./resnet152/requirements.txt 修改yml文件 12345678910echo &quot;version: 1.0provider: name: openfaas gateway: http://127.0.0.1:31112functions: resnet152: lang: resnet152 handler: ./resnet152 image: username/resnet152:latest #此处username是Dockerhub用户名&quot; &gt; ./resnet152.yml build函数 1faas-cli build -f ./resnet152.yml --build-arg MODEL=resnet152 push镜像到dockerhub 12#确保docker login过了sudo docker push username/resnet152:latest 部署函数（这一步会从dockerhub拉取镜像） 1faas-cli deploy -f ./resnet152.yml 等待容器成功运行 1234kubectl get pods -n openfaas-fnNAME READY STATUS RESTARTS AGEresnet152-c6b687d55-hlkp2 1/1 Running 0 4h41m 调用函数 12faas-cli invoke resnet152 -g 127.0.0.1:31112 &lt; empty_input.txt #由于input使用的是提前下载好的图片，所以这里采用了empty input，直接执行模型推理 函数调用没有成功返回时，可以进入容器排查错误：1kubectl exec -it resnet152-c6b687d55-hlkp2 -n openfaas-fn /bin/bash","categories":[{"name":"coding","slug":"coding","permalink":"https://linqy71.github.io/categories/coding/"}],"tags":[{"name":"k8s openfaas tf-serving","slug":"k8s-openfaas-tf-serving","permalink":"https://linqy71.github.io/tags/k8s-openfaas-tf-serving/"}]},{"title":"用kubeadm部署k8s并检测GPU","slug":"deploy-k8s-with-kubeadm","date":"2023-03-25T17:30:14.000Z","updated":"2025-02-24T12:08:16.424Z","comments":true,"path":"2023/03/26/deploy-k8s-with-kubeadm/","link":"","permalink":"https://linqy71.github.io/2023/03/26/deploy-k8s-with-kubeadm/","excerpt":"","text":"尝试用minikube部署k8s的时候遇到一系列的问题，最终难以实现对GPU的检测,尝试分析问题，但由于minikube采用的是docker in docker的形式，所以较为复杂，改用kubeadm。minikube是单机的k8s集群，kubeadm则支持多机的k8s集群，且与minikube相比少了一层docker，尽管配置起来稍微麻烦一点，但是出了问题比较好排查。 此处应该是最齐全的教程，但是我部署到一半才发现这个教程。Install Kubernetes - NVIDIA Cloud Native Technologies documentation 以下简单记录部署过程系统：ubuntu16.04, 32CPU, 100GB memory, 2GPUNVIDIA-SMI 418.67, Driver Version: 418.67, CUDA Version: 10.1本文所有操作在root用户下执行最好保证内存足够大，之前采用39GB内存的系统配置起来问题一大堆 部署k8s 安装kubeadm 1234567891011121314151617181920212223mkdir /etc/apt/keyringssudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpgecho &quot;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main&quot; | sudo tee /etc/apt/sources.list.d/kubernetes.listsudo apt-get updatesudo apt-get install -y kubelet kubeadm kubectlsudo apt-mark hold kubelet kubeadm kubectl#install docker enginesudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ lsb-releasemkdir -m 0755 -p /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgecho \\ &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullapt-get updateapt-get install docker-ce docker version docker run hello-world#成功运行hello-world 安装containerdcontainerd安装官方教程 12345678910111213141516171819202122232425262728293031323334#从官网下载安装包tar Cxzvf /usr/local containerd-1.6.2-linux-amd64.tar.gzbin/bin/containerd-shim-runc-v2bin/containerd-shimbin/ctrbin/containerd-shim-runc-v1bin/containerdbin/containerd-stresssystemctl daemon-reloadsystemctl enable --now containerd#从官网下载runc.amd64,参照上述官方教程install -m 755 runc.amd64 /usr/local/sbin/runc#从官网下载cni安装包mkdir -p /opt/cni/bintar Cxzvf /opt/cni/bin cni-plugins-linux-amd64-v1.1.1.tgz././macvlan./static./vlan./portmap./host-local./vrf./bridge./tuning./firewall./host-device./sbr./loopback./dhcp./ptp./ipvlan./bandwidth 配容器运行时(containerd)容器运行时 官方教程 12345678910111213141516171819202122232425262728293031323334353637#转发ipv4让iptables看到桥接流量cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.confoverlaybr_netfilterEOFsudo modprobe overlaysudo modprobe br_netfilter# 设置所需的 sysctl 参数，参数在重新启动后保持不变cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1net.ipv4.ip_forward = 1EOF# 应用 sysctl 参数而不重新启动sudo sysctl --systemlsmod | grep br_netfilterlsmod | grep overlaysysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward#先执行这个命令把配置同步过来containerd config default &gt; /etc/containerd/config.toml#修改/etc/containerd/config.toml[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options] SystemdCgroup = true[plugins.&quot;io.containerd.grpc.v1.cri&quot;] sandbox_image = &quot;registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6&quot;#重启containerdsudo systemctl restart containerd#init成功，根据指引，因为是root用户，所以export KUBECONFIG=/etc/kubernetes/admin.conf 尝试启动kubeadm 12345kubeadm init --cri-socket=unix:///var/run/containerd/containerd.sock --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers#init成功，根据指引，因为是root用户，所以export KUBECONFIG=/etc/kubernetes/admin.conf#也可以把上面这个命令写入/etc/profile或~/.bashrc中，避免每次重开bash都要执行一次 安装calico（网络插件）安装calico官方教程 12345678910111213141516kubeadm reset kubeadm init --pod-network-cidr=192.168.0.0/16 --cri-socket=unix:///var/run/containerd/containerd.sock --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers#确保可用内存&gt;10Gkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/tigera-operator.yamlkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/custom-resources.yaml#这两个命令是解除k8s不允许运行其他容器的限制kubectl taint nodes --all node-role.kubernetes.io/control-plane-kubectl taint nodes --all node-role.kubernetes.io/master-#也可以：kubectl taint node NodeName node-role.kubernetes.io/control-plane=:NoSchedule-#查看节点状态：readykubectl get nodes#查看pods状态，全部running（需要等一会）kubectl get pods --all-namespaces 让k8s容器可以检测到GPU 确保GPU驱动已经正确安装，由于系统之前已经安装了所以我没有再安装 安装cuda toolkit10.0(因为是ubuntu16.04，所以选择安装了这个版本)下载链接 安装nvidia k8s plugin插件官方地址 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950distribution=$(. /etc/os-release;echo $ID$VERSION_ID)curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo apt-key add -curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | sudo tee /etc/apt/sources.list.d/libnvidia-container.listsudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkit#跳过教程里configure docker阶段，因为采用containerd作为运行时，所以直接configure containerd#修改/etc/containerd/config.tomlversion = 2[plugins] [plugins.&quot;io.containerd.grpc.v1.cri&quot;] [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd] default_runtime_name = &quot;nvidia&quot; [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes] [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia] privileged_without_host_devices = false runtime_engine = &quot;&quot; runtime_root = &quot;&quot; runtime_type = &quot;io.containerd.runc.v2&quot; [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.nvidia.options] BinaryName = &quot;/usr/bin/nvidia-container-runtime&quot;sudo systemctl restart containerdkubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.13.0/nvidia-device-plugin.ymlcat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Podmetadata: name: gpu-podspec: restartPolicy: Never containers: - name: cuda-container image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2 resources: limits: nvidia.com/gpu: 1 # requesting 1 GPU tolerations: - key: nvidia.com/gpu operator: Exists effect: NoScheduleEOFkubectl logs gpu-pod#成功检测到gpu了kubectl describe nodes 成功啦！","categories":[{"name":"coding","slug":"coding","permalink":"https://linqy71.github.io/categories/coding/"}],"tags":[{"name":"k8s kubernetes kubeadm gpu","slug":"k8s-kubernetes-kubeadm-gpu","permalink":"https://linqy71.github.io/tags/k8s-kubernetes-kubeadm-gpu/"}]},{"title":"rocksdb源码学习","slug":"rocksdb学习-1","date":"2021-03-18T02:48:58.000Z","updated":"2025-02-24T12:08:16.429Z","comments":true,"path":"2021/03/18/rocksdb学习-1/","link":"","permalink":"https://linqy71.github.io/2021/03/18/rocksdb学习-1/","excerpt":"","text":"rocksdb相对于leveldb的改进 性能上： 多线程compaction 多线程memtable写入 减少DB互斥锁持有 优化了基于level的compaction方式以及全局compaction方式 前缀布隆过滤器 memtable布隆过滤器 单个布隆过滤器覆盖整个sstable 写锁优化 提升了Iter::Prev()操作的性能 在进行跳表搜索时调用更少的比较器 使用huge page申请内存 用法特点上： 列族 column families 事务以及根据下标的批量写 备份以及检查点 Merge操作符 compaction过滤器 Rocksdb Java 持久化cache 在自动进行compaction的同时也可以执行手动compaction bulk loading 前向迭代器和尾部迭代器 single delete 范围删除文件 pin iterator key/value 数据结构和格式上： 在memory-only的场景下使用plain table memtable有基于向量和基于哈希两种格式 基于时钟的cache 可插入的information log 用blob注释事务日志写入（用于复制） 协调性上： 比例限制 （rate limiting） 可调整的减速和停止阈值 有参数可使所有文件保持open 有参数可保留index block 和 布隆过滤器block在block cache中 多种WAL恢复模式 Fadvise hints for readahead and to avoid caching in OS page cache（可协调预读、防止在OS页面缓存中缓存） 可以选择将L0文件的index和布隆过滤器块放在内存中 更多的压缩类型：zlib、lz4、zstd 压缩字典 校验和类型：xxhash 不同的层大小增大方式以及每层的压缩类型 管理能力上： statistics Thread-local profiling 命令行工具中的更多命令 用户定义的table properties 事件监听器 更多DB性质 动态参数调整 从string或map中获取参数 持久化参数到option files中。 来源: RocksDB Features that are not in LevelDB compaction操作对rocksdb性能的影响 单线程情况下：cpu执行compaction就无法处理读写请求。 多线程情况下：L0到L1的compaction操作无法与其它层的compaction操作并行 rocksdb的compaction策略（compaction主要是重新排序数据、清理过期数据和重复数据等） universal compaction(tired compaction的一种) 每一个run包含了一段时间内加入的数据 不同的run的时间段不会重叠 只对相邻时间段的run进行compaction 当run累积到一定的数量N时触发compaction leveled compaction","categories":[{"name":"源码阅读","slug":"源码阅读","permalink":"https://linqy71.github.io/categories/源码阅读/"}],"tags":[{"name":"rocksdb","slug":"rocksdb","permalink":"https://linqy71.github.io/tags/rocksdb/"}]},{"title":"面经总结","slug":"面经总结","date":"2021-03-03T08:36:34.000Z","updated":"2025-02-24T12:08:16.437Z","comments":true,"path":"2021/03/03/面经总结/","link":"","permalink":"https://linqy71.github.io/2021/03/03/面经总结/","excerpt":"","text":"字节跳动-C++后台开发一面 自我介绍 针对项目提问： rockdb原理，了解哪些 LSM Tree的适用于什么场景 解释了一下项目针对rocksdb做了什么研究 问了一下遇到的问题可能是由什么原因引起的 redis数据结构 redis中有序集合是用什么实现的，讲了跳表 跳表插入或查询的时间复杂度 redis为什么这么快 问了mysql内部实现原理 问关系型数据库与KV数据库各自的优缺点 开始问基本知识，操统和网络： TCP滑动窗口 TCP四次挥手中有一个timewait，什么时候会进入timewait 进程间通信 类的内存模型，new了一个对象后，内存空间是怎么样的 虚函数如何实现 虚函数表存放在哪里 1道编程题： 反转链表中从m到n的部分 阿里云块存储阿里云块存储一面 自我介绍 项目相关： 发现了什么问题？打算怎么解决？ 有没有关注过数据库其他方面导致的性能问题？ 为什么要选这个课题？ 使用什么工具？该工具其他功能？ CPU cache了解吗 说说缓存一致性 操作系统： 进程线程的区别 进程同步，方法及原理 线程同步 锁，及原理 如何用互斥锁实现读写锁 协程 线程切换开销，具体有哪些 C/C++: 关键字 static作用，static变量以及static函数的作用 虚函数，作用及原理 队列和栈，如何用队列实现栈 哈希和map 编程题： 一个有序数组从中间分成两段，将后一段移到数组前面，查找某数在数组中的位置。 腾讯TEG 云平台架构 介绍背景和项目 针对项目提问（34min） 基础知识： static C++比较新的特性用过吗 多态，虚函数实现原理 继承关系中的构造析构顺序 什么是IO多路复用 七层模型 算法题： 寻找普通二叉树中的两个节点的最近公共父节点。 腾讯TEG 云平台架构 一面 自我介绍 项目 自定义的一个类如果要在map里面使用需要实现什么函数 为什么不是operator&lt;= 头文件使用尖括号和双引号的区别 继承和模板有什么区别，分别适用于什么场景 内存泄漏，C++如何避免内存泄漏 RAII linux 网络抓包命令，查看所有tcp连接的命令 什么是堆，讲一下堆排序，总的时间复杂度，建堆的时间复杂度 快排的时间复杂度，最坏情况复杂度，如何优化最坏情况？（partition的时候有没有什么技巧） 插入排序的时间复杂度，在数组接近有序的时候的时间复杂度 B和B+树的区别 LSM树 send()函数返回成功了数据包一定被发送出去了吗 什么时候TIME_WAIT，有什么意义 哈希冲突，解决方法 缓存淘汰策略 redis持久化方式 rdb方式如何防止持久化过程阻塞掉网络请求 fork函数 编程： 实现一个存放自定义类Student的List 一个字符串数字，删除k个数字得到能表示的最小数字 腾讯TEG 云平台架构 二面 自我介绍 redis内存模型 如何存储key？ extern C static static成员函数可以通过对象访问吗 虚函数底层原理 构造析构虚函数 vector底层 扩容、缩容 map、unordered map linux 内核哪个版本 目录 用户目录 etc proc dev 三次握手 第三次ack丢失的时候客户端和服务器怎么处理 慢启动、拥塞避免 浏览器输入url get 和 post的区别 进程线程 进程间通信 协程 为什么切换开销比线程小？","categories":[{"name":"面经","slug":"面经","permalink":"https://linqy71.github.io/categories/面经/"}],"tags":[{"name":"字节跳动、阿里、腾讯","slug":"字节跳动、阿里、腾讯","permalink":"https://linqy71.github.io/tags/字节跳动、阿里、腾讯/"}]},{"title":"Lightweight and Accurate Memory Allocation in Key-Value Cache","slug":"paper-LAMA","date":"2021-02-25T12:16:57.000Z","updated":"2025-02-24T12:08:16.429Z","comments":true,"path":"2021/02/25/paper-LAMA/","link":"","permalink":"https://linqy71.github.io/2021/02/25/paper-LAMA/","excerpt":"","text":"Abstract 影响memcached性能的因素：memory allocation among different item classes. 本文提出了一种用于memcached的轻量的、准确的内存分配模式。 早期的内存分配优化工作：LAMA，使用了基于footprint的MRC（miss ratio curves），但没有考虑memcached的删除操作，且空间开销非常大。 相比于LAMA，本文提出的方法的空间开销为LAMA的3%，能够处理读、写、删除操作，且miss rate降低了15%、平均响应时间减少了12.3%。 Introduction memcached，最常用的分布式内存键值对缓存系统。 memcached中的items根据大小被分为不同的class，而内存分配不考虑数据的locality。 slab calcification: 当可用的slab被创建时，分配的空间无法再根据访问模式的改变而调整。 LAMA（locality-aware memory allocation） 为了保持数据一致，写操作直接更新后端数据库，并将对应的key从memcached中删除。（？） MRC construction aet: average eviction time Lightweight and Accurate Memory AllocationMemory Allocation Controller","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://linqy71.github.io/categories/论文阅读/"}],"tags":[{"name":"key-value cache, memcached","slug":"key-value-cache-memcached","permalink":"https://linqy71.github.io/tags/key-value-cache-memcached/"}]},{"title":"netbeans配置","slug":"netbeans配置","date":"2021-01-26T05:31:52.000Z","updated":"2025-02-24T12:08:16.424Z","comments":true,"path":"2021/01/26/netbeans配置/","link":"","permalink":"https://linqy71.github.io/2021/01/26/netbeans配置/","excerpt":"","text":"记录一下装完netbeans后所进行的一些配置 准备 JDK NetBeans8.2 安装NetBeans8.2。 C/C++插件本来安装了NetBeans12.0，在插件列表里找不到C/C++插件。于是改装NetBeans8.2就可以成功打开C/C++项目。 远程调试 工具 -&gt; 选项 -&gt; C/C++ -&gt; 编辑 -&gt; 添加 填写主机及端口","categories":[{"name":"coding","slug":"coding","permalink":"https://linqy71.github.io/categories/coding/"}],"tags":[{"name":"netbeans","slug":"netbeans","permalink":"https://linqy71.github.io/tags/netbeans/"}]},{"title":"AC-Key阅读笔记","slug":"AC-Key","date":"2020-12-22T03:28:40.000Z","updated":"2025-02-24T12:08:16.397Z","comments":true,"path":"2020/12/22/AC-Key/","link":"","permalink":"https://linqy71.github.io/2020/12/22/AC-Key/","excerpt":"","text":"AC-Key: Adaptive Caching for LSM-based Key-Value Stores USENIX ATC’20Fenggang Wu, Ming-Hong Yang, Baoquan Zhang, and David H.C. Du, University of Minnesotahttps://www.usenix.org/conference/atc20/presentation/wu-fenggang key word 使用cache来提升基于LSM Tree的KV store读性能 ARC算法 cache benefit and cache cost backgroundLSM Tree特点：写友好，读不友好 LSM Tree基本原理：总体来说，LSM Tree分为两部分，一部分存在于DRAM——MemTable，一部分存在于Storage——SST files。KV（Key-Value）对存储在一个一个的Data Block中。当DRAM中的MemTable满了之后，会通过flush操作将数据刷到Storage中。Storage中的SSTable以树状形式排列，flush操作会首先将数据刷到L0的一个SST中。当L0满后通过compaction操作将数据merge到L1中，以此类推。同时，每个SSTable中存放的不只是data block，还包括BF block——布隆过滤器，以及Index Block——当前SSTable 存放的Key的索引。以及Storage中的每一个level（除L0外）会有一个特殊的文件包含了该层所有SSTable存储的Key范围。 这就导致LSM Tree在查找数据时需要读出多个块，即经过多次storage I/O，才能查找出结果，开销较大。 ARC一种使用ghost cache动态调整cache大小的算法 ARC基本原理：首先，Cache中维护了4个LRU，2个以Frequency为策略, 2个以Recency为策略。图中的方框表示Real Cache，里面存放了真实的数据，横线表示Ghost cache，其size相对较小，存放的是从Real cache中被剔除的数据的元数据，例如page number等。当Recency侧的ghost cache命中时，该数据应被放回到Recency real cache中，因此Recency real cache的size需要增大，动态的boundary需要向Frequency侧移动；同理，当Frequency侧的ghost cache命中时boundary向Recency侧移动，从而达到cache size的动态自适应。 LSM – read基于LSM Tree的KV Store的读请求有两种类型： point lookup 点查找：单个KV对 range query 范围查找：范围内多个KV对 ChallengeCache item type 首先，Cache中可以存放的item类型有三种： block（basic I/O unit），例如data block，BF block，index block KV，即Key Value对 KP，即Key Pointer对，pointer为指向storage的指针，实际数据需要经过一次storage I/O才能获取。 这三种类型的cache有各自的特点： block能存放多个有序的KV对，非常适合范围查找。 KV cache存放了一个一个的KV对，不需要额外的I/O即可读出数据，适合点查找，但当Value的size较大时空间利用率较低，因此适用于value size较小的情况。 KP cache将Value转变为指针，尽管需要一次I/O，但cache的空间利用率大，适用于点查找中value size较大的情况。 同时，相比KP cache来说，KV cache应对热点问题更加有效。 目前存在的问题： 目前较为成熟的几个产品例如LevelDB, RocksDB, Cassandra，都只实现了三种cache类型中的一种或两种，不能够很好地兼容点查找和范围查找，并且无法动态调整大小。 因此，本文提出，Key Challenge is: adjust the size of different types of caches according to dynamic workloads cache efficiency另外，基于LSM Tree的特点，使用cache来提高读性能还需要考虑cache benefit与cache cost之间的平衡： cache benefit：一次cache hit所能节省的storage I/O Key存在的level越深，能够节省的storage I/O越多 cache cost：Cache entry占用的cache space Designcaching efficiency factor为了权衡cache benefit与cache cost，本文设计了一个caching efficiency factor： 定义为benefit与cost的比值，即 节省的I/O与所占的cache space之间的比值。 根据这个factor E，本文改进了： LRU → E-LRU: 选择最近最少使用的a个条目，从中剔除E值最小的条目 ARC → E-ARC：根据E来确定动态boundary移动的距离 Saved storage I/O–b b的计算方式： 对于block cache来说，因为一个block是最基本的I/O单元，因此若发现下一个要读取的block已经在cache中了，则该次I/O被节省，因此$b=1$ 对于KV cache来说，因为可以直接在cache中匹配所要查找的key，若命中了，则在storage中查找该key的所有I/O都可以被节省，此时b被定义为一个m相关的函数，m为查找该key要经过的SSTable的数量。 对于KP cache来说，cache命中时仍要比KV cache多一次I/O，因此可节省的I/O要比KV cache少1。 m的计算方式： 假设Storage中$L_0$的的SSTable数量为$n_0$，则： 当要查找的key存在于$L_0$时，需要一个一个遍历$L_0$中的SSTable直到找到key，因此平均下来$m=n_0/2$ 当要查找的key存在于其它level时，需要首先遍历$L_0$中的所有SSTable，即$n_0$次I/O，再往下查找每个level中存放有key范围的特殊文件，因此是$l$次I/O，所以$m=l+n_0$ $f(m)$ $f(m)$取决于KV store的实现，不过在通常情况下： $f(m) = m+2$ 因为查找一个KV对首先要读出m个BF block(布隆过滤器)来找到key所在的SSTable，再读出1个index block来找到key所在的data block，最后再将data block读出来找到对应的key value。 AC-Key Caching components 总体框架： AC Key将block、KV以及KP整合进cache中，并使用E-ARC算法动态调整大小。 Block cache 包含data block、 BF block以及index block KV cache and KP cache 若有新的key需要加入cache，则首先加入到KP cache中，此key被定义为warm key。 当KP cache中的key命中时，该key升级为hot key，经过1次storage I/O取出value后将KV对保存到KV cache中。 保存到KV cache中的hot key无法回退为warm key，因其pointer信息已经丢失。 Flush &amp; Compaction Handling由于LSM Tree的flush操作和compaction操作会影响到cache的有效性，所以还需要做相应的处理。（处理read请求时，KV store首先会在MemTable中查找，未查找到的才会在cache中查找） flush handling 在进行flush时，根据MemTable中的内容在KV cache和KP cache中匹配对应的key并更新。 由于flush时只会在storage中产生新的块，不会影响到旧的块，因此block cache无需更新。 compaction handling compaction会影响KP cache和block cache，但不会影响KV cache。 对于KP cache来说，只需要将对应的指针更新为compaction后的新地址。 对于block cache来说，需要移除失效的block，并以key范围与之有最大重叠的新block代替。 HAC: Hierarchical Adaptive Caching 分层的自适应cache总体架构： 上层分为point cache和block cache，对其应用E-ARC算法动态调整大小。 下层point cache内部分为KV cache和KP cache，对其应用E-ARC算法动态调整大小。 boundary移动规则： 当KV ghost cache或KP ghost cache命中时，都会导致point cache的size增大，而只有当增大的size达到了一个block的size时，point cache与block cache之间的boundary才会真正向block cache侧移动。 当block ghost cache命中时，会导致point cache的size减小，此时KV cache以及KP cache按照他们size的比例对应减小。 boundary移动距离： $d=kE=k{b/s}$ EvaluationAC Key的自适应过程展示 offline介绍： offline是指，在无法动态调整三种cache的size大小的情况下，手动设置KP cache所占比例以及block cache所占的比例进行测试，选择测试结果最优的配置作为最终的固定配置进行实验。 横坐标0-1为range query，可以看到此时全为block cache 横坐标1-3为point cache，block cache急剧减少至0，KV cache和KP cache不断上升并动态调整至平衡。 可以看到AC-Key与offline相比，读性能相近甚至更优。 性能对比 rocksdb相当于pure block varying cache size varying value size varying hot key ration and range query ratio 总结AC-Key是一种使用cache来提升基于LSM Tree的KV store读性能的设计，在cache中整合了block cache、KV cache以及KP cache来适应不同类型的读请求，并且运用了一种改进的ARC算法动态调整cache大小来提高cache的空间利用率。","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://linqy71.github.io/categories/论文阅读/"}],"tags":[{"name":"cache, LSM-Tree","slug":"cache-LSM-Tree","permalink":"https://linqy71.github.io/tags/cache-LSM-Tree/"}]},{"title":"读《华盖集》","slug":"luxun-huagaiji","date":"2020-11-25T07:49:42.000Z","updated":"2025-02-24T12:08:16.424Z","comments":true,"path":"2020/11/25/luxun-huagaiji/","link":"","permalink":"https://linqy71.github.io/2020/11/25/luxun-huagaiji/","excerpt":"","text":"读鲁迅《华盖集》以及《华盖集续编》 我以为如果艺术之宫里有这么麻烦的禁令，倒不如不进去；还是站在沙漠上，看看飞沙走石，乐则大笑，悲则大叫，愤则大骂，即使被沙砾打得遍身粗糙，头破血流，而时时抚摩自己的凝血，觉得若有花纹，也未必不及跟着中国的文士们去陪莎士比亚吃黄油面包之有趣。(华盖集-题记) 我看中国书时，总觉得就沉静下去，与实人生离开；读外国书——但除了印度——时，往往就与人生接触，想做点事。中国书虽有劝人入世的话，也多是僵尸的乐观；外国书虽然是颓唐和厌世的，但却是活人的颓唐和厌世。少看中国书，其结果不过不能作文而已。但现在的青年最要紧的是行，不是言。只要是活人，不能作文算什么大不了的事。(华盖集-青年必读书) 在这样”不留余地”空气的围绕里，人们的精神大抵要被挤小的。（华盖集-忽然想到） 历史上都写着中国的灵魂，指示着将来的命运，只因为涂饰太厚，废话太多，所以很不容易察出底细来。（华盖集-忽然想到） 伶俐人实在伶俐，所以，决不攻难古人，动摇古例的。古人做过的事，无论什么，今人也都会做出来。而辩护古人，也就是辩护自己。况且我们是神州华胄，敢不”绳其祖武”么？（华盖集-忽然想到） 讲话和写文章，似乎都是失败者的征象。正在和命运恶战的人，顾不到这些。（华盖集-通讯） 暴君的专制使人们变成冷嘲，愚民的专制使人们变成死相。（华盖集-忽然想到） 世上如果还有真要活下去的人们，就先该敢说，敢笑，敢哭，敢怒，敢骂，敢打，在这可诅咒的地方击退了可诅咒的时代！（华盖集-忽然想到） 正当苦痛，即说不出苦痛来，佛说极苦地狱中的鬼魂，也反而并无叫唤！（华盖集-“碰壁”之后） 我所憎恶的太多了，应该自己也得到憎恶，这才还有点像活在人间；如果收到的乃是相反的布施，于我倒是一个冷嘲，使我对于自己也要大加侮蔑；如果收到的是吞吞吐吐的不知道算什么，则使我感到将要呕哕似的恶心。然而无论如何，”流言”总不能吓哑我的嘴……。（华盖集-我的”籍”和”系”） 一国当衰弊之际，总有两种意见不同的人。一是民气论者，侧重国民的气概，一是民力论者，侧重国民的实力。前者多则国家终亦渐弱，后者多则将强。（华盖集-忽然想到） 我每看运动会时，常常这样想：优胜者固然可敬，但那虽然落后而仍非跑到终点不止的竞技者，和见了这样竞技者而肃然不笑的看客，乃正是中国将来的脊梁。（华盖集-这个与那个） 活在沙漠似的北京城里，枯燥当然是枯燥的，但偶然看看世态，除了百物昂贵之外，究竟还是五花八门，创造艺术的也有，制造流言的也有，肉麻的也有，有趣的也有…这大概就是北京之所以为北京的缘故，也就是人们总还要奔凑聚集的缘故。（华盖集续编-有趣的消息） 惟有民魂是值得宝贵的，惟有他发扬起来，中国才有真进步。（华盖集续编-学界的三魂） 真正的勇士，敢于直面惨淡的人生，敢于正视淋漓的鲜血。这是怎样的哀痛者和幸福者？然而造化又常常为庸人设计，以时间的流驶，来洗涤旧迹，仅使留下淡红的血色和微漠的悲哀。在这淡红的血色和微漠的悲哀中，又给人暂得偷生，维持着这似人非人的世界。我不知道这样的世界何时是一个尽头！（华盖集续编-纪念刘和珍君） 我向来是不惮以最坏的恶意，来推测中国人的，然而我还不料，也不信竟会下劣凶残到这地步。（华盖集续编-纪念刘和珍君） 惨象，已使我目不忍视了；流言，尤使我耳不忍闻。我还有什么话可说呢？我懂得衰亡民族之所以默无声息的缘由了。沉默呵，沉默呵！不在沉默中爆发，就在沉默中灭亡。（华盖集续编-纪念刘和珍君）","categories":[{"name":"文学","slug":"文学","permalink":"https://linqy71.github.io/categories/文学/"}],"tags":[{"name":"鲁迅 杂文","slug":"鲁迅-杂文","permalink":"https://linqy71.github.io/tags/鲁迅-杂文/"}]},{"title":"Redis环境配置","slug":"Redis环境配置","date":"2020-10-04T06:54:14.000Z","updated":"2025-02-24T12:08:16.423Z","comments":true,"path":"2020/10/04/Redis环境配置/","link":"","permalink":"https://linqy71.github.io/2020/10/04/Redis环境配置/","excerpt":"","text":"Redis环境配置记录 记录在centos上安装redis的过程 下载Redis软件包wget http://download.redis.io/releases/redis-6.0.0.tar.gz选择最新版redis压缩包进行下载 解压并安装tar xvf redis-6.0.0.tar.gzcd redis-6.0.0makesudo make install PREFIX=/usr/local/redis 创建redis命令软链接sudo ln -s /usr/local/redis/bin/redis-server /usr/bin/redis-server上述命令为redis-server创建了软链接，这样在任何目录下都能启动redis服务器，对客户端、benchmark等也可以进行同样的软链接操作。 安装libatomic.so.l启动redis服务器时遇到error：redis-server: error while loading shared libraries: libatomic.so.1: cannot open shared object file: No such file or directory安装libatomic即可解决：sudo yum -y install libatomic 启动redis集群为多个server修改配置文件以配置不同的端口、开启集群模式等，然后运行多个server，每个server启动命令如下：redis-server ./redis-6.0.0/conf/redis-6379.conf 后台查看server运行状态ps -fu username 可以查看用户名下运行的所有进程 启动后客户端连接服务器redis-cli -h xxx -p xxx-h 接server所在的主机ip， -p接server运行端口 发现客户端无法连接server 修改server的配置文件： 注释掉 bind 127.0.0.1 将 protected-mode yes 改为 protected-mode no 重新启动多个server 打开端口号：iptables -I INPUT -p tcp --dport xxxx -j ACCEPT查看开放端口：sudo iptables -L -n关闭端口：iptables -A OUTPUT -p tcp --dport xxxx -j DROP 2020.10.4 遇到的问题： 位于另外一台主机的client无法连接上server： 两台主机之间需要通过内网访问 需要注释掉redis配置文件中对ip地址的绑定 关闭防火墙 集群启动 记录集群启动过程 在主机1上启动6个server节点 在主机2上连接其中一个节点并进行节点握手：redis-cli -c -h xxxx(host ip) -p 63796379&gt; cluster meet xxxx 6380/6381/6382/6383/63846379&gt; quit 在主机2上为6个server分配16384个slots：&gt; redis-cli -h xxxx -p 6379 cluster addslots {0..2729}其余5个server节点类似。 查看集群：6379&gt; cluster nodes 测试集群：6379&gt; set university &quot;SYSU&quot; 使用benchmark测试集群： 集群启动方法二： redis-cli --cluster create host1:port1 host2:port2 ... 监控集群 安装redis-stat采用 gem install redis-stat 报错：于是下载github上的jar包后，通过java -jar redis-stat-0.4.14.jar --server直接启动redis-stat redis-stat 参考 https://github.com/junegunn/redis-stat","categories":[{"name":"coding","slug":"coding","permalink":"https://linqy71.github.io/categories/coding/"}],"tags":[{"name":"Redis, centos","slug":"Redis-centos","permalink":"https://linqy71.github.io/tags/Redis-centos/"}]},{"title":"读《悲剧的诞生》","slug":"读《悲剧的诞生》","date":"2020-10-02T07:06:22.000Z","updated":"2025-02-24T12:08:16.437Z","comments":true,"path":"2020/10/02/读《悲剧的诞生》/","link":"","permalink":"https://linqy71.github.io/2020/10/02/读《悲剧的诞生》/","excerpt":"","text":"读尼采《悲剧的诞生》日神——阿波罗，酒神——狄奥尼索斯。日神象征造型的艺术，酒神象征音乐的艺术。两者的结合则诞生了悲剧艺术。 唯有作为审美现象，世界之此在才是合理的。 1. 从希腊人出发 希腊人越来越强烈的对美的渴求，对节庆、快乐、新崇拜的渴求，真的起于缺失、匮乏、伤感和痛苦吗？ 悲剧从何而来呢？莫非来自快乐，来自力量，来自充沛的健康，来自过大的丰富么？ 莫非癫狂未必是蜕化、衰败、迟暮文化的征兆。如果说希腊人正处于青春的丰富当中，具有追求悲剧的意志，成了悲观主义者，那又如何呢？如果说正是癫狂给希腊带来了极大的福祉，那又如何呢？如果希腊人正处于崩溃和虚弱时代，变得越来越乐观、肤浅、虚伪，越来越热衷于逻辑和对世界的逻辑化，因而也变得“更快乐”和“更科学”了，那又如何？ 怎么？一切与“现代观念”和民主趣味的偏见相反，乐观主义的胜利，已经占了上风的理性，实践上和理论上的功利主义，类似于与它同时代的民主制，可能是精力下降、暮年将至、生理疲惫的一个征兆吗？ 阿波罗，作为一切造型力量的神，同时也是预言之神。阿波罗乃是“闪耀者、发光者”，是光明之神，他也掌管着内心幻想世界的美的假象。 当人由于根据律在其某个形态中似乎遭遇到例外，从而突然对现象的认识形式生出怀疑时，人就会感到无比恐惧。如果在这种恐惧之外还加上那种充满喜悦的陶醉，那么我们就能洞察到狄奥尼索斯的本质。 在这里，在醉的战栗中，整个自然的艺术强力得到了彰显，臻至“太一”最高的狂喜满足。 阿波罗与它的对立面，即狄奥尼索斯，是两种艺术力量，它们是从自然本身中突现出来的，无需人类艺术家的中介作用。而且在其中，两者的艺术冲动首先是直接地获得满足的：一方面作为梦的形象世界，其完美性与个体的知识程度和艺术修养毫无联系，另一方面乃作为醉的现实性，它同样也不重视个体，甚至力求消灭个体，通过一种神秘的统一感使个体得到解脱。 2. 从音乐出发 旋律是普遍性的东西，它能在多种文本中承受多种客观化。 按照语言模仿现象世界和形象世界还是模仿音乐世界，我们可以区分出希腊民族语言史上的两大主流。 在荷马与品达之间，必定奏响过纵情狂欢的奥林匹斯笛声，直到亚里士多德时代，一个音乐已经极其发达的时代，这笛声依然令人陶醉激动，而且确实以其原始的作用，激发同时代人的一切诗歌表现手段去模仿它。 音乐显现为意志，也即显现为审美的、纯粹关照的、无意志的情调的对立面。按其本质来看，音乐不可能是意志，倘若音乐是意志，则它就会完全被逐出艺术领域了，因为意志本身乃是非审美的东西。但音乐却显现为意志 唯有艺术才能把那种对恐怖或荒谬的此在生命的厌恶思想转化为人们赖以生活下去的观念：那就是崇高和滑稽，崇高乃是以艺术抑制恐怖，滑稽乃是以艺术发泄对荒谬的厌恶。 3. 苏格拉底 希腊悲剧的毁灭不同于全部更古老的姊妹艺术种类：它是由于一种难以解决的冲突而死于自杀，所以是悲剧性的。 把那种原始的和万能的狄奥尼索斯元素从悲剧中剔除出去，并且纯粹地、全新地在非狄奥尼索斯的艺术、道德和世界观基础上重建悲剧，——这就是欧里庇德斯的意图。 而欧里庇德斯从某种意义上来说也只是面具：借他之口说话的神祗不是狄奥尼索斯，也不是阿波罗，而是一个完全新生的恶魔，名叫苏格拉底。 这是一种全新的对立：狄奥尼索斯和苏格拉底，而希腊悲剧艺术作品便因此对立而走向毁灭了。 审美苏格拉底主义的最高原则：“凡要成为美的，就必须是理智的。” 当苏格拉底发现他是唯一承认自己一无所知的人时，他关于这种新的 对知识和见识的空前重视 发表了极为尖刻的话。他以挑衅之势走遍雅典，造访那些大政治家、大演说家、大诗人和大艺术家，所到之处都见到知识的自负。他那审视的目光所及，只看到缺乏识见和幻想猖獗，然后从这种缺失当中推断出现存事物的内在颠倒和无耻下流。 在所有创造性的人那里，直觉恰恰是一种创造和肯定的力量，意识表现为批判性的和劝告性的，而在苏格拉底身上却不然，在他那里，直觉成了批判者，意识成了创造者。 苏格拉底的原理的结论：“德性即是知识；唯有处于无知才会犯罪；有德性者就是幸福者”：在这三种乐观主义的基本形式中，蕴含着悲剧的死亡。因为现在，有德性的英雄必定是辩证法家，德性与知识、信仰与道德之间必定有一种必然的、可见的联合，现在，埃斯库罗斯的先验的正义解答，沦落为“诗歌正义”这一浅薄而狂妄的原则了。 然而，苏格拉底主义与艺术之间是否必然地只有一种对立的关系？一个“艺术苏格拉底”的诞生究竟是不是某种自相矛盾的东西？ 4. 再谈音乐 与其他所有艺术不同，音乐不是现象的映像，而径直就是意志本身的映像，所以，音乐表现的是世界中一切物理因素的形而上学性质，是一切现象的物自体。在一种较为严格的意义上讲，美学乃始于这种在全部美学中最为重要的美学认识。 《作为意志和表象的世界》第一篇，“根据所有这一切，我们可以把显现的世界（或自然）与音乐看作同一事物的两种不同表达。如果我们把音乐看作世界之表达，那么它就是最高级的普遍语言，甚至于这种语言之于概念的普遍性的关系，大致如同概念之于个别事物的关系。但它的普遍性绝不是那种抽象的空洞普遍性，是与概无例外的、清晰的确定性相联系的。” 当一种合适的音乐对某个场景、行动、事件和环境响起来的时候，这种音乐似乎向我们揭示了这些个场景、行动、事件和环境最隐秘的意义，表现为对后者的最正确和最清晰的注解。 我们或许可以把世界成为被形体化的音乐，同样地也可以把世界成为被形体化的意志。 首先，音乐激发对狄奥尼索斯式的普遍性的比喻性直观，其次，音乐也使得这种比喻性形象以之高的意蕴显露出来。 音乐具有诞生神话的能力，作为重要的例证，就是能够诞生出悲剧神话——那是用比喻来言说狄奥尼索斯式认识的神话。 如若音乐只是强迫我们去寻找某个生命和自然事件与音乐的某些旋律形态和独特声音之间的外在相似性，力图借此来激发我们的快感，那么，我们就被下降到一种不可能孕育神话因素的情绪之中了。因为神话只能被直观地感受为一种向无限凝视的普遍性和真理性的唯一例子。 5. 现象背后 狄奥尼索斯艺术同样也要使我们坚信此在的永恒快乐：只不过，我们不应该在现象中寻求这种快乐，而是要在现象背后来寻求。我们应当认识到，一切产生出来的东西都必定要痛苦地没落，我们不得不深入观察个体实存的恐惧，而我们却不应因惊恐而发呆：一种形而上学的慰藉会让我们暂时挣脱变化形态的喧嚣。 这是一个永恒的现象：贪婪的意志总是在寻找某种手段，通过一种笼罩万物的幻景使它的造物持守在生命中，并且迫使它们继续存活下去。 有人受缚于苏格拉底的求知欲，以及那种以为通过知识可以救治永恒的此在创伤的妄想；也有人迷恋于在自己眼前飘动的诱人的艺术之美的面纱；又有人迷恋于那种形而上学的慰藉，认为在现象漩涡下面永恒的生命坚不可摧，长流不息。根本上，这三种幻想等级只适合于品质高贵的人物，这等人物毕竟能以更深的不快和反感来感受此在的重负和艰难，并且不得不通过精选的兴奋剂来对自己隐瞒这种不快和反感。 席勒说过，自然与理想要么是哀伤的对象，要么是快乐的对象。当自然被表现为失落了的东西而理想被表现为未达到的东西时，两者就是哀伤的对象；而当两者被设想为现实的东西时，它们就是快乐的对象。第一种情况提供出狭义的哀歌，第二种情况则产生出最广义的牧歌。 歌剧的特征绝不带有对于一种永远丧失的哀痛，而倒是有着一种对于永远重获的欢欣。 每当狄奥尼索斯热情明显地向四周蔓延时，我们总是能够察觉到，对个体之桎梏的狄奥尼索斯式的摆脱首先表现为一种政治本能的减退，减退到了冷漠、甚至敌视政治本能的地步。 若没有对个体人格的肯定，也就不可能有国家和故乡意识。 一个民族若以政治冲动的绝对有效性为出发点，则恰恰必然地陷于极端世俗化的轨道里。（罗马帝国） 6. 唯有作为审美现象 唯有作为审美现象，此在与世界才显得是合理的：在这种意义上，悲剧神话恰恰是要我们相信，甚至丑陋和不和谐也是一种艺术游戏，是意志在其永远丰富的快感中与自己玩的游戏。 音乐与悲剧神话同样是一个民族的狄奥尼索斯能力的表现，而且彼此不可分离。两者起源于一个位于阿波罗因素之外的艺术领域；两者都美化了一个区域，在这个区域的快乐和谐中，不谐和音以及恐怖的世界图景都楚楚动人地渐趋消失；两者都相信自己有极强大的魔法，都玩弄着反感不快的芒刺；两者都用这种玩法为“最坏的世界”之实存本身辩护。 在这里，与阿波罗因素相比较，狄奥尼索斯因素显示为永恒的和原始的艺术力量，说到底，正是这种艺术力量召唤整个现象世界进入此在之中：而在现象世界的中心，必需有一种全新的美化假象，方能使这个生机盎然的个体化世界保持活力。","categories":[{"name":"文学","slug":"文学","permalink":"https://linqy71.github.io/categories/文学/"}],"tags":[{"name":"尼采 哲学","slug":"尼采-哲学","permalink":"https://linqy71.github.io/tags/尼采-哲学/"}]},{"title":"Redis学习-2","slug":"Redis学习-2","date":"2020-09-14T11:32:40.000Z","updated":"2025-02-24T12:08:16.423Z","comments":true,"path":"2020/09/14/Redis学习-2/","link":"","permalink":"https://linqy71.github.io/2020/09/14/Redis学习-2/","excerpt":"","text":"深入理解RedisRedis阻塞 Redis 是典型的单线程架构，所有的读写操作都是在一条主线程中完成的。当Redis用于高并发场景时，阻塞问题至关重要。 导致阻塞的原因 内在原因：不合理地使用API或数据结构、CPU饱和、持久化阻塞等 外在原因：CPU竞争、内存交换、网络问题等 CPU饱和 单线程的Redis处理命令时只能使用一个CPU，CPU饱和是指Redis把单核CPU使用率跑到接近100%。CPU饱和导致Redis无法处理更多命令。 解决方法有： 采用集群分摊OPS压力（Operations per Second） 检查是否存在过度的内存优化，例如为了节省内存使用ziplist代替hash 检查是否采用了高算法复杂度的命令 CPU竞争 进程竞争：当Redis与其它多核CPU密集型服务部署在一起，会出现竞争CPU资源的情况。 绑定CPU：部署Redis时为了充分利用多核CPU，通常一台机器会部署多个实例。常见的一种优化是把Redis进程绑定到CPU上，用于降低CPU频繁上下文切换的开销。 但是当Redis父进程创建子进程进行持久化时，如果作了CPU绑定，子进程与父进程就会在同一个CPU上进行，从而使得子进程与父进程抢夺CPU资源。因此对于开启了持久化或参与复制的主节点不建议绑定CPU。 Redis内存 Redis实际内存消耗主要包括：键值对象、缓冲区内存、内存碎片。 缓冲内存包括：客户端缓冲、复制积压缓冲、AOF缓冲区 Redis事件处理Redis服务器是典型的事件驱动程序。其中，事件分为文件事件和时间事件，事件封装在结构体aeEventLoop中。 Redis底层使用4中I/O多路复用模型（evport, select, kqueue, epoll），并对这4种模型进一步封装。 事件循环执行函数的主要逻辑： 查找最早会发生的时间事件，计算超时时间 阻塞等待文件事件的产生 处理文件事件 处理时间事件 文件事件Redis客户端通过TCP socket与服务端交互，文件事件指的就是socket的可读可写事件。为了同时处理多条网络连接，采用较为成熟的I/O多路复用模型。 epoll epoll是linux内核为处理大量并发网络连接而提出的解决方案，能显著提升系统CPU利用率。 epoll_create: 创建一个epoll专用的文件描述符 epoll_ctl: 注册、修改或删除需要监控的事件 epoll_wait: 阻塞进程知道监控的若干网络连接有事件发生 时间事件本质上，Redis只有一个时间事件——serverCron。该函数实现了Redis服务器所有定时任务的周期执行。 Redis Server启动过程Server初始化 初始化配置，包括用户可配置的参数以及命令表的初始化 加载并解析配置文件 初始化服务端内部变量，其中包括数据库。 创建事件循环eventLoop 创建socket并启动监听 创建文件事件与时间事件 开启事件循环 Redis 数据分区当单台机器的可用内存里无法装载大型数据库或者数据集时，数据分区就成为了一种重要策略，它将键进行分割并指派给特定的Redis实例。通过分区这一方式，单一的Redis实例的计算能力和资源将不再成为限制。 数据分区的方法客户端分区分区逻辑包含在客户端代码中，基于算法或者存储的额外信息来选择正确的分区或Redis节点。常见的策略有： 范围分区：为每个Redis实例指定键的范围。会带来额外的成本，包括用户追踪分区的Redis bitstring数据结构，以及定制开发的客户端代码 列表分区：为分区指定一个列表值。与范围分区类似，列表分区同样需要中间数据结构来支持数据存储中 键的分配与追踪。 哈希分区：根据键和哈希算法计算出值，并基于数据存储中的分区数量或可用实例数对该值进行取模。 复合分区：结合不同分区方法进行分区。辅助代理分区Redis客户端连接到代理中间件，再由它将客户端请求路由到正确的Redis节点。 Twemproxy：Twemproxy是一个由Twitter发布的开源项目，旨在创建客户端和由memcache或者Redis实例组成的服务器端间的缓存代理。Twemproxy通过采用中间件的方式，分离客户端调用和数据存储后端 查询路由 任一客户端查询集群中的随即节点将会被路由到包含正确键的正确节点上，这是Redis集群当前的实现方式。 Redis集群Redis在大规模分布式计算中主要面临两个问题： 如何将数据分区到N个Redis实例中去 如何优雅地处理某些情况下的节点故障 Redis集群不提供健壮的一致性保证，也就是说在传播数据时数据可能丢失。 Redis集群默认运行的传播模式是异步的流程（在与客户端交互期间，Redis集群会继续写操作）。在主从节点的配置下，集群的性能胜于数据的一致性。如果数据的一致性对于应用程序来说比性能更重要，那么Redis集群提供的WAIT命令可以用来将数据传播的方式变更成同步流程。 当Redis集群在运行时，当中的每个节点会打开两个TCP socket。第一个用于连接客户端的标准Redis协议，默认端口是6379。第二个端口是由第一个端口加上10000所得（默认16379），运行着用于节点间通信的二进制协议。 Redis集群中的节点使用Redis集群总线在网状网络拓扑结构中与其他节点连接。 参考文献 《Redis开发与运维》 《Redis 5设计与源码分析》 《深入理解Redis》","categories":[{"name":"源码阅读","slug":"源码阅读","permalink":"https://linqy71.github.io/categories/源码阅读/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://linqy71.github.io/tags/Redis/"}]},{"title":"Google论文-Bigtable阅读笔记","slug":"Google论文-Bigtable阅读笔记","date":"2020-07-08T03:00:06.000Z","updated":"2025-02-24T12:08:16.417Z","comments":true,"path":"2020/07/08/Google论文-Bigtable阅读笔记/","link":"","permalink":"https://linqy71.github.io/2020/07/08/Google论文-Bigtable阅读笔记/","excerpt":"","text":"Bigtable: a distributed storage system for structured data 本文为翻译版 摘要Bigtable是一个用于管理结构化数据的分布式存储系统，数据可扩展到非常大的尺寸：几千个商业服务器上的大数据。许多Google项目把数据存储在Bigtable中，包括web indexing, Google Earth, Google Finance。从数据大小的角度或是延迟要求的角度来说，这些应用对于Bigtable有不同的要求。但尽管需求不同，Bigtable能够为这些产品提供灵活的、高性能的解决方案。本文描述了Bigtable提供的简单数据模型，该数据模型使得客户端能够动态控制数据布局和格式，并描述了Bigtable的设计和实现。 Introduction在过去的两年半时间里，我们设计、实现、部署了一个用于管理结构化数据的分布式存储系统——Bigtable。Bigtable的设计目的是使得大数据能够可靠地扩展到上千个机器上。Bigtable已经实现了几个目标：广泛的应用性、可扩展性、高性能、高可用性。Bigtable已经被用于六十多个Google产品和项目中。这些产品使用Bigtable来存放很多不同需求的负载，从面向吞吐量的批处理工作到延迟敏感的服务器数据。被这些产品所使用的Bigtable集群已经扩展了广泛的配置，存储了几百T的数据。 在许多方面，Bigtable类似于一个数据库：它与数据库共享许多实现方案。并行数据库和主存数据库已经取得了可扩展性和高性能，但Bigtable提供了跟这些系统不一样的接口。Bigtable不支持完整关系数据模型，相反，它为客户端提供了一个简单的可以支持对数据布局和格式动态控制的数据结构，使得客户端能够推测在底层存储中所表示的数据的位置属性。数据使用可以是任意字符串的行列名字作为下标。Bigtable把数据当成未翻译的字符串，尽管客户端经常将各种格式的结构化、半结构化数据序列化成这些未翻译字符串。客户端能够控制数据的位置(locality)通过选择他们的模式。最后，Bigtable模式参数使得客户端能够动态控制从内存还是硬盘中处理或访问数据。 数据模型一个Bigtable是一个稀疏的、分布式的、持久的多维有序map。该map以一个row key、column key、timestamp作为index，map中的每个value是一个未翻译的字节数组。 在检查了一个类似于Bigtable系统的许多实用场景后我们选定了这个数据模型。一个具体的例子：假设我们想要保存一份存有大量网页和相关信息的表格，暂且将表格称为Webtable。在Webtable中，我们使用URL作为row key，使用网页的不同方面作为column names，将网页内容存储在contents中，contents是一个列。 行表中的行key可以是任意字符串(目前大小上限为64KB，10-100字节是多数用户使用的大小)。对于一个row key的每次数据读写都是原子性的(atomic)，使得客户端能够在同一行中出现并发更新时更容易推断出系统行为。 Bigtable以row key的词典顺序维护数据。一个表的行区间(row range)是被动态分割的。每个行区间被称作一个tablet，是分布和负载均衡的单位。因此，短行区间的读是高效的并且通常只需要同少数机器进行通信。客户端能够通过选择他们的row key开发这个属性从而使得它们能够为数据访问获取数据的位置信息。例如，在Webtable中，某些领域的页面被并为一组存放在相邻的行中(通过翻转URL可以做到)。这种方式使得访问更加高效。 列族 column familiescolumn keys被划分为一些集合，这些集合成为column families，组成了访问控制的基本单位。存储在同一column familiy中的所有数据通常是同一种类型的。一个column family必须在数据存储到任何该family中的key之前创建。当一个family被创建之后，这个family中的任何column key都可以被使用。我们故意使得column family的数量保持在少数（最多几百个），而且families很少在操作过程中改变。相反，一个表中可能有无数个列。 一个column key的命名方式要遵循语法：family:qualifier。Column family 的名字必须是可打印的，qualifier就可以是任意字符串。例如：Webtable中的一个column family是language，存储了该web page对应的语言，该family中只有一个key，存储了language ID。另一个family是anchor，里面的每个key表示一个单独的anchor。如图1所示，qualifier表示相关网站，表格中的内容则是链接文本。 访问控制和硬盘、内存统计是在column family层面执行的。以Webtable为例，这些控制使得我们能够管理一些不同种类的应用：添加新的基数据、读取基数据和创建衍生的column family以及只允许浏览现有数据。 时间戳 timestampsBigtable中的每个cell能够包含同一数据的不同版本。这些版本以时间戳为下表。Bigtable的时间戳是64位证书。它们能够被Bigtable本身所赋值或是被客户端应用显式赋值。客户端应用需要生成单独的时间戳以避免碰撞。一个cell的不同版本是按照时间戳递减顺序排列的，因此最近的版本会被最先访问。 为了更好地管理有版本的数据，我们支持两种设置使得Bigtable能够自动进行cell版本垃圾回收。客户端能够指定只有最新的n个版本能够被保留或是只有足够新的版本能够被保留(例如只保留最近7天内被写入的版本)。 以Webtable为例，我们设置这个存储在contents中的被爬下来的网页的时间戳…上面描述的垃圾回收机制使得每个页面只能保留最近的3个版本。 APIBigtable API提供了一些用于创建和删除表、column family的方法。它也提供了一些改变cluster、table、column family metadata的方法，例如访问控制权限。 客户端应用能够写入或删除Bigtable中的数据，查找每个行中的数据或者是遍历表中数据的某个子集。 ······ Bigtable支持一些其他的特性使得用户能够更复杂地操控数据。首先，Bigtable支持单行交易，能够用于执行原子性的对保存在单个row key中的数据的读写操作。Bigtable目前不支持通用的跨row key的交易，尽管它提供了一个跨row key批量写入数据的接口。其次，Bigtable允许每个cell被用作integer counters。最后，Bigtable支持在服务器的地址空间中执行客户端提供的脚本。这些脚本使用一种Google为了处理数据而开发的语言写的——Sawzall。目前，我们的基于Sawzall的API不支持客户端脚本写回Bigtable，但它允许不同的数据转化格式，以任意表达式过滤以及通过多种操作符总结。 Bigtable可以与MapReduce一起使用。MapReduce是Google开发的一个用于运行大规模并行计算的框架。我们已经封装了许多接口使得一个Bigtable既可以作为MapReduce job的输入又可以作为输出。 building blocksBigtable是基于一些其他的Google基础设施构建的。Bigtable使用分布式的Google File System(GFS)来存储日志文件和数据文件。一个Bigtable集群通常在一个共享池中被操作，池中包含了运行有其他分布式应用的机器。Bigtable进程经常与其他应用的进程共享同一台机器。Bigtable依赖一个集群管理系统来调度工作、管理共享机器的资源、处理机器错误以及监视机器状态。 Google SSTable文件格式用于存储Bigtable数据。一个SSTable提供了一个持久的、有序不变的map将key映射到value，其中key和value都是任意字符串。SSTable提供了查找跟特定key所关联的value的操作，或者是遍历特定key区间内的键值对。在内部，每个SSTable 包含一个块序列，通常每个块是64KB，但这个大小是可配置的。一个块的下标（储存在SSTable的末端）用于定位块，这个下标在SSTable被打开时载入内存。一个查找操作通过一次磁盘搜索便可以完成：首先通过对内存中的下标进行二分查找找到合适的块，再将该块从磁盘中读取出来。一个SSTable也可以完整映射到内存中，从而查找操作可以无需访问磁盘。 Bigtable依靠一个高可用和持久的分布式锁服务——Chubby。一个Chubby服务包含5个活跃的副本，其中一个被选举为master并响应请求。当多数的副本都处于运行状态并且能够互相通信时，服务即试做在线(live)。Chubby使用Paxos算法来保持副本之间的一致性。Chubby提供了一个命名空间包含了文件夹和一些小文件。每个文件夹或文件可以作为一个锁，对一个文件的读写是原子性的。Chubby客户端库提供一致的Chubby文件缓存服务。每个Chubby客户端维护一个session。当客户端的session无法在租约到期时间内更新他的session lease则session过期。当一个客户端session过期时，它释放所有的锁和已开启的handle。Chubby客户端能够为Chubby文件和文件夹注册回调函数用于通知变化或session过期时间。 Bigtable使用Chubby来完成各种任务：确保在任何时间最多只有一个活跃的master；保存Bigtable数据的bootstrap location；发现tablet服务器和中间tablet服务器的死亡；存储Bigtable的模式信息（每个表中的column family信息）；存储访问控制列表。如果Chubby持续一段时间内都不可用那么Bigtable也会变得不可用。我们在14个跨越了11个Chubby实例的Bigtable集群测量了这种影响。在Bigtable的服务时间内由于Chubby不可用造成存储在Bigtable中的数据不可用的时间平均占比为0.0047%，其中占比最高的单个集群为0.0326%。 ImplementationBigtable包含三个主要组件：链接到每个客户端的库、一个master server和许多tablet server。集群中的tablet server 能够动态添加或删除来适应负载的变化。 master负责分配tablets给tablet server， 删除额外的和过期的tablet server， 均衡 tablet server 的负载以及GFS中的文件的垃圾回收。并且，它还处理模式的变化例如表或column family的创建。 每个tablet server管理一个tablet集合（通常每个tablet server有10-1000个tablet）。tablet server处理它载入的tablet的读写请求并将变得过大的tablet切分开来。 就像许多单master的分布式存储系统一样，客户端数据不通过mater移动：客户端直接与tablet server进行读写通信。因为Bigtable客户端不依赖master来获取tablet 定位信息，多数的客户端从不与master通信。因此，master 在实际上是轻载的。 一个Bigtable集群存储了许多表。每个表包含了许多tablet，每个tablet包含了与一个行区间关联的所有数据。一开始，每个表只包含一个tablet。随着表的增长，它自动切分成了多个tablet，每个默认大小为100-200MB。 tablet location （片位置）我们使用一个类似于B+树的三层结构来储存片位置信息。 第一层是一个存储在Chubby中的文件，包含了根片（root tablet）的位置信息。根片包含了所有片的位置信息在一个特殊的METADATA表中。每个METADATA片包含了一个用户tablet集合的位置信息。根片是METADATA表的第一个片，它不会再被分解，确保了片位置信息层次不会超过三层。 METADATA表存储了一个片的位置信息在一个row key中，row key是这个片的表的标识以及它的末尾行的编码。每个METADATA行存储了大约1KB的数据在内存中。若METADATA的上限为128MB，那么这种三层的位置结构可以存储2^34个片。 客户端库存储了片位置。如果客户端不知道某个片的位置或者如果它发现了缓存中的位置信息是错误的，那么他就会递归地上升片位置层次。如果客户端缓存为空，那么定位算法需要3轮网络通信，包括一次对Chubby的读。如果客户端的缓存是被污染的，那么定位算法需要6轮网络访问，因为被污染的缓存条目只有在不命中时才会被发现。尽管片位置信息存储在内存中，已经无需访问GFS，我们还是进一步减少了内存开销，通过令客户端库预取片位置：无论何时读取METADATA表时都会读取不止一个片。 我们在METADATA表中也存储了一些次要信息，包括所有事件的日志等，有助于debug和性能分析。 tablet assignment 片分配每个片一次只会分配给一个tablet server。master保持对活跃的tablet server集合的追踪，以及对tablet分配行为的追踪，包括未被分配的tablets。当一个片是未被分配的，并且有一个拥有足够空间的tablet server是可用的，那么master就会以发送一个tablet载入请求给server的形式将片分配给server。 Bigtable使用Chubby来追踪(track)tablet server。当一个tablet server开启，它创建并获得一个专用的锁在一个特殊Chubby文件夹的单一命名的文件上。master通过监控这个文件夹来发现其他的tablet server。如果这个专用的锁丢失了那么tablet server就会停止服务：例如：由于网络切分导致server丢失了Chubby session。Chubby提供了一个有效的机制能够使得tablet server在不引发网络拥塞的情况下可以检查它是否还保留着锁。只要文件还存在tablet server就会尝试重新获取文件锁。如果文件已经不存在了，则表示tablet server 无法再继续服务，因此它会将自己kill掉。当tablet server终结时(例如)它会尝试释放锁使得master能够更快地重新安排它的tablets。 master负责检测tablet server不再服务它的片了并且尽快重新安排这些片。为了检测tablet server是否不再服务它的片，master会定期询问每个server的锁状态。如果某个tablet server报告它已经丢失了它的锁，或者master经过几次尝试后都无法到达这个tablet server，master会尝试获取这个server的文件锁。如果master成功获取了这个文件锁那么Chubby是活跃的并且这个tablet server还未死亡或者只是无法获取Chubby，那么master会删除它的server文件来确保这个server不会再提供服务。一旦一个server的文件被删除，master能够移动这钱分配给这个server的所有的片进入未分配片的集合中。为了确保Bigtable集群不会轻易由于master和Chubby之间的网络原因受损，master会在Chubby session过期的时候杀死它自己。然而，尽管如上所述，master的failure不会改变对片的分配。 当master被集群管理系统启动的时候，它需要在改变片安排情况之前获取现有的片安排情况。master启动时执行这些操作：1)master在Chubby中抓取一个特殊的master锁，避免并发的master初始化；2)master扫描Chubby中的server文件夹来寻找存活的server；3)master和其他在线的tablet server通信以获取片分配情况；4)master扫描METADATA表。当扫描到了一个还未被分配的片时，master将这个片添加到未分配片集合中。 较为复杂的情况是对METADATA表的扫描只有在METADATA表已经被分配的情况下才能发生。因此，在扫描开始之前，master会添加根片到未分配片集合中如果在第3)步中对跟片的分配未被发现。这个附加条件确保了根片会被分配。因为根片包含了所有METADATA片的名字，master扫描根片之后便可以获取所有片名。 现有的片集合只有当一个表创建或删除、两个表的合并或一个表的切分时才会发生改变。master能够保持对这些变化的追踪。片切分会被特殊对待因为它们是被tablet server初始化的。tablet server会将新片的信息记录到METADATA表中。当信息成功提交后会通知master。万一切分的通知丢失了（由于tablet server或master的死亡引起的），master会检测新的片当它命令一个tablet server去载入已切分的片时。tablet server会通知master切分行为因为它在METADATA表中找到的tablet条目只会指定master要求装载的一部分片。 tablet serving片的持久状态被保存在GFS中。更新会被提交到一个保存了重做记录的日志中。在所有的更新中，最近提交的更新会被保存在一个有序的内存缓存中，称为memtable。旧的更新保存在一个SSTable序列中。为了记录一个片，tablet server会从METADATA表中读取数据。被读取的数据包含了SSTable列表，这个列表包含了一个片，一个重做点集合（指向提交日志中那些可能与该片有关的数据）。server读取这些指数到内存中并重新构建memtable通过应用这些在重做点后提交的更新。 当一个写操作到达tablet server的时候，server会检查它是否完好并检查发送者是否已授权。授权操作是通过读取Chubby文件中的允许写入者列表来确认的。(这个操作在Chubby客户端缓存中几乎总是命中的)。一个有效的突变会被写入提交日志中。提交分组被用来提高小突变的吞吐量。当写操作成功提交后，它的内容会被插入到memtable中。 当一个读操作到达tablet server的时候，server也会检查它是否完好并检查发送者是否已授权。一个有效的读操作会被执行以SSTable序列和memtable合并的视角来看。由于SSTable和memtable是按字典顺序排序的数据结构，因此合并操作非常高效。 当tablet被切分或合并时即将到来的读写操作可以持续进行。 Compaction当写操作执行时，memtable的大小增加。当大小增加到一定的阈值是，memtable会被冻结，一个新的memtable会被常见，被冻结的表会转化成SSTable并写入到GFS中。这个最小压实操作有两个目标：1)收缩服务器的内存使用情况；2)减少当服务器死亡后恢复过程中需要从日志中读取的数据量。未来的读写操作可以在压实操作过程中持续进行。 每个最小压实操作会创建一个新的SSTable，如果这个行为没有被检测出来，读操作可能需要从任意多个SSTable中合并更新。相反，我们限制了这种文件的数量通过在后台定时执行一个合并压实操作。一个合并压实操作会从一些SSTable和memtable中读取内容并写入到新的SSTable中。当压实操作完成后作为输入的SSTable和memtable就可以被丢弃了。 一个合并压实操作会重写所有的SSTable到一个SSTable这种，这种操作成为主压实操作。由非主压实操作产生的SSTable可以包含特殊的删除条目，这些条目会抑制已经被删除的数据(但是在旧的SSTable中还存活的数据)。而主压实操作产生的SSTable不会包含删除信息以及被删除的数据。Bigtable循环遍历它的片并规律地执行主压实操作。这些主压实操作使得Bigtable能够澄清被已删除数据占用的资源并确保已删除的数据能够及时从系统中消失(对于存储敏感数据的服务来说非常重要)。 Refinement上述章节描述的实现方法需要一些改进以获取更高的性能、可用性和可靠性。 locality groups客户端可以将多个column family分组到一个locality组中。一个独立的SSTable会被创建用于每个tablet的每个locality组。分离那些不是很经常被访问的column family到一个单独的locality组中能够提高读效率。例如，Webtable中的网页元数据(例如语言或是访问量)可以处于一个locality组中，而内容可以处于另一个组中：一个想要读取元数据的应用不会需要读取网页内容。 另外，一些有用的平衡参数也能够被指定针对每一个locality组。例如，一个组可以被声明是保存在内存中的。用于保存在内存中的locality组的SSTable会被惰性地载入tablet server的内存中。一旦被载入，这些组中的column family能够在不访问磁盘的情况下被读取。这个特性对于一些频繁被访问的小片数据来说非常有用：我们在内部使用它为了定位METADATA表中的column family。 Compression客户端能够控制是否压缩一个locality组对应的SSTable，如果压缩，它还可以决定采用哪种压缩方式。用户指定的压缩方式会被应用到每个SSTable块中（块的大小是可控的通过一个特殊的参数）。尽管由于单独压缩每个块会浪费一些空间，但是读取的时候只需要取出一小部分而不是全部的文件就可以了。许多客户端采用传统的two-pass压缩方式。第一个pass使用Bentley and McIlroy’s Scheme，能够跨越大区间压缩长字符串。第二个pass是使用一个快速压缩算法来寻找一个16KB的小区间中的重复数据。两个pass都是非常快速的，编码速度100-200MB/s，解码速度400-1000MB/s。 尽管我们在选择算法时强调速度而不是节省的空间，这个压缩模式却表现优秀。例如，在Webtable中，我们使用这种压缩模式来存储网页内容。在我们的实验中，我们存储了很多文件在一个压缩的locality组中。为了达到实验目的，我们限制了每个文件只有1个版本。这种压缩方式实现了10:1的空间节省。这远好过GZip的3:1或4:1的压缩比，因为网页的行是这么分布的：单个host的所有网页存储的位置相邻。不仅是Webtable，还有很多应用选择行名使得相似的数据能够聚集在一块因而达到较高的压缩比。当Bigtable中存储了相同数据的多个版本时压缩比甚至能达到更高。 caching for read performance为了提高读性能，tablet server使用2层缓存。高层的成为Scan Cache，缓存了由SSTable接口返回给tablet server代码的键值对。底层的是Block Cache，缓存了从GFS中读出来的SSTable块。Scan Cache对于那些倾向于重复读取相同数据的应用更有用。而Block Cache则对那些倾向于读取最近读取过的数据的应用更有用。 Bloom filers一个读操作需要读取所有的SSTable来拼凑tablet的状态。如果SSTable不再内存中，最后还是需要访问磁盘。我们减少磁盘访问次数通过允许客户端指定在特定的locality组中的SSTable生成Bloom filter。一个Bloom filter可以使得我们可以询问一个SSTable是否包含某个特定行/列对的数据。对于某些应用，少量的tablet server内存用来存放Bloom filter可以减少由读操作引起的磁盘访问。我们使用Bloom filter同时也表明了大多数对不存在的行列的查找不需要访问磁盘。 commit-log implementation如果我们将每个片的提交日志保存在不同的日志文件中，那么GFS将会同时有大量的文件写入。这些写操作可能导致大量的磁盘搜索取决于每个GFS服务器的底层实现。并且，每个单独的日志文件会减少分组带来的优化。为了解决这些问题，我们将突变拼接到每个tablet server的提交日志中，再混合不同server的日志到同一个日志文件中。 使用单个日志文件提供了良好的性能优化，但灾难恢复变得更复杂。当一个tablet server死亡时，它所服务的片会被移动到很多其他的tablet server上:每个server只会载入少量的片。为了恢复片的状态，新的server需要重新应用突变到原本写好的提交日志上。然而，这些片的突变已经在同一个日志文件中混合。一个方法是令每个新的tablet server去读取完整的日志文件并恢复那些需要恢复的条目。但效率太低。 通过对提交的日志条目进行排序我们避免了重读的日志读取(根据 table、row name、log sequence number排序)。在排序后的输出中，一个特定的片的所有转变是相邻的因此能够通过一次磁盘搜索高效地读取。为了并行化排序，我们将日志文件划分为64MB大小的段，然后在不同的tablet server上并行地排序每个段。这种排序过程是由master协调的并且当一个tablet server表明他需要从日志文件中恢复一些变化时被初始化。 写日志到GFS中有时会导致性能瓶颈，有很多原因，例如写操作冲撞涉及到的GFS server，或者到达三个GFS服务器的指定集合的网络路径被阻塞或是高负载。为了保护突变免受延迟峰值的影响，每个tablet server实际上有2个写日志线程，每个线程写入它自己的日志文件，一次只有一个线程工作。如果写入的文件性能很差，那么就会切换到另一个线程。日志条目包含了序列号使得恢复过程可以避免由于线程切换造成的重复条目。 speeding up tablet recovery如果master将一个片从一个tablet server移动到另一个，源server首先对该片执行一个最小压实操作。这个操作减少了恢复时间通过减少日志中未被压实的状态数量。压实结束后，源tablet server不再服务于这个片，在它真正卸载这个片之前，server执行另外一个（通常都非常快）最小压实操作来消除在第一个压实过程中到达的残留的未被压实的状态。当这两个压实操作完成后，该片会被装载到另一个server中而无需进行日志条目恢复。 exploiting immutability包括SSTable缓存在内，Bigtable系统的许多其他部分都被简化了，根据SSTable的不变性。例如，当读取SSTable时我们不需要任何对文件系统的并行访问。因此，对行的并行控制能够高效的实现。唯一可变的数据结构是memtable。为了减少读取memtable过程中产生的冲突，我们使每个memtable的行在写入时复制并且允许读写并行。 由于SSTable是不可变的，移除被删除的数据等同于对过时的SSTable进行垃圾回收。每个片的SSTable在METADATA表中注册。master移除过时的SSTable通过对SSTable集合进行一个mark-sweep垃圾回收操作，METADATA表中包含root集合。 最后，SSTable的不变性使得我们能够很快地切分片。我们令子片和父片共享一个SSTable而不是为每个子片重新生成SSTable。 performance evaluation我们建立了N个tablet server的Bigtable集群来测量Bigtable随着N变化的性能和可扩展性。tablet server使用1GB内存，2个400GB IDE硬盘驱动来写入一个有1786个机器组成的GFS cell。N个客户端机器生成用来测试的Bigtable负载。我们使用同样数量的客户端作为tablet server来确保客户端不会成为瓶颈。每个机器有2个双核Opteron 2GHz芯片，足够的物理内存来装载正在运行的进程的工作集，以及一个单千兆以太网链路。这些机器会被安排成一个2层的树形的在根节点大约有100-200Gbps合成可用带宽的网络。所有的机器处于同一个主机中因此任何机器间的通信时间少于1毫秒。 tablet server、master、测试客户端、GFS server全都跑在同一个机器集合上，每个机器运行一个GFS server。一些机器也会运行tablet server或者一个客户端进程、或是同时处理其他工作。 R是测试中Bigtable的不同行key的数量。选择一个合适的R使得每个benchmark都会读写大约1GB的数据。 sequential write使用0-(R-1)作为行 key，行key空间被划分为10N个等大的区间。这些区间被一个中央调度器安排到N个客户端，只要客户端处理完上一个分配给它的区间这个调度器就会分配下一个可用的区间给客户端。这种动态分配消除了由其他运行在客户端上的进程产生的对性能的影响。我们在每个行key下写了一个字符串。每个字符串是随机生成的因此行是不可压缩的。而且，不同的行key下的字符串是不同的，因此跨行的压缩是不可能的。random write也是相似的除了行key被哈希后对R取模因此写负载被均匀得传播到每一个行空间。 benchmark介绍 —介绍sequential read —介绍scan —介绍random reads(mem) single tablet-server performance随机读取比任何其他操作都慢。每次随机读取涉及到将一个64KB的SSTable通过网络从GFS server传送到tablet server中，其中只有1000字节的值被使用。tablet server每秒大约执行1200次读，也就是能够从GFS中读取大约75MB每秒的数据。这样的带宽足够使得tablet server CPU饱和，由于网络堆栈中的开销、SSTable转化、Bigtable代码。而且这样的带宽也足够使得系统中的网络饱和。大多数Bigtable应用会减少块大小至8KB。 从内存随机读取是非常快的因为每1000字节的读取tablet server的内存就可以满足，而不需要从GFS读取一个大的64KB的块。 随机和顺序的写比随机读表现更好因为每个tablet server会拼接所有到来的写到一个单独的日志中并使用组提交来将这些写高效地流入GFS。在随机写和顺序写的性能方面没有太大差别。两种情况下，所有的写都会被记录到同一个日志中。 顺序读比随机读更优因为每个从GFS取出的64KB的SSTable块会被存储到块缓存中用于下一次的64读请求。 scaling当我们增加tablet server数量从1到500时总吞吐量也增加。例如，从内存的随机读取增加了300倍，当tablet server数量增加了500倍时。这种行为是因为这个benchmark的性能瓶颈是每个tablet server的CPU。 然而，性能并没有线性增加。对于大多数的benchmark来说，当tablet server的数量从1变成50的时候，每个server的吞吐量反而下降了。这种下降是因为负载不均衡，通常是因为其他进程抢夺了CPU和网络。我们的负载均衡算法尝试解决这种不均衡，但是无法完美：重新均衡被限制为减少tablet的移动（移动时一个tablet会短暂不可用，通常少于1秒）；由benchmark产生的负载会到处挪动。 随机读的benchmark表明了最坏的扩展性（当tablet server数量扩大500倍时总体吞吐量只提高了100倍）。这种行为是因为每1000个字节的读取都需要通过网络传输一个64KB的块。这种传输 使得1千兆以太网链路饱和，因此每个服务器的吞吐量会随着奇迹数量的增加而下降。 Real Application截止2006年8月，已有388个非测试的Bigtable集群运行在不同的Google机器集群上，共有约24500个tablet server。 Google AnalyticsGoogle Analytics 是一个帮助webmaster在网站上分析交通模式的服务。它提供了总体的数据，例如每日访问量以及每个URL每天的阅读量，以及一些网站分析报告，例如已经浏览了某个网页后进行购买的用户比例。 为了实现这个服务，webmaster嵌入了一个小JS程序在网页中。这个程序在网页被访问时触发。它记录了不同的Google Analytic请求信息，例如一个用户标识符和网页读取相关信息。Google Analytic总结了这些数据并使得它对webmaster可用。 我们简单描述了Google Analytics使用的两个表格。原生点击表格为每个端用户session维护一行，行名为包含了网站名字和session创建时间的组合。这种模式确保了访问同一个网站的session是连续的并按时间顺序排列。这个表格压缩到原来尺寸的14%。 Google Earthgoogle为用户提供了高解决方案的卫星云图，通过基于网站的的Google地图接口和Google Earth。这些产品使得用户能够在地球表面穿梭：他们可以放大、旋转、浏览、标记卫星云图。这个系统使用一个表来预处理数据，还有一个不同表的集合来服务客户端数据。 预处理流水线使用一个表来存储原生图像数据。在预处理期间，图像被清洁和巩固到最终的服务数据。这个表包含了大约70T的数据因此是保存在磁盘中的。这些图像被有效压缩因此Bigtable压缩是不可用的。 图像表中的每行对应一个地理段。行的命名确保了相邻的地理段会保存在相近的位置。表中包含一个column family来追踪每个段的数据源。这个column family 有很多column：每个对应一个原生图像数据。由于每个段只是从几张图片构成的，因此这个column family十分稀疏。 预处理流水线十分依赖MapReduce来转化数据。总体的系统以1MB/s的速度处理每个tablet server的数据。 服务系统使用一个表来index存储在GFS中 数据。这个表非常小（大约500GB）但它必须在非常低的延迟下每秒每个数据中心服务成千上万个查询。因此，这个表由几百个tablet server持有并包含了存储在内存中的column family。 Personalized SearchPersonalized Search是一个记录了用户对不同的Google产品例如网页搜索、图像、新闻的查询、点击操作。用户可以浏览他们的搜索历史来重新访问旧的查询和点击，他们可以寻求个性化的搜索结果。 Personalized Search在Bigtable存储了每个用户的数据。每个用户有单独的userid并且用这个userid命名了一个行。所有的用户行为被保存在一个表中。每种类型的行为预留一个单独column family（例如，有一个column family存储了所有web查询）。每个数据元素使用用户行为触发的事件作为Bigtable时间戳。Personalized Search使用对Bigtable的MapReduce生成用户描述，可以用于个性化的用户实时搜索结果。 Personalized Search数据在多个Bigtable集群中是重复的，为了提高可用性和由于客户端的距离产生的延迟。Personalized Search团队一开始创建了一个基于Bigtable的客户端副本机制为了确保所有副本的事件一致。这个系统现在使用服务器内部的一个复制子系统。 Personalized Search存储系统的这种设计使得其他的组能够添加新的用户信息到他们自己的column中，这个系统现在已经被多个其他需要个性化用户配置选项和设置的Google产品使用。不同组之间共享一个表造成了非常多的column family。为了支持这种共享，我们添加了一个简单的quota机制到Bigtable中来限制共享表中任一客户端的存储消耗。这种机制提供了不同的产品组之间的一些隔离。 Lessons在设计、实现、维护和支持Bigtable的过程中，我们获得了有用的经历和有趣的教训。 一个教训是大的分布式系统对于很多类型的失败来说是易损的，不只是很多分布式协议中设想的标准的网络切分和fail-stop失败。例如，我们已经发现了很多由于以下原因导致的问题：内存和网络崩溃、大的时钟偏差、悬挂机器、扩展的和非对称的网络切分、其他正在使用的系统的bug、GFS quota移除、计划合非计划的硬件维护。我们使用多种协议来解决这些问题。例如，我们添加了校验和到RPC机制中。我们还通过移除了系统的一部分对另一部分所做的假设。例如，我们不再假设Chubby操作只能够返回固定的一组错误。 另一个教训是在新的特性没搞清楚之前不要急着添加。例如，我们一开始计划在我们的API中支持通用目的的交易。因为我们并没有立即用到这个功能，因此我们没有实现。现在我们已经有了很多真实的跑在Bigtable上的应用，我们能够检查他们实际的需求并且发现了大多数的应用只需要单行交易。当人们对分布式交易有需求时，最重要的是维护次要的指数，因此我们打算添加一个特殊的机制来满足这个需求。新的机制会比分布式交易更不通用一点，但会更高效（特别是对于跨越了几百个行的更新来说），并且会与我们的优化跨数据中心副本交互得更好。 一个很实用的教训是适当的系统层面监控是非常重要的（也就是说不仅监控Bigtable本身也监控使用了Bigtable的客户端进程）。例如，我们扩展了RPC系统使得对于一个RPC样来说他能够保持一个详细的对重要行为的记录。这个特性使得我们能够检测和修复许多问题，例如对tablet数据结构的锁争夺、提交Bigtable突变时写操作过慢、由于METADATA 片不可用造成的访问阻塞。另一个有效监控的例子是每个Bigtable集群都在Chubby中注册。这使得我们能够追踪所有的集群，发现他们的代销、观察我们的软件正在运行哪个版本、它们接收时是否拥塞、或者是否产生大的延迟等。 最终要的一个教训是简单设计的价值很高。由于系统的大小(大约10万行非测试代码)，以及代码随时间演变，我们发现代码和设计清晰度对后期的代码维护和debug非常重要。一个例子是tablet server的menbership协议。我们第一个协议非常简单：master定期发布租约到tablet server中，租约过期时tablet server杀死自己、然而这种协议在出现网络问题时可用性非常低，并且对master恢复时间敏感。我们又重新设计了协议。然而，最终的协议非常复杂并且依赖于一些很少被其他应用使用的Chubby特性的行为。我们在Chubby代码的晦涩案例上而不只是Bigtable代码上花费了太多时间。最终，我们废弃了这个协议并设计了一个新的简单协议，只依赖于那些广泛使用的Chubby特性。 Related WorkBoxwood项目有些组件与Chubby、GFS、Bigtable有重合，因为它提供了分布式agreement、锁、分布式chunk存储、分布式B树存储。在每种重合的情况下，Boxwood的组件针对的是更低层次的对象。Boxwood的目标是提供一个用于构建更高层次服务（例如文件系统或数据库）的框架，而Bigtable的目标是支持想要存储数据的客户端应用。 许多最近的项目已经解决了分布式存储或为广域网提供高层服务的问题。这包括对随着CAN、Chord、Tapestry等项目而开始的分布式哈希表的工作。这些系统强调了一些Bigtable没有出现的问题，例如高可变的带宽、不信任的参与者以及频繁的重配置。去中心化的控制和拜占庭容错不是Bigtable的目标。 从分布式数据存储模型的角度来说，我们相信有B树或分布式哈希表提供的键值对模型比较局限，相对于提供给应用开发者的模型来说。键值对是一个有用的构件块，但它们不应该是唯一一个提供给开发者的块。我们选择的模型比单一的键值对更丰富，并且支持稀疏的半结构化数据。尽管如此，它也是足够简单的，可以用高效的flat-file形式表示，并且足够透明，用户可以监控系统的重要行为。 许多数据库销售公司已经开发了并行数据库，可以存储大量的数据。Oracle的Real Application Cluster数据库使用共享磁盘来存储数据，一个分布式锁来管理。IBM的DB2 Parallel Edition基于一个与Bigtable类似的shared-nothing体系结构。每个DB2服务器负责一个表中的行子集，行子集存储在本地的关系数据库中。两个产品都提供了完整的关系模型，并支持交易。 Bigtable locality 组实现了相似的压缩和磁盘读取性能，通过以基于列的数据组织形式而不是基于行的形式来实现。另一个实现横向和纵向切分数据到平面文件中的系统并且实现了很高压缩率的系统是AT&amp;T的Daytona数据库。Locality组不支持CPU缓存层面的优化。 Bigtable使用memtable和SSTable来存储对片的更新，这种形式与Log-Structured Merger Three存储更新的形式相似。两个系统中，被排序的数据在被写入磁盘之前都缓存在内存中，而读操作必须合并内存和磁盘的数据。 C-store和Bigtable有一些相似的特性：都使用一个shared-nothing体系结构并且有两种不同的数据结构，一种用于最近的写，一种用于存储长寿命的数据，并且拥有移动数据的机制。两个系统在API方面不同：C-store表现为关系型数据库，然而Bigtable提供了一个更低层次的读写接口而且支持每个服务器每秒几千次操作。C-store也是一个读优化的关系型数据库管理系统，然而Bigtable为读写敏感的应用提供了更优的性能。 Bigtable的负载均衡器解决了一些与shared-nothing数据库面临的相同的问题。我们的问题更加简单：1）我们不考虑相同数据可能会有多个副本；2）我们让用户告知我们哪些数据是在内存中的而那些数据应该在磁盘中，而不是动态地去决定。3）我们无需执行或优化复杂的请求。 Conclusions我们已经描述了Bigtable——一个用于存储结构化数据的分布式系统。Bigtable集群自从2005年4月一来就投入生产，在此之前，我们已经花了将近7年的时间来设计和实现。截止2006年8月，超过60个项目正在使用Bigtable。我们的用户非常喜欢由Bigtable提供的性能和高可用性，他们能够简单地通过增加更多机器来扩展集群的容量。 考虑到Bistable一些不同寻常的接口，问题是对于用户来说他们适应的过程会有多难。新用户有时对于如何最好地使用Bigtable的接口并不确定，特别是当他们已经习惯于使用关系型数据库的情况下。尽管如此，许多成功使用Bigtable的Google产品证明了我们工作的实用性。 我们正继续开发几个额外的Bigtable特性，例如支持次要指数以及创建跨数据中心的Bigtable副本。我们也开始为产品组部署Bigtable作为服务，使得个人用户无需维护他们自己的集群。随着服务集群的扩展，我们需要解决很多Bigtable内部的资源共享问题。 最后，我们发现在Google搭建我们的解决方案有非常大的优势。我们在为Bigtable设计我们自己的数据模型时获得了大量的灵活性。而且，我们控制Bigtable的实现、以及其他Bigtable所依赖的Google组件，意味着我们能够随着问题的出现移除瓶颈和低效率的部分。","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://linqy71.github.io/categories/论文阅读/"}],"tags":[{"name":"Hbase, Bigtable, 论文","slug":"Hbase-Bigtable-论文","permalink":"https://linqy71.github.io/tags/Hbase-Bigtable-论文/"}]},{"title":"Redis学习","slug":"Redis学习","date":"2020-07-06T06:10:18.000Z","updated":"2025-02-24T12:08:16.423Z","comments":true,"path":"2020/07/06/Redis学习/","link":"","permalink":"https://linqy71.github.io/2020/07/06/Redis学习/","excerpt":"","text":"了解RedisRedis介绍REmote Dictionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。 Redis特点 Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis支持的数据结构 简单动态字符串 （simple dynamic string SDS） 空间预分配：若SDS长度大于1MB，程序会分配1MB的未使用空间。 惰性空间释放 二进制安全 获取字符串长度为常数复杂度 杜绝缓冲区溢出 链表 字典 跳跃表 整数集合（intset） 不包含重复项 从小到大有序排列 压缩列表（ziplist） 压缩列表是为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序性数据结构 压缩链表可以包含多个节点，每个节点可以保存一个字节数组或整数值。 Redis对象类型 字符串对象 string 列表对象 list 当列表元素较少时，使用压缩列表作为底层实现（所有字符串长度都小于64KB，且元素数量小于512） 当列表元素较多时，使用双端链表作为底层实现 哈希对象 hash 当所有键值对的键和值的字符串长度都小于64KB，且键值对数量小于512时，哈希对象采用压缩列表作为底层实现，每对键值保存在相邻位置。 否则采用hashtable编码，即采用字典作为底层实现，字典的每个键值都是字符串对象。 集合对象 set 当所有元素都是整数值且个数不超过512时，采用intset作为底层实现。 否则采用hashtable编码，即字典作为底层实现，字典的键对应集合中的元素，字典的值全部为NULL 有序集合对象 zset 当所有元素的长度小于64KB且数量小于128个时，采用ziplist作为底层实现 否则采用zset作为底层实现，zset结构同时包含一个字典和一个跳跃表，这两种数据结构通过指针共享相同的元素成员和分值。 Redis的内存回收机制 引用计数机制： 创建一个新对象时，引用计数的值被初始化为1 对象被一个新程序使用时，引用计数值加1 对象不再被一个程序使用时，引用计数值减1 对象的引用计数值为0时，对象所占用的内存会被释放Redis的对象共享机制 Redis中，多个键可以共享同一个值对象： 将数据库的键指针指向一个现有的值对象 并将被共享的值对象的引用计数加1 redis在初始化服务器时会创建一万个字符串对象，包含了从0-9999的所有整数值，当服务器要用到这些字符串对象时直接引用就可以了。 Redis的复制即主从服务器的同步。 旧版复制功能： SYNC命令： 主服务器执行BGSAVE命令生成RDB文件，此过程消耗大量的CPU、内存和磁盘I/O资源 发送RDB文件给从服务器，消耗网络资源 从服务器载入RDB文件时会因为阻塞而无法处理命令请求 新版复制功能： 完整重同步： 初次复制时使用完整重同步，操作与SYNC命令相同。 部分重同步： 用于断线后重新复制的情况 Redis源码探究Redis服务器 server.h: redisServer结构体中含有服务器全局信息的相关属性 server.c/main: 程序创建一个redisServer结构的实例变量 server ， 调用函数 initServerConfig() , 将 server 的各个属性初始化为默认值。 server.c/main: 读入配置文件及参数设置等，打印log server.c/main: 配置完毕后启动aeMain，进入时间循环 ae.c/aeMain: 循环执行aeProcessEvents直到接收到stop信号 ae.c/aeProcessEvents: 调用multiplexing API – aeApiPoll，只有当超时或某些事件被触发时才会返回。 ae_epoll.c/aeApiPoll: 调用epoll_wait接收请求，返回事件数量 ae.c/aeProcessEvents: 根据返回的事件数量处理队列中的事件。一般情况下，首先处理读事件，再处理写事件。 由于采用了I/O多路复用技术，即使有多个连接存在，Redis服务器在处理网络请求时也是单进程单线程的。 优点： 代码更清晰，处理逻辑更简单 不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗 不存在多进程或者多线程导致的切换而消耗CPU 缺点： 无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来完善； （主从服务器如果部署在同一节点上，是否就失去了实用意义？）","categories":[{"name":"源码阅读","slug":"源码阅读","permalink":"https://linqy71.github.io/categories/源码阅读/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://linqy71.github.io/tags/Redis/"}]},{"title":"垃圾回收功耗优化论文阅读","slug":"垃圾回收功耗优化论文阅读","date":"2020-06-29T14:01:27.000Z","updated":"2025-02-24T12:08:16.433Z","comments":true,"path":"2020/06/29/垃圾回收功耗优化论文阅读/","link":"","permalink":"https://linqy71.github.io/2020/06/29/垃圾回收功耗优化论文阅读/","excerpt":"","text":"垃圾回收功耗优化论文阅读1. Heap Compression for Memory-Constrained Java EnvironmentsMS: Mark-SweepMC: Mark-CompactMCC: Mark-Compact-CompressMCL: Mark-Compact-LazyMCCL: Mark-Compact-Compress-Lazy MS: “fregment problem”,即垃圾释放后空间碎片化问题 MC: Mark结束后，将存活对象整理到堆的一侧，另一侧释放后作为完整的空闲区域。 解决上述MS的问题。 缺点：移动了对象，所以对对象的引用(reference)也需要更新。 MCC: 标记存活对象并记录大小，由此得出剩余空间大小 当剩余空间小于请求分配的空间时，压缩存活对象以增加可用空间。 缺点：压缩和解压带来额外开销 MCL： 当一个对象被创建后，实际上用到的可能只有一小部分。 将大对象分解成几个子对象，当子对象遇到第一次写访问的时候才真正被allocated MCCL： MCC和MCL的结合，效果最优。 实现 indirect object reference 在handle pool中创建handle， 每个handle由指向instance的指针和指向class的指针构成。 当handle pool空间用尽时，GC被触发。 当handle pool的剩余空间小于某个阈值时，它会扩大。 压缩 解压缩 将大对象分解 Lazy Allocation. 分解后的子对象直到第一次写访问时才被真正创建。 实验结果 主要对比的是运行过程中堆的使用情况。 MCCL各阶段所花的时间与MC所花时间的对比结果： 激进的对象压缩 原本，只有当compaction不足以提供足够的空闲空间用于分配时，compression才会被触发。 从实验结果看，对于heap memory较小的情况来说，激进的对象压缩能够一定程度减少MCCL原本所花的时间。 去掉handle pool由于handle pool的大小很难确定，所以去掉它会更合适。由此带来的代价是压缩率轻微下降。 相关工作与能耗、GC相关的： Chen et al. [14]，提出能够降低嵌入式Java应用程序能耗的方法。证明了提高GC的频率有助于增加可以放入低功耗操作模式的bank的数量。[14] G. Chen, R. Shetty, M. Kandemir, N. Vijaykrishnan, M. J. Irwin, and M. Wolczko. Tuning garbage collection in an embedded Java environment. In the 8th International Symposium on High-Performance Computer Architecture (HPCA’02), Cambridge, MA, USA, Feb. 2002. 逃逸分析（例如[16]）提供了另一种解决方案，可以减少垃圾收集的负担。具体来说，逃逸分析器确定对象是否可以在堆栈中分配，以及对象是否仅由单个线程访问。这样，当相应的方法返回时，堆中分配的对象可以自动收集，并且可以安全地删除仅由单个线程访问的对象上的同步。Choi等人。[16] 显示出，对于他们的基准测试，多达70%的对象可以在堆栈中分配，11%到92%的锁操作可以安全删除。综上所述，他们观察到了从2%到23%的性能改进。 思路：模仿此文压缩算法，把所有对象压缩以后程序继续执行，经过多次gc后仍保持压缩的对象则放入低功耗内存中。（得先试一下每种负载中到底有多少冷对象） 2. Tuning garbage collection in an embedded Java environment主要思路：shuts off memory banks that do not hold live data. 个人疑问： 模拟器如何实现shut off？ 读后感想：难道是把voltage设为0？ memory energy主要包括 dynamic energy 和 leakage energy when a memory array is referenced or precharged, 动态功耗就会产生。 本文主要解决的是leakage energy。方法：integrated hardware-software strategy. 实现 （疑问：模拟器能够区分RAM和ROM吗？） ROM一旦被激活就不会再关掉，因此它只有在首次引用时才会被激活，从而减少程序执行过程中没有用到的memory banks的leakage energy。 将SRAM划分为banks，根据是否装有存活对象决定是否断电。 datapath energy = execution energy + gc energy gc energy = mark energy + sweep energy + compact energy(if used) memory energy = heap + runtime stack + KVM &amp; class lib(see fig.2) 对SRAM采用的功耗模型与用于cache的模型类似。每个bank的大小以及bank的数量是可调的。 每个bank有三种状态：read/write, active（有存活对象但没有读写操作）, inactive（没有存活对象） read/write 和 active 状态产生动态功耗，inactive状态产生少量静态功耗 能耗特点及优化 A.断电法： 75.6%的heap energy来自leakage 将无用bank断电后，heap energy减少了31%， 90%是因为leakage的减少。 访问断电的bank会带来额外的开销。 提前gc法： 当对象变成垃圾后，在它被回收之前还是会持续产生能耗，因此提高gc的频率可以适当减低能耗，当然需要与gc本身的能耗做平衡。 提高gc频率的策略：k-allocation 每经过k次allocation后就调用一次gc B.调整位置法： 原本对象分配空间不考虑位置，即整个heap使用一个free list。现令每个bank单独维护一个free list，尽量将对象分配在active bank上。即active-bank-first allocation。 Active Bank+：结合了active-bank-first allocation以及当现有的active bank无法满足分配要求时触发gc的策略。 以上，Active Bank+最佳。对比结果： C.Compact 策略： 原本，heap将permanent object放在一个特定区域，现指定几个特定的bank作为这个特定的区域来存放permanent objects。 好处：当新的permanent object创建时无需移动dynamic object。 缺点：当permanent和dynamic对象都存在时需要同时激活至少2个bank。 结果：Active Bank+结合compact策略效果最优。 D.还有一个M&amp;C2：采用Lisp2算法代替KVM中原本的break table-based算法。（break table是更新reference时要用到的）好处：能够处理不同大小的对象，并维持了对象被创建后的顺序，坏处：在每个对象的header中需要添加一个4 byte的指针域。 MC2的好处： 可以根据对象的生命周期移动对象。例如：生命周期相近的对象放到同一个bank中。 更新reference更高效。 E.调整Heap大小以及bank数量： 相关工作 Catthoor et al. [1998], Kandemir et al. [2000], and Vijaykrishnan et al. [2000] ：程序转换可以非常有效地降低以数组为主导的嵌入式应用程序的内存能量 Lebeck et al. and Delaluzetal 提出了基于操作系统和基于编译器/硬件的优化策略，以降低动态功耗 3. Impact of GC Design on Power and Performance for Android主要思路：采用不同的GC策略，观察其对android设备的能耗和性能影响。 CMSCMS: Dalvik Concurrent Mark-Sweep（安卓内部gc） Dalvik GC通常作为C编码的后台守护进程，在自己的本地Linux线程中并发运行，应用程序级Java变异器线程（mutator）也被调度为本地Linux线程 Dalvik的组成部分包括：GC deamon, JIT compiler, signal catcher, main thread, application threads mutator thread: 即application thread CMS在每个collection cycle开始时将所有mutator threads 挂起，扫描heap roots, 然后在mark开始之前恢复被挂起的线程，随后并发进行mark。 当并发的mark阶段结束后，再次将mutator threads挂起，mark剩下的对象…然后恢复挂起的线程，再进行sweep。 targetUtil: 每次GC结束后用来调整heap大小的值 softLimit: 某个阈值 CSB 阈值：softLimit - 某个delta CMS 被触发的条件： allocation 超过CSB阈值，触发background GC allocation 超过softLimit 或 allocation失败， 触发 foreground GC 显式GC，当 System.gc() 被调用时。 Generational CMS generational 即，假定 最近创建的对象有较低的存活概率，将堆分为young和mature两个部分。 Minor GC 将young区域中存活的对象放到mature区域中。 major GC则检测整个区域，包括young 和 mature Gen CMS 即 在 CMS的基础上，将新分配的对象当作young，将GC后存活的对象当作old。 Gen CMS 与 CMS 触发GC的条件相同，只不过被触发的变成了minor GC，而major GC 只有当存活的对象已经超过了softLimit才会被触发。 CMSFly 当CMS进行 mark 操作时，有个stop-the-world阶段，CMSFly则解决这个问题。 当一个mutator thread的root已经被mark之后，CMSFly则立即通知它继续执行(本来是标记完一轮之后才继续执行)。 Concurrency Policies background: 由GC deamon完成 foreground: 由mutator完成，与其他线程并行。 实验结果 增加堆大小并不一定能减少能耗 当GC全部是由GC deamon在后台完成时，能耗增加了。 调整heap 增长策略或并发性能减少能耗。 foreground GC 改善minimum mutator utilization（与响应度相关的指标）。而background和generational策略则更适用于large heap。 不同的GC策略在不同benchmark上的能耗表现如下：(没有绝对更优，取决于benchmark以及系统配置) 相关工作 结合Mark-Sweep Compact和引用计数(An energy efficient garbage collector for Java embeded devices) Tuning garbage collection in an embedded Java environment，即文章2","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://linqy71.github.io/categories/论文阅读/"}],"tags":[{"name":"垃圾回收；功耗优化","slug":"垃圾回收；功耗优化","permalink":"https://linqy71.github.io/tags/垃圾回收；功耗优化/"}]},{"title":"Edge-Computing相关论文-1","slug":"Edge-Computing相关论文-1","date":"2020-06-15T07:36:52.000Z","updated":"2025-02-24T12:08:16.404Z","comments":true,"path":"2020/06/15/Edge-Computing相关论文-1/","link":"","permalink":"https://linqy71.github.io/2020/06/15/Edge-Computing相关论文-1/","excerpt":"","text":"Edge Computing相关论文阅读（一） 主要介绍两篇综述类论文 1. Right-Provisioned IoT Edge Computing: An Overview(Great Lakes Symposium on VLSI 2019 (GLSVLSI’19) ) 作者：Tosiron Adegbija, Roman Lysecky, and Vinu Vijay Kumar Department of Electrical &amp; Computer Engineering, University of Arizona, Tucson, AZ, USA;Google, Mountain View, CA 摘要：物联网（IoT）上的边缘计算是一种越来越流行的范例，其中计算越来越靠近数据源（即边缘设备）。 边缘计算可减轻因响应时间，通信带宽，数据安全性和隐私，能源消耗等增加而导致的基于云计算的开销。但是，鉴于新兴物联网设备的潜在严格资源限制和功能要求，边缘计算绝不能被过度或不足地配置。 在本文中，我们概述了正确配置的IoT边缘计算问题，其中IoT设备配备了“足够”资源，即使在设计时可能没有明确定义“足够”时也是如此。 我们重点介绍了一些研究方向和关键挑战，以实现正确配置的物联网边缘计算。 内容 本文所描述的边缘计算是指在边缘设备上进行计算，区别于MEC（在基站或路由器上进行计算） 正确配置(right-provisioned)是指：既不使得设备性能降低又能合理利用设备资源 正确配置应该是针对系统的，而不是针对应用的，因此获知系统的行为信息十分重要。而大多数物联网设备涉及一些可变性，在运行期间，应用程序、系统输入、目标功能或用户要求可能会发生巨大变化。 定义： under-provisioned: 影响了功能/性能 over-provisioned: 资源过剩 粒度： task specific → application specific → domain specific → general(domain-specific: 提供更好的应用程序灵活性，并且对于执行各种相似应用程序的系统而言更好。) static VS dynamic 大多数IoT设备是静态配置的，需要提前获知整个系统的信息。静态配置适用于只执行单个应用程序或一些已知其先验特征的应用程序。 动态配置能够满足系统在运行过程中发生变化的要求 挑战 HLS(hign-level synthesis) timing-driven low-power right-provisioned：为系统的各个组件选择合适的时钟域和频率，以使组合延迟小于总延迟约束，同时满足功率约束 新兴的HLS方法必须提供形式化设计，合成和优化框架，以支持可精确合成的可精确计时系统模型，从而使各种不同的计算方式具有明确的综合规范 这些新的HLS方法必须能够自动提取与现有的性能驱动的HLS工具/方法无缝集成所需的组件级和系统级综合约束。 新的HLS方法必须支持设计方法，事件驱动的通信以及在给定系统需求和约束的情况下进行自我时钟优化以优化能耗。 计算卸载 为了满足功能需求和系统约束，需要动态计算迁移方案来自适应地确定必须执行的计算。（协调计算开销与卸载开销） threat detection Energy efficiency adaptive memories 2. Cost-Aware Cloudlet Placement in Edge Computing Systems摘要边缘计算中的一项众所周知的挑战是战略性放置小云。 这项挑战的基本目标是最大程度地降低部署成本，并确保边缘服务用户的延迟最小。 我们通过设计一种可感知成本的Cloudlet放置方法来解决此挑战，该方法可将用户应用程序完全映射到适当的Cloudlet，同时确保其延迟要求。 我们通过基于纽约市OpenData进行广泛的实验来研究我们提出的方法的有效性。 结果表明，我们的方法获得了接近最佳成本的解决方案，并且大大减少了执行时间。 3. On Multi-Access Edge Computing: A Survey of the Emerging 5G Network Edge Cloud Architecture and Orchestration（IEEE Communications Surveys &amp; Tutorials） 摘要多访问边缘计算（MEC）是一个新兴的生态系统，旨在融合电信和IT服务，在无线电访问网络的边缘提供一个云计算平台。 MEC在边缘提供存储和计算资源，从而减少了移动最终用户的等待时间，并更有效地利用了移动回程和核心网络。 本文介绍了有关MEC的调查，重点介绍了基本的关键支持技术。 它在考虑单个服务和支持移动性的MEC平台网络的情况下精心设计了MEC编排，从而为不同的编排部署选项带来了光明。 此外，本文分析了MEC参考体系结构和主要部署方案，这些方案为应用程序开发人员，内容提供商和第三方提供了多租户支持。 最后，本文概述了当前的标准化活动，并进一步阐述了开放研究的挑战。 内容MEC usecases and applications 计算卸载 energy consumption code partitioning RAN awareness ( Gaining information on the RAN quality and user context before performing ofﬂoading can assist both the device and the network to make the best out of the MEC platform services ) 分布式内容交付与缓存 context awareness pre-caching popularity prediction web性能增强 content optimization (content awareness) accelerated browsing web acceleration: adapting the content size dynamically IoT和大数据 data aggregation and big data analytics 智能城市服务 应用感知与内容优化 MEC enabling technologies cloud computing 私有云、公有云等技术模型 Iaas、Paas、SaaS等服务模型 VMs and Containers NFV SDN By decoupling the control plane from the data plane and through the use of common APIs, SDN introduces a logical centralized control, which can easily instantiate and offer virtual network instances, by abstracting the underlying network infrastructure. Network SlicingIt consists in slicing one network into multiple instances, each architected and optimized for a speciﬁc requirement and/or speciﬁc application/service MEC FrameWork and architecture MEC service and orchestrationorchestration 包含这些属性： Resource allocation Service placement Edge selection Reliability Service mobility VM migration Joint optimization of VNFs and MEC services MEC deployment issues in mobile networks Orchestration Deployment Options Open-O: 由Linux Foundation支持的一个开源项目，该项目建立了运营商级的编排平台，以跨虚拟的SDN / NFV基础架构和旧版网络提供端到端的组合服务。 OPEN-O实现了灵活性，支持多域和多位置，并通过自动化提高了服务生命周期。它还通过三个业务流程模块的层次结构缩短了上市时间，从而加快了创新速度。这种编排层次结构由（i）启用端到端服务组合和交付的Global Service Orchestrator，（ii）负责NFV编排的NFV-O组成，其中考虑了范围广泛的VNFM和VIM中的各种VNF，以及（iii ）SDNOrchestrator，它通过不同的SDN控制器（例如OpenDaylight和ONOS）和/或传统的元素管理系统来提供网络连接和流量控制。 Open-O采用TOSCA，YANG数据模型，REST API，OpenStack，并通过各种SDN，NFV和旧版网络支持资源抽象，从而提供包括策略管理，安全性和其他管理功能在内的一组通用服务. ECOMP: 该项目最初由AT＆T发起，后来移交给Linux Foundation。它专注于VNF管理和提供以软件为中心的网络功能，并利用云技术和网络虚拟化的优势提供自动化服务。 ECOMP定义了一个负责自动化端到端服务实例的主服务协调器，它与三种不同的Controller类型（即通常在云层内的基础结构控制器，网络控制器和应用程序控制器）进行交互。编排自动化配置过程，可编程性规则和由策略驱动的操作管理，考虑到网络数据和面向服务的分析，在实例化，修改和终止网络，应用程序或基础架构服务和资源方面实现了灵活性。 ECOMP扩展了ETSI MANO的范围，引入了资源控制器和策略组件的概念以及资源描述的概念，即元数据，用于虚拟环境的生命周期管理，从而实现了网络的敏捷性和弹性，同时缩短了时间，市场。为此，ECOMP支持开放云标准（例如OpenStack，OPNFV和TOSCA），并遵循Netconf，Yang配置和管理模型以及REST-API。 Open Network Automation Platform (ONAP) : Open-O与ECOMP合并。 《边缘计算开源平台现状分析》面向物联网端：EdgeXfoundry、ApacheEdgent面向边缘云：CORD、Akraino EdgeStack面向云边融合：Azure IoT Edge面向构建边缘计算平台： 网络管理：ONAP 容器技术：Docker 云平台： OpenStack 人工智能技术：Acumos Lessions learned and research challenges MEC Service Orchestration and Programmability MEC Service Continuity and Mobility Service enhancements: QoE and Resiliency MEC Security and Privacy MEC Service Monetization 结论MEC是一项新兴技术，它通过网络提出了边缘云计算的技术优势，并支持多租户，允许第三方通过标准化API按需提供应用程序和服务。 MEC使无线电和网络层对应用程序提供商/开发人员可见，从而在QoE上提供了一系列新的进步。 MEC被认为是5G系统的关键新兴技术之一，这归功于它对回程和核心网络中的低延迟保证和容量增强的显着贡献。 MEC的成功从根本上取决于技术与ETSI NFV ISG的一致性，以在服务弹性和生命周期管理，服务移动性以及与网络资源的联合优化方面正确定义管理和协调系统。目前，MEC提出了一系列尚未解决的挑战。但是，考虑到其潜力，很明显，MEC将极大地提升移动通信的形态和体验。 下一步进一步了解相关开源项目研究内容，结合所了解的边缘计算方向挑战，寻找可入手的点。","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://linqy71.github.io/categories/论文阅读/"}],"tags":[{"name":"Edge Computing;","slug":"Edge-Computing","permalink":"https://linqy71.github.io/tags/Edge-Computing/"}]},{"title":"service-placement相关文章","slug":"service-placement相关文章","date":"2020-06-08T07:54:11.000Z","updated":"2025-02-24T12:08:16.429Z","comments":true,"path":"2020/06/08/service-placement相关文章/","link":"","permalink":"https://linqy71.github.io/2020/06/08/service-placement相关文章/","excerpt":"","text":"service-placement相关文章 无头苍蝇似的在各种顶会上寻找研究方向，在浏览了许多论文之后总觉得杂乱无章，收获甚少。终于发现一个较为感兴趣的方向，即service placement 服务放置问题。对这个问题甚是陌生，希望能从找到的这些文章中整理出一些思路。 顶会论文简介 论文 类型 研究内容 1 算法类 service placement + request scheduling 2 算法类 service placement + request routing 3 算法类 service placement ， user mobility 4 算法类 VNF placement ， budget &amp; capacity constraint 5 算法类 ML job placement ，interference 6 算法类 SFC placement ，throughput 7 算法类 DAG placement 8 算法类 application component placement INFOCOM20191. Service Placement and Request Scheduling for Data-intensive Applications in Edge Clouds作者Vajiheh Farhadi, Fidan Mehmeti, Ting He, Tom La Porta, Hana Khamfroush, Shiqiang Wang, Kevin S Chan Pennsylvania State University, University of Kentucky, IBM, ARL 摘要移动边缘计算使无线用户可以利用云计算的功能而不会造成较大的通信延迟。为了从边缘服务于数据密集型应用程序（例如增强现实，视频分析），除了需要CPU周期和用于计算的内存外，我们还需要用于存储服务器数据的存储资源和用于接收用户提供的数据的网络带宽。此外，在考虑系统稳定性和运营成本的同时，需要随时间调整数据放置以适应随时间变化的需求。我们通过提出一个两阶段规模的框架来解决此问题，该框架在存储，通信，计算和预算约束下共同优化服务（数据和代码）放置和请求调度。通过分析各种情况的难度，我们可以充分说明问题的复杂性。通过将问题转化为集合函数优化，我们开发了多项式时间算法，该算法在某些条件下可实现恒定因子近似。大量的综合和跟踪驱动的仿真表明，该算法可实现90％的最佳性能。 一些概念 shared resource pool 共享资源池： 服务迁移需要考虑service performance和migration cost之间的平衡。当某些边缘节点负载较重时，考虑使用非离用户最近的边缘节点。因此，标准化的开放式边缘计算环境应运而生，使同一地理环境内的边缘云形成一个共享资源池。 request scheduling 请求调度： 探究用户请求应调度到哪个服务器上以使得一些参数（例如 cost、completion time）最优的问题。 它决定是否/在何处调度每个请求，考虑通信、边缘云的计算能力以及其他限制。 service placement 服务放置： 它决定如何在每个边缘云的存储容量内复制和放置每个服务（包括服务器代码和数据） 本文工作我们共同考虑数据密集型应用程序的服务放置和请求调度。 与[20]相比，我们将两个决策的时间尺度分开：服务放置发生在较大的范围（frames）以防止系统不稳定，而请求调度发生在较小的尺度（slots）以支持实时服务。 由于服务复制/迁移，我们还施加了预算约束来控制运营成本。 这些更改可在重新配置的成本和服务请求的性能之间实现可控的权衡，同时在根本的优化问题中引发关键的更改。 2. Joint Service Placement and Request Routing in Multi-cell Mobile Edge Computing Networks作者Konstantinos Poularakis, Jaime Llorca, Antonia M. Tulino, Ian Taylor, and Leandros Tassiulas Department of Electrical Engineering and Institute for Network Science, Yale University, USANokia Bell Labs, USADepartment of Electrical Engineering and Information Technologies, University of Naples Federico II, ItalySchool of Computer Science and Informatics, Cardiff University, UK 摘要诸如增强现实，网络游戏和自动驾驶等创新移动服务的激增，刺激了人们对低延迟访问计算资源的需求日益增长，而这些延迟只能通过现有的集中式云系统无法满足。通过支持在最终用户附近的网络外围执行计算任务，移动边缘计算（MEC）有望成为满足低延迟服务需求的有效解决方案。尽管许多最新研究已经解决了确定服务任务的执行以及将用户请求路由到相应边缘服务器的问题，但重点主要放在高效利用计算资源上，而忽略了这样一个事实：需要存储数据以启用服务执行，并且许多新兴服务表现出不对称的带宽要求。为了填补这一空白，我们研究了在具有多维（存储-计算-通信）约束的支持MEC的mmulti-cell网络中，服务放置和请求路由的联合优化。我们表明，该问题概括了文献中的几个问题，并提出了一种使用随机舍入实现接近最佳性能的算法。评估结果表明，我们的方法可以有效利用可用资源，以最大程度地减少低延迟边缘云服务器所服务的请求数量。 一些概念 面对的挑战： allocation of computation resources non-trival amout of data to be prestored at BS communication requirements of services(不对称的双向通信，占用无线基站上行链路和下行链路带宽容量的不同部分) 3. Adaptive User-managed Service Placement for Mobile Edge Computing: An Online Learning Approach作者Tao Ouyang, Rui Li, Xu Chen, Zhi Zhou, Xin Tang School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China 摘要设想为云扩展的移动边缘计算（MEC）将云资源从网络核心推送到网络边缘，从而满足许多新兴的计算密集型移动应用程序的严格服务要求。现有的许多工作都集中在研究系统范围内的MEC服务放置问题，个性化服务性能优化而受到的关注较少。因此，在本文中，我们提出了一种新颖的自适应用户管理的服务放置机制，该机制可以联合优化用户的感知潜伏期和服务迁移成本，并通过用户偏好进行加权。为了克服未来信息的不可用和未知的系统动力学问题，我们将动态服务放置问题公式化为a contextual multiarmed bandit (MAB) 问题，然后提出一种基于汤普森采样的在线学习算法来探索动态MEC环境，进一步协助用户做出自适应服务放置决策。严格的理论分析和广泛的评估证明了所提出的自适应用户管理的服务放置机制的优越性能。 4. Joint Placement and Allocation of Virtual Network Functions with Budget and Capacity Constraints作者Gamal Sallam and Bo Ji Department of Computer and Information Sciences, Temple University, Philadelphia, PA, U 摘要随着网络功能虚拟化（NFV）的出现，传统上可以在专用硬件上运行的网络服务现在可以使用托管在通用商品硬件上的虚拟网络功能（VNF）来实现。这种新的网络范例为网络服务提供商（ISP）提供了极大的灵活性，可以有效地操作其网络（收集网络统计信息，执行管理策略等）。但是，引入NFV要求进行投资以将VNF部署在某些网络节点（称为VNF节点）上，这必须考虑实际的限制，例如部署预算和VNF节点容量。为此，重要的是设计一个联合的VNF节点放置和容量分配算法，该算法可以在尊重此类实际约束的同时，最大化VNF节点完全处理的网络流量总量。与通常忽略预算约束或能力约束的大多数先前工作相反，我们明确考虑了两者。我们证明，考虑这些约束会带来一些新的挑战。具体而言，我们证明了所研究的问题不仅是NP难的，而且是非亚模的。为了解决这些挑战，我们引入了一种新颖的松弛方法，以使松弛放置子问题的目标函数变为亚模。利用这种有用的子模性质，我们提出了两种算法，它们分别对原始的非松弛问题实现了1/2（1-1 / e）和1/3（1-1 / e）的近似比。最后，我们使用跟踪驱动的仿真和基于综合网络设置的仿真，通过广泛的评估来证实所提出算法的有效性。 5. Deep Learning-based Job Placement in Distributed Machine Learning Clusters作者Yixin Bao, Yanghua Peng, Chuan Wu Department of Computer Science, The University of Hong Kong 摘要生产机器学习（ML）集群通常托管各种分布式ML工作负载，例如语音识别，机器翻译。虽然作业之间的服务器共享可以提高资源利用率，但是位于同一地点的ML作业之间的干扰会导致性能严重下降。现有的群集调度程序（例如，Mesos）在其工作位置上是无干扰的，从而导致资源效率不佳。文献中已经研究了具有干扰意识的工作位置，但是使用详细的工作量分析和干扰建模进行了处理，这不是一般的解决方案。本文介绍了Harmony，这是一种深度学习驱动的ML群集调度程序，它以最小化干扰和最大化性能（即训练完成时间）的方式放置训练作业。Harmony基于精心设计的深度强化学习（DRL）框架，并补充了奖励建模。 DRL采用最先进的技术来稳定训练并提高收敛性，其中包括演员批评算法，作业意识动作空间探索和体验重播。鉴于通常缺乏对应于不同安置决策的奖励样本，我们建立了一个辅助奖励预测模型，该模型使用历史样本进行训练，并用于为看不见的安置产生奖励。在由6个GPU服务器组成的Kubernetes集群中使用实际ML工作负载进行的实验表明，就平均作业完成时间而言，Harmony的性能比典型的调度程序高25％。 一些概念 本文所描述的interference：创建在同一server上的不同类型的ML jobs，例如CPU-intensive, I/O intensive, network bandwith-intensive, 由于底层资源的共享而导致的干扰。 6. Octans: Optimal Placement of Service Function Chains in Many-Core Systems作者Zhilong Zheng, Jun Bi, Heng Yu, Haiping Wang, Chen Sun, Hongxin Hu, Jianping Wu Institute for Network Sciences and Cyberspace, Tsinghua UniversityDepartment of Computer Science, Tsinghua UniversityBeijing National Research Center for Information Science and TechnologySchool of Computing, Clemson University 摘要网络功能虚拟化（NFV）可以通过在具有多个核心的商用服务器上运行服务功能链（SFC），来提供服务交付灵活性并降低总体成本。用于将SFC放置在一台服务器中的现有解决方案将所有CPU内核视为相等，并将隔离的CPU内核分配给不同的网络功能（NF）。但是，高级服务器通常采用非统一内存访问（NUMA）架构来提高多核系统的可伸缩性。 CPU内核分为多个节点，由于跨节点内存访问和节点内资源争用而导致性能瓶颈。我们的评估表明，与最佳放置解决方案相比，随机选择将NF放置在SFC中的核心可能会降低39.2％的吞吐量。在本文中，我们提出了Octan，它是NFV协调器，可在多核系统中实现所有SFC的最大总吞吐量。 Octans首先将优化问题表述为非线性整数规划（NLIP）模型。然后，我们确定解决问题的关键因素是评估同一SFC或不同SFC中其他NF导致的NF吞吐量下降，即性能下降指数，并基于系统级性能指标提出正式而精确的预测模型。最后，我们提出了一种有效的启发式算法来快速找到接近最佳的放置解决方案。我们已经实现了Octans的原型。广泛的评估表明，与两种最先进的放置机制相比，Octan显着提高了总吞吐量26.7％〜51.8％，SFC性能的预测误差非常低（平均偏差为2.6％）。而且，Octans可以快速找到具有最佳间隙（1.2％〜3.5％）的接近最佳的放置解决方案。 一些概念 NFV 网络功能虚拟化：对传统在专有硬件上运行的网络服务（例如路由器、防火墙和负载平衡器）进行虚拟化的方法。这些服务被打包为商用硬件上的虚拟机（VM），这样服务提供商便可以在标准服务器（而非专有服务器）上运行其网络。 SFC 服务功能链：网络包以network functions sequence的形式被处理，从而形成SFC。 挑战现有解决方案将所有CPU内核视为相等，将隔离的CPU内核分配给不同的网络功能。 随机选择支持SFC的CPU内核可能会严重损害吞吐量：（一个节点由多个CPU cores组成） 跨节点内存访问引起的吞吐量瓶颈 节点内资源争用 本文工作 用非线性整数编程模型解决问题 为了评估由于资源争用和链接而导致的性能下降指标，我们引入了一种正式的方法来查找性能指标，并提出了一种用于性能下降预测的准确模型。 SEC7. Linearize, Predict and Place: Minimizing the Makespan for Edge-based Stream Processing of Directed Acyclic Graphs （2019）作者Shweta Khare, Hongyang Sun, Julien Gascon-Samson, Kaiwen Zhang, Aniruddha Gokhale, Yogesh Barve, Anirban Bhattacharjee, and Xenofon Koutsoukos. 摘要在诸如智能电网之类的网络物理系统中发现的许多物联网应用，都必须对关键事件（例如供需不匹配）采取控制措施，这需要对流数据进行低延迟处理以进行快速事件检测和异常纠正。这些流应用程序通常采用有向非循环图（DAG）的形式，其中顶点表示运算符，边表示这些运算符之间的数据流。边缘计算由于能够在数据源附近提供低延迟处理的能力而作为一种很容易满足延迟关键的物联网应用程序需求的方法，最近引起了广泛的关注。为了获得边缘计算的好处，这些应用程序的组成运营商必须以一种合理的方式放置，通过权衡运营商之间的通信成本与由于运营商在同一资源受限的边缘上的同一地点而产生的干扰成本。为了解决这些挑战并大幅简化任意大小和拓扑的DAG的放置问题，我们提出了一种算法，该算法首先将任意流处理DAG转换为一组近似的线性链。随后，用于共处一地的线性链的数据驱动的等待时间预测模型用于通知操作员的位置，以使定义为DAG中所有路径的最大等待时间的延展时间最小化。我们使用Beagle Bone集群上代表边缘计算环境的各种DAG放置方案，通过经验评估我们的算法。 (DAG placement) 8. Efficient placement of multi-component applications in edge computing systems （2017）作者Tayebeh Bahreini and Daniel Grosu Dept. of Computer Science, Wayne State University 摘要移动边缘计算（MEC）是一种新的范例，已被引入以解决移动云计算技术的低效率问题。 MEC背后的关键思想是通过将应用程序的计算转发到网络边缘而不是云数据中心来增强移动设备的功能。 MEC的主要挑战之一是确定移动应用程序组件在边缘服务器上的有效放置，从而最大程度地减少运行应用程序时产生的成本。在本文中，我们通过设计一种有效的启发式在线算法来解决边缘计算中的多组件应用程序放置问题。我们还提出了考虑到用户位置和网络功能的动态特性的多组件应用程序放置问题的混合整数线性规划公式。我们进行了广泛的实验，以评估该算法的性能。实验结果表明，该算法执行时间极短，并获得了最佳解。 一些概念 challenging issues in MEC：用户移动性导致的应用组件放置问题 application graphs: 节点表示应用组件 application placement problem：可以视为两种图之间的映射问题 本文工作 将多组件应用程序放置问题的onine版本公式化为混合整数线性程序（MILP） 基于简单算法技术（例如匹配和局部搜索）的算法，并避免使用复杂的方法（例如基于马尔可夫决策过程的方法） 算法设计的主要思想是确定应用程序组件与边缘/核心服务器之间的最佳匹配，而无需考虑组件之间的通信需求，然后考虑组件之间的通信需求并使用本地搜索过程改善解决方案 总结 service placement问题是指考虑如何在每个边缘云的存储容量内复制和放置每个服务的问题。 挑战： 通常考虑优化服务器在storage、computation、communication方面的资源限制，以及用户的移动性 由于在同一资源受限的edge server上部署不同的service而导致的问题 最新研究 与请求调度、网络功能虚拟化（NFV）结合进行研究","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://linqy71.github.io/categories/论文阅读/"}],"tags":[{"name":"service placement; Edge;","slug":"service-placement-Edge","permalink":"https://linqy71.github.io/tags/service-placement-Edge/"}]},{"title":"微信小程序--入门与踩坑","slug":"wechat-project-summary","date":"2019-06-29T11:12:04.000Z","updated":"2025-02-24T12:08:16.431Z","comments":true,"path":"2019/06/29/wechat-project-summary/","link":"","permalink":"https://linqy71.github.io/2019/06/29/wechat-project-summary/","excerpt":"","text":"微信小程序入门微信小程序的官方文档提供了非常详细、完整的描述，为入门提供了很好的指导。 微信小程序指南 微信小程序组件 还有API、框架等文档也在同一个目录下。 组件分享微信小程序的实现与web网页的实现非常像，但是微信更加便捷，因为它提供了很多封装好的组件，下面介绍一些对于初学者来说觉得挺好用的组件。 1. 分页，tabbar： 小程序整体的标签页在app.json中设置即可，默认标签位置在页面底部，color设置标签颜色，selectedColor设置被选中标签颜色，list设置标签内容及对应路径： 2. 从底部弹起的滚动选择器，picker： 官方文档 除了普通选择器和多列选择器，官方还提供了时间、日期、省市区选择器，真的方便又快捷，感恩。 关于这部分就不再赘述，想起来再补充，基本上你需要的控件微信官方都有提供，在文档上一搜就有了。 样式分享，强推 WeUIWeUI是一套同微信原生视觉体验一致的基础样式库,由微信官方设计团队为微信内网页和微信小程序量身设计,令用户的使用感知更加统一。 首先，微信小程序搜索 “WeUI”, 进入之后页面如下： 小程序提供了很多样例，这些样例都是符合微信小程序设计指南的，简洁又美观，具有微信的特色。这些只是样例，我们可以依照这些样例进行页面设计，同时WeUI也提供了这些样例对应的代码，给我们太提供了很方便的学习案例。 下面介绍使用方法： 首先，去github下载WeUI代码 在自己的微信小程序项目中引入样式文件，可直接引用dist/style/weui.wxss，或者单独引用dist/style/widget下的组件的wxss 若不知道如何使用样式文件，dist/example/下的代码即是WeUI提供的样例的具体实现。 一些坑和技巧微信小程序其实坑很少，项目经历的时间有点长，很多也已经忘记了，这里替一些还有些许印象的坑坑。 console.log()console.log()可以在调试面板中打印日志，反正找bug我基本就靠这个了，根据查看不同位置的输出看与设想的符不符合来找到出错位置，但是有一天，它反过来摆了我一道。 事情是这样的，我在位置1打印了对象A的值，然后改变对象A的值为A’，然后在位置2再次打印对象A，结果位置1打印出来的值居然是改变后的A’，所以我一直以为是位置1之前的代码出了问题，花了很长的事件都没找出来。 事实上，js并不像C语言那样是严格地从上往下执行的。具体js代码的执行顺序可以参考这篇博客 Promise如何确保for循环执行完之后再执行某个promise？ 举个例子： (个人理解，欢迎指教)在getByCourseId返回时，then用来处理成功返回值，此时相当于在一个新开的线程里面执行then里面的代码，在单一的线程里面代码是按顺序执行的，所以在用foreach完成对res的处理之后，下一个promise操作才会被执行。之所以采用return是为了防止多层promise嵌套，提高代码可读性。 如何一次执行多个Promise？ 还是这个例子： 其中，蓝色框是一个promise操作，红色框是将promise操作存放到一个数组里。 最重要的步骤是这个： Promise.all可以将多个Promise实例包装成一个新的Promise实例，在等待多个异步操作返回结果后再执行下一步时非常有用。","categories":[{"name":"coding","slug":"coding","permalink":"https://linqy71.github.io/categories/coding/"}],"tags":[{"name":"微信小程序","slug":"微信小程序","permalink":"https://linqy71.github.io/tags/微信小程序/"}]},{"title":"MoneyDodo-项目管理总结","slug":"MoneyDodo-project-summary","date":"2019-06-29T07:57:10.000Z","updated":"2025-02-24T12:08:16.417Z","comments":true,"path":"2019/06/29/MoneyDodo-project-summary/","link":"","permalink":"https://linqy71.github.io/2019/06/29/MoneyDodo-project-summary/","excerpt":"","text":"本篇博客是关于课程大作业–“MoneyDodo”项目的项目管理总结，介绍一些项目中的收获。感谢我的组员们在初次开会的时候给我提供了作为项目经理的宝贵机会。 1. 关于团队组建与成员分工首先，我们发现线下面对面的交流相比于线上的交流效率会高很多，所以我们团队7个人采用线下开会的方法，一共进行了4次小组会议，来讨论成员分工以及一些设计的细节。 关于成员的分工，我们充分考虑了每个成员的长处，尽量为成员们分配擅长的工作，例如有的同学修过“服务计算”这门课程，比较适合后端开发，而有的同学没有，又比如团队中的女成员对于UI界面具有更优的美感，所以安排她们进行UI设计和前端开发。当然，因为是学生阶段的课程项目，有的成员希望接触一些新的领域来拓展自己的技能，现学现用也未尝不可，所以结合成员们的长处和意见，最终确定了成员的角色分配，在项目初期就完成了前后端的分离。 2. 关于每次会议的经验总结我们采用线下的会议，第一次的会议主要是确定角色和分工，每个人都到场并积极参与讨论，我觉得这是作为一名团队成员应有的素质，而不是出席会议却不参与讨论，静静坐在一旁。关于会议参与度我觉得我们团队每个人都非常好。 当然，会议肯定需要有人主持，一般来说，项目经理需要承担这个工作，而且需要有人进行会议记录，以便后续的回顾和总结。我们以轮流的方式进行会议记录，每场会议由不同的人进行记录和总结，减轻负担。而项目经理在每次会议需要做的工作主要有： 确认前端和后端的工作成果和进度，若进度与计划不符，则要及时分析原因，并及时对计划作出调整。我们团队在进度方面做得还是比较好的，特别是后端，进度相当快，为前端提供了很多便利。 细化下一轮迭代的工作内容。因为我在一开始为团队编写了迭代周期的框架，我们后续的工作是按照这个框架开展的，我们将项目大致划分为三轮迭代，每次迭代完成一定的工作内容。因此我们每次开会需要细化每一轮迭代的工作内容，包括需求分析和设计，前端主要工作及分工，后端主要工作及分工。 3. 关于沟通方式在项目的实现过程中，完成不同功能模块、前端与后端的人员需要进行大量的沟通，以便进行不同功能模块的合并或连接以及前后端的衔接，因此，一种有效的沟通方式能够减少沟通成本，提高沟通效率，从而推进项目的进度，减少成员负担。我们主要采用两种沟通方式： 可视化图形结构 文档 可视化图形结构主要用于前期的需求分析与设计，各种UML图帮了很大的忙。项目前期阶段我们使用Umlet绘制了用例图、活动图、领域模型、状态模型等图，使用modao工具设计了UI界面图，这些图代替语言，让成员们更好地理解，后续工作的开展也是按照这些图进行的，保证了项目朝着正确的方向进展。 前后端的数据主要是通过API交互的，而如何使用后端编写的API已经通过API文档详细描述了，所以前端工程师只需要依靠一个API文档，就能顺利开展相应的工作，省去了与后端人员沟通的很多麻烦。 PM个人总结与反思首先，本次的项目是我真正意义上的第一个团队项目，一开始就从团队的角度出发。以往的项目大多是个人独立完成的，即使是小组，成员间的工作也较为分散，通常是各做各的，缺少沟通和合作，而且也没有总体的规划，常常是脑子里想到什么就开始写代码了，这样会导致代码结构混乱，写代码的效率低下，修改代码所花费的时间较多，而且常常由于沟通不够导致衔接出现问题，或者是重点方向出现偏差，最终需要重写代码等问题。而本次的项目不是从写代码入手的，而是从人员的分工开始，每个人以自己擅长的领域着手，前端或后台，分工明确。 第一次尝试项目经理这个角色，对团队合作有了更进一步的了解。其实团队合作是需要靠人指挥和带动的，否则成员可能会出现怠惰的现象，一拖再拖，而项目经理就是起到这样的作用，规划项目的进度，监督成员们的工作，促进成员间的交流合作。作为项目经理，我并没有完全尽到相应的责任，中间有段时间忽略了项目的进展，项目的进度停滞了2-3个星期，导致项目最终的成果与预期有部分偏差，这是我需要反思的地方。 总体来说，我觉得我们小组的成员为了这个项目都付出了很多工作，最终看到项目的成果我也觉得很有成就感，通过这个项目我学会了很多，带给我的经验也是非常有用的。感谢所有同伴及老师的帮助。","categories":[{"name":"项目管理","slug":"项目管理","permalink":"https://linqy71.github.io/categories/项目管理/"}],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"https://linqy71.github.io/tags/项目管理/"}]},{"title":"系分项目-个人小结","slug":"swsad-final-report","date":"2019-06-29T06:30:37.000Z","updated":"2025-02-24T12:08:16.429Z","comments":true,"path":"2019/06/29/swsad-final-report/","link":"","permalink":"https://linqy71.github.io/2019/06/29/swsad-final-report/","excerpt":"","text":"1. 个人小结首先，作为团队的项目经理和前端成员，我帮助团队完成了写文档、画图、确定需求、管理团队、前端代码编写等工作。 总的来说，我们团队成功实现了项目的基本需求，但是与最初的计划有些许的偏差，这是我作为项目经理的失职。但是尽管我们后期有点懈怠了，我们还是在中期完成了大部分的工作，项目的进度也是持续的，迭代周期一和迭代周期二按时完成，迭代周期三拖了一点时间但也完成了。 下面介绍我的成果 1.管理： 集合人员，为成员合理分配角色，让前后端分离。这是大家开会共同讨论的结果: 团队与分工 编写迭代周期，监督大家根据迭代周期保证产出。迭代周期 2. 分析： 需求分析：包括设计用例以及绘制活动图 3. 开发： 实现了小程序端的发布任务和任务详情的界面及功能 通过前端调用帮助测试后端API，并为后端提出一些逻辑上的缺陷以及数据库字段的完善意见。 PSP2.1 统计 PSP阶段 耗时(h) 计划 5 预估任务完成的时间 5 开发 100 需求分析 10 生成设计文档 10 设计复审 0 代码规范 0 具体设计 10 具体编码 60 代码复审 0 测试 10 报告 7 测试报告 0 计算工作量 2 总结&amp;过程改进计划 5 合计 112 主要工作清单 最有苦劳的工作：关于发布任务功能的实现，需要与后端交互，而且整个项目最核心的也是这个任务管理系统，因此它涉及到了各个系统API的调用包括用户管理系统、任务管理系统、交易管理系统等。在实现功能的过程中，发现了后端API涉及的逻辑缺陷、数据库字段缺陷以及一些测试漏掉的功能缺陷等。需要与后端沟通，并等待后端修改，才能进行下一步的测试和编写，耗费的时间最长。 个人git总结1. Dashboard文档 2. 小程序端代码 个人博客清单 微信小程序–入门与踩坑 MoneyDodo-项目管理总结 特别鸣谢 感谢linshk同学前端后端两头跑，承担起了前端后端大部分的衔接工作，而且完成了前端40%的工作，并且以自己的小程序项目经验带动了小程序端工作的顺利进行，没有linshk同学，另外两个前端工程师可能要在泥潭里挣扎很久。 感谢liuyh同学作为后端的负责人，积极与前端进行沟通并及时解决存在的问题。 感谢liuwd同学独自一人承担起了web前端的所有工作。 感谢几次会议进行会议记录的朋友，替PM分担了好多工作。 感谢每次会议都不缺席的全体组员。","categories":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/categories/系统分析与设计/"}],"tags":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/tags/系统分析与设计/"}]},{"title":"系统分析与设计-HW5","slug":"系统分析与设计-HW5","date":"2019-05-25T06:09:27.000Z","updated":"2025-02-24T12:08:16.435Z","comments":true,"path":"2019/05/25/系统分析与设计-HW5/","link":"","permalink":"https://linqy71.github.io/2019/05/25/系统分析与设计-HW5/","excerpt":"","text":"HW5使用 UMLet 建模：根据订旅馆建模文档，Asg-RH.pdf：绘制用例图模型（到子用例） 给出 make reservation 用例的活动图 根据课程练习“投递员使用投递箱给收件人快递包裹”的业务场景分别用多泳道图建模三个场景的业务过程 场景一：x科技公司发明了投递柜，它们自建了投递柜以及远程控制系统。注册的投递员在推广期免费使用投递柜。由于缺乏资源，仅能使用y移动平台向客户发送短信通知。 场景二：随着产品推广，x公司与各大快递z公司达成协议。x公司在快递柜上添加了二维码扫描装置，z公司的快递员不仅可在快递柜上登陆（由z公司提供认证服务），且可扫描快递单号，投递入柜后自动由z公司发短信给客户。客户取件后，自动发送给z公司投递完成。 场景三：x公司进一步优化服务，开发了微信小程序实现扫码取快递。如果用户关注了该公司公众号，直接通过过公众号推送给用户取件码等信息。不再发送短信。 根据上述流程，给出快递柜系统最终的用例图模型 用正常色彩表示第一个业务流程反映的用例 用绿色背景表述第二个业务场景添加或修改的用例，以及支持 Actor 用黄色背景表述第三个业务场景添加或修改的用例，以及支持 Actor","categories":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/categories/系统分析与设计/"}],"tags":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/tags/系统分析与设计/"}]},{"title":"系统分析与设计-HW4","slug":"系统分析与设计-HW4","date":"2019-05-23T06:20:41.000Z","updated":"2025-02-24T12:08:16.434Z","comments":true,"path":"2019/05/23/系统分析与设计-HW4/","link":"","permalink":"https://linqy71.github.io/2019/05/23/系统分析与设计-HW4/","excerpt":"","text":"HW4简答题 用例的概念 Use case is a collection of related success and failure scenarios that describe an actor using a system to support a goal. 用例和场景的关系？什么是主场景或 happy path？ Scenario is a specific sequence of actions andinteractions between actors and the system; it is also called a usecase instance. A use case represents a collection of scenarios. The primary scenario（主场景／基本流） corresponds to the main system interactions, usually the ‘success’ scenario. 用例有哪些形式？ Three Common Use Case Formats : Brief, Casual, Fully 对于复杂业务，为什么编制完整用例非常难？ 复杂业务设计的场景较多 什么是用例图？ 用例图是指由参与者（Actor）、用例（Use Case），边界以及它们之间的关系构成的用于描述系统功能的视图。 用例图的基本符号与元素？ 用例图包含六个基本元素：参与者(Actor)、用例(Use Case)、关联关系(Association)、包含关系(Include)、扩展关系(Extend)以及泛化关系(Generalization) 用例图的画法与步骤 确定参与者：在获取用例前首先要确定系统的参与者 识别用例：特定参与者希望系统提供什么功能，由哪个参与者触发、当系统改变状态时，是否通知参与者、是否存在影响系统的外部事件等。一般以动词开头描述某件事情。 确定用例间关系：确定用例间的关联关系、包含关系、扩展关系、泛化关系 识别外部系统和服务 用例图给利益相关人与开发者的价值有哪些？ 合理的用例识别（制作的用例图），通常给团队带来以下利益： 明确系统的业务范围、服务对象（角色）、外部系统与设备； 帮助识别技术风险，提前实施关键技术原型公关与学习； 易于评估项目工作量，合理规划迭代周期，规划人力需要； 用例图能够让利益相关人更直观地了解到系统所能带来的好处 建模练习题（用例模型） 选择2-3个你熟悉的类似业务的在线服务系统（或移动 APP），如定旅馆（携程、去哪儿等）、定电影票、背单词APP等，分别绘制它们用例图。并满足以下要求：请使用用户的视角，描述用户目标或系统提供的服务粒度达到子用例级别，并用 include 和 exclude 关联它们请用色彩标注出你认为创新（区别于竞争对手的）用例或子用例尽可能识别外部系统和服务 为什么相似系统的用例图是相似的？因为相似的系统要实现的功能是相似的，业务逻辑相似，很多场景也一致，只是针对的对象不同。 如果是定旅馆业务，请对比 Asg_RH 用例图，简述如何利用不同时代、不同地区产品的用例图，展现、突出创新业务和技术.可以利用大数据分析，根据用户喜好，用户来自哪里，为用户推荐适合用户风格的酒店。 如何利用用例图定位创新思路（业务创新、或技术创新、或商业模式创新）在系统中的作用用色彩标注出创新的用例或子用例，从而突出创新思路。 请使用 SCRUM 方法，选择一个用例图，编制某定旅馆开发的需求（backlog）开发计划表 Id Name Imp Est How to demo Notes 1 查找旅馆 25 3 可按地点、日期查找旅馆 调用地图API进行定位 2 下订单 20 2 选择好旅馆、房间类型和日期等信息后确认提交订单 3 支付订单 25 2 选择支付方式进行付款，可使用银行卡支付、微信支付、支付宝支付 需要调用外部系统的支付API 4 登录 20 1 人脸识别 需要调用相关接口 根据任务4，参考 使用用例点估算软件成本，给出项目用例点的估算 用例 # 业务 # 计算 原因 UC 权重 查找旅馆 4 3 简单 下订单 5 5 平均 支付订单 5 3 简单 登录 1 1 简单","categories":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/categories/系统分析与设计/"}],"tags":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/tags/系统分析与设计/"}]},{"title":"系统分析与设计-HW3","slug":"系统分析与设计-HW3","date":"2019-04-18T11:49:36.000Z","updated":"2025-02-24T12:08:16.434Z","comments":true,"path":"2019/04/18/系统分析与设计-HW3/","link":"","permalink":"https://linqy71.github.io/2019/04/18/系统分析与设计-HW3/","excerpt":"","text":"HW3简述瀑布模型、增量模型、螺旋模型（含原型方法），并分析优缺点瀑布模型简介瀑布模型（Waterfall Model）是一个项目开发架构，开发过程是通过设计一系列阶段顺序展开的，从系统需求分析开始直到产品发布和维护，每个阶段都会产生循环反馈，它将软件生命周期划分为制定计划、需求分析、软件设计、程序编写、软件测试和运行维护等六个基本活动，并且规定了它们自上而下、相互衔接的固定次序，如果有信息未被覆盖或者发现了问题，那么最好 “返回”上一个阶段并进行适当的修改，项目开发进程从一个阶段“流动”到下一个阶段，这也是瀑布模型名称的由来。 优点 降低软件开发的复杂程度，提高软件开发过程的透明性，提高 软件开发过程的可管理性。 推迟软件实现，强调在软件实现前必须进行分析和设计工作。 以项目的阶段评审和文档控制为手段有效地对整个开发过程进 行指导，保证了阶段之间的正确衔接，能够及时发现并纠正开发过程中存在的缺陷，使产品达到预期的质量要求。 缺点 强调过程活动的线性顺序。 缺乏灵活性，尤其无法解决软件需求不明确或不准确的问题。 风险控制能力较弱。 瀑布模型中的软件活动是文档驱动的，当阶段之间规定过多的文档时，会极大地增加系统的工作量。 管理人员如果仅仅以文档的完成情况来评估项目完成进度，往往会产生错误的结论。 增量模型简介增量模型首先对系统最核心或最清晰的需求进行分析、设计、实现、 测试并集成到系统中，再按优先级逐步实现后续需求。 优点 增强客户对系统的信心； 降低系统失败风险； 提高系统可靠性； 提高系统的稳定性和可维护性。 缺点 建立初始模型时，作为增量基础的基本业务服务的确定有一定难度； 增量粒度难以选择。 螺旋模型（含原型方法）简介螺旋模型是风险驱动的迭代过程，强调可选方案和约束条件从而支持软件的重用，有助于将软件质量作为特殊目标融入产品开发之中。螺旋模型结合了瀑布模型和快速原型方法，将瀑布模型的多个阶段转化到多个迭代过程中，以降低项目的风险。 优点 设计上的灵活性,可以在项目的各个阶段进行变更； 以小的分段来构建大型系统,使成本计算变得简单容易； 客户始终参与每个阶段的开发,保证了项目不偏离正确方向以及项目的可控性； 随着项目推进,客户始终掌握项目的最新信息, 能够和管理层有效地交互。 缺点 采用螺旋模型需要具有相当丰富的风险评估经验和专门知识，在风险较大的项目开发中，如果未能够及时标识风险，势必造成重大损失； 过多的迭代次数会增加开发成本，延迟提交时间。 简述统一过程三大特点，与面向对象的方法有什么关系统一过程的三大特点 统一过程是用例驱动的 所有的用户和用例组合在一起就是用例模型，它描述了系统的全部功能。用例图促使我们从系统对用户的价值方面来考虑问题，是站在用户的角度出发，以人为本。并且用例图不仅能确定用户的需求，还可以驱动系统设计、实现和测试的进行，也就是说用例可以驱动开发过程。用例驱动表明开发过程是沿着一个流——一系列从用例得到的工作流前进的：用例被确定、用例被设计、最后用例又称为测试人员构造测试用例的基础。 统一过程是以架构为中心的 尽管敏捷方法认为系统设计应该随着软件开发不断演化，但是，系统的架构设计应该在系统开始编码之前给予充分的斟酌。因为架构关心的不仅是功能性需求，更多关心的是非功能性需求，如系统的性能等。一个没有经过深思熟虑的架构往往会在开发后期或系统移交之后暴露出很多性能上的问题，那时再进行重构的代价是非常大的。 风险驱动 UP的另一个驱动就是风险，因为如果你不主动预测和防范风险，风险就会主动攻击你。UP需要对软件开发中的风险进行分析、预测并关注软件的构造。 与面向对象方法的关系 统一软件开发过程是基于面向对象方法和UML统一建模语言的 简述统一过程四个阶段的划分准则是什么？每个阶段关键的里程碑是什么？ 每个阶段根据其工作和迭代在时间上被划分。 初始阶段：为系统建立业务案例(Business Case) 并确定项目的边界。业务案例包括项目的验收规范、风险评估、所需资源 估计、阶段计划等。确定项目边界需要识别所有与系统交互的外部实体，并在较高层次上定义外部实体与系统交互的特性，主要包括识别外部角色(Actor)、识别所有用例并详细描述一些重要的用例。 精化阶段：分析问题领域，建立健全的体系结构基础，编制项目计划，完成项目中高风险需求部分的开发。 构造阶段：完成所有剩余的技术构件和稳定业务需求功能的开发，并集成为产品，详细测试所有功能。构建阶段只是一个制造过程，其重点放在管理资源及控制开发过程以优化成本、进度和质量。 移交阶段：确保软件对最终用户是可用的。产品化阶段可以跨越几次迭代，包括为发布做准备的产品测试，基于用户反馈的少量调整。 划分每个阶段和对应的主要里程碑如下： 阶段 里程碑 初始阶段 生命周期目标 精化阶段 生命周期体系结构 构造阶段 初始运行能力 移交阶段 产品发布 软件企业为什么能按固定节奏生产、固定周期发布软件产品？它给企业项目管理带来哪些好处？ 因为RUP利用软件产品范围的弹性，合理规划范围（20%业务决定80%满意度），使得软件生产按固定节奏运行，固定迭代周期、固定开发周期、固定升级周期。 好处： 明确了不同阶段迭代的里程碑与目标 支持 CI/CD 的版本交付 为固定项目周期提供了可能 每个迭代产品在增量（制品是可运行的），利于及时交付使用并反馈 固定的迭代周期（等量的人月），利于量化团队/个人生产率","categories":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/categories/系统分析与设计/"}],"tags":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/tags/系统分析与设计/"}]},{"title":"系统分析与设计-HW2","slug":"系统分析与设计-HW2","date":"2019-04-18T09:48:07.000Z","updated":"2025-02-24T12:08:16.433Z","comments":true,"path":"2019/04/18/系统分析与设计-HW2/","link":"","permalink":"https://linqy71.github.io/2019/04/18/系统分析与设计-HW2/","excerpt":"","text":"HW2简答用简短的语言给出对分析、设计的理解。 分析：强调对问题和需求的调查而不是解决方法，例如如果需要一个新的线上交易系统，如何使用它？它的功能是什么？ 设计：强调满足需求的概念解决方案（在软件和硬件中），而不是它的实现。例如，数据库模式和软件对象的描述。 用一句话描述面向对象的分析与设计的优势。 能够加强对问题领域和系统责任的理解，对需求的变化由较强的适应性，分析者不需要精通某种程序设计语言，通过共同的标记方法就可以让问题领域的专家与实现领域的专家进行沟通。 简述 UML（统一建模语言）的作用。考试考哪些图？ 统一建模语言(Unified Modeling Language , UML) 是一种绘制软件蓝图的标准语言，可以用UML对软件密集的制品进行可视化、详述、构造和文档化 1、可视化：清晰的模型有利于交流 2、详述：可以使用uml对分析、设计、实现等决策进行详细描述 3、构造：把uml描述映射成编程语言 4、文档化：系统的所有细节都可以是uml进行描述。如：项目计划、发布活动等 用例图、类图、对象图、包图、交互图、状态图、活动图、部署图 从软件本质的角度，解释软件范围（需求）控制的可行性由于软件本身的复杂性、不可见性、一致性、可变性，软件范围多数情况下对于客户和开发者都是模糊的，这形成软件产品与其他产品不同的开发过程。因此，范围管理是软件项目管理的重中之重。在多数情况下，客户与开发者能就项目的 20% 内容给出严格的需求约定，80% 的内容都是相对模糊的。因此，围绕客户目标，发现并满足客户感兴趣的内容是最关键的。砍去一些客户都没思考清晰的业务，永远是对的。 实践看板使用练习： UML绘图工具练习： 取《UML和模式应用(原书第3版)》P211， 图16-17，原图为： 用UMLet画的图为：","categories":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/categories/系统分析与设计/"}],"tags":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/tags/系统分析与设计/"}]},{"title":"阅读笔记 ：jerryscript-internals","slug":"notes-about-jerryscript-internals","date":"2019-03-31T06:41:32.000Z","updated":"2025-02-24T12:08:16.429Z","comments":true,"path":"2019/03/31/notes-about-jerryscript-internals/","link":"","permalink":"https://linqy71.github.io/2019/03/31/notes-about-jerryscript-internals/","excerpt":"","text":"阅读了jerryscript的internals文档，过程中做了一些笔记。主要记录的是ECMA部分。 virtual machineVM 是逐句执行byte-code指令的js翻译器。翻译开始的函数是vm_run。vm_loop是VM中非递归的主循环。也就是说在函数调用时它不会调用它自己进行递归但是有返回值，因此不会给栈带来负担。 ECMA数据表示 data representation 最低2bit表示了数据类型type（simple,number,string,object） simple是预定义的常数，包括：undefined,null,true,false,empty(uninitialized value)compressed pointers16bits，排列成8byte（可以表示512Kb的内存，即Jerryscript的堆大小），可以扩展成32bits来表示更大的内存numberIEEE 754标准。默认8 byte（double），也可以是4 byte（单精度）。通过CONFIG_ECMA_NUMBER_TYPE指定。string不仅仅是字符序列，也能表示numbers和magic id。read only memory中有一个表格用来存储常见的字符序列，保存的形式是（magic id，character sequence）对。对于表格中存在的字符序列，它对应的magic id也会被记录在表格中。这种机制可以加速property access，节省内存。object/lexical environment一个object可以是传统的数据对象，也可以是lexical environment对象。对象可以引用其他数据类型，并且可能存在循环引用，因此引用计数的机制不足以决定dead object。对于所有现存的对象有一个chain list，能够在垃圾回收的时候找到未被引用的对象。一个对象的gc-next指针就是指向它在chain list中的下一个对象。lexical environment在jerry script中也当成对象（object）实现的，因为它包含像object一样的键值对（called binding）。这样可以简化实现并且减少代码量。 property of objects对象中有一个包含了他们的性质的链表。这个链表实际上包含的是property pairs，为了节省内存：7bit的property + 2 bit 的type = 9bit，需要占用2 byte的空间。因此，将2个property与1个type放在一起就是 7bit + 7 bit + 2bit = 16bit, 同样也是2 byte的空间，提高了利用率。 property hashmap：如果property对的数量超过一个限制（16对），property hashmap就被插入到pair list的头部，这样就可以通过这个hashmap来找到property，而不是通过线性便利链表来查找。 hashmap可以包含2^n个元素，查过了一个对象的property的个数，每个元素可以有3种类型的值：null,deleted,reference to the existing property 对于对象包含的每个property，用hashmap查找一定可以找到。 internal property：内部性质是一种特殊的性质，它携带了无法通过访问js代码获得的但是对于引擎本身来说很重要的信息。例如： Class：class type Code：指向函数的字节码的存放位置的指针 native code：指向本地函数代码存放位置的指针 PrimitiveValue for booean：存放boolean对象的值 PrimitiveValue for number：存放number对象的值 Lcache：用来根据对象以及性质名寻找性质的hashmap。 一个对象的所有性质并不一定都能在Lcache中找到，若找不到，则在property-list中寻找，找到后会被放入Lcache中。 Collections：array-like，save memory。collection是一个以array为元素的链表。 Exception Handling：为了实现异常处理，JerryScript函数的返回值可以指出它们的错误或者异常的操作。这些返回值实际上是ECMA的一些值，当错误出现时error bit会被置位。 Value Management and Ownership：每个被引擎存储的ECMA值都会与一个虚拟的“ownership”相关联，ownership定义了ECMA值何时被释放或者何时传递给另一个函数。 一开始，一个value由它的owner创建，owner有释放这个value的责任，当这个value作为一个参数被传递到另一个函数时，它的ownership不会跟着传递，那个函数必须创建一个value的拷贝。然而，当一个value作为返回值被传递的时候，它的ownership也会跟着传递，因此调用函数的caller必须负责释放它。","categories":[{"name":"源码阅读","slug":"源码阅读","permalink":"https://linqy71.github.io/categories/源码阅读/"}],"tags":[{"name":"jerryscript","slug":"jerryscript","permalink":"https://linqy71.github.io/tags/jerryscript/"}]},{"title":"论文阅读笔记 ：Energy Transparency for Deeply Embedded Programs","slug":"notes-about-Energy-Transparency-for-Deeply-Embedded-Programs","date":"2019-03-31T06:29:35.000Z","updated":"2025-02-24T12:08:16.425Z","comments":true,"path":"2019/03/31/notes-about-Energy-Transparency-for-Deeply-Embedded-Programs/","link":"","permalink":"https://linqy71.github.io/2019/03/31/notes-about-Energy-Transparency-for-Deeply-Embedded-Programs/","excerpt":"","text":"阅读了KyriakosGeorgiou等人的Energy Transparency for Deeply Embedded Programs，过程中作了一些笔记。 Abstract 开发软件层面的能耗估计来代替硬件层面的能耗估计。 预估处于ISA层之上，LLVM 优化器之下，即LLVM IR层的能耗 使得对于LLVM优化器来说，能耗是可见的，从而可以做出一些减少能耗的调整 Instruction 系统栈的抽象层使得程序员很难理解代码和数据结构如何影响程序执行时的能耗 使用电池的嵌入式设备需要经常更换电池，超低能量的内嵌设备（ultralow energy embedded devices）：unreliable；not enough energy for many IoT applications. 需要：让程序员了解潜在的硬件层面的energy saving. 提出：呈现用于一些嵌入式系统的软件的实际能耗以及能耗的界限，以便于提出一些节约能耗的方案。 物理测量（physical measurement）：not easily accessable; 能量监测计数器(energy-monitoring counters): number and acailability limited; 总之，简单的物理层面的能耗检测存在各种不足。 WCET 最坏情况执行时间；→ 方法： IPET(implicit path enumerate technique): 隐式路径枚举技术；&amp; an energy model 估计最坏情况能耗。 Xcore：adopt IPET in SRA（静态资源分析） Xcore：时间确定性指令执行的多线程深度嵌入式处理器。 simplier；performance ↑，consumption ↓。 可扩展成多核系统。 novel mapping technique：energy model in ISA-level → LLVM IR level（从指令集层面到LLVM 中间代表层）。 LLVM IR 层：更多程序信息，如 类型 和 循环结构。 适用于任何使用LLVM 优化器的编译器。 比基于指令集模拟的估计（ISS-based estimations）更好。根据算法的复杂度以及最终程序的大小，表现出与ISS-based estimation 相同甚至更好的性能。 适用于迭代优化。 Xcore 体系结构以及能量模型Xcore体系结构 Xcore：可使得硬件接口在软件层面实现的深度嵌入式处理器。 Xcore：提供线程间的交流以及ISA层面的I/O端口控制 适合IoT应用：时间确定性执行、最快响应。 整数，没有浮点数。无需：流水线阶段的转发、推测性指令问题、分支预测 线程：轮询调度算法。需要4个以上的线程在线（active） Xcore：多核可扩展。同核或异核的线程间的交流：基于同步信道的消息传递。 Xcore 多线程指令集体系架构能量模型 在ISA层面捕捉；指令序列能耗；模型主要捕捉：硬件协调一系列的仿形测试和测量过程中产生的线程调度花费； 公式：总的E = 每个指令的能耗+空闲时能耗 E = （静态能量 + 动态等待能量）* 动态等待时间 + 求和（每个指令能耗） 每个指令能耗 = （静态能量+某些特定指令额外的动态能量 扩展因子 指令交错平均开销）/ 活跃线程数 * 4个时钟周期 大于4个活跃线程，每个线程的指令发射率↓ 一个线程的指令发射延迟=max(Nt, 4)*Tclk 这些计时规则被用于 基于模拟的能量估计，SRA，以及本文提到的profiling 这些计时规则可能无效：指令数量有限 关心：完全可预测的指令将能量模型用于能耗估计 need：提取每个线程的控制流图（CFG）以及识别线程间的交替 → 获得Np(进程数) &amp; Tidl(等待时间) 对于SRA，将IPET用于CFG可以提取出划分程序能耗界限的路径（4.1详细描述） 对任意多线程程序使用静态分析去估计能耗很难→使用2种并发模式：任务场、流水线 任务场、流水线：使用的线程数=整个程序的活跃线程数(常数) 影响能耗：FNOP。不定时发生。使用指令缓存模型来确定发生FNOPs的位置（Georgiou中详细描述） 将ISA代码映射到LLVM IR 以及LLVM IR的能量特征 LLVM mapping technique：关注编译器行为、CFG结构。可转移、目标不可知。mapping的格式说明 一堆公式。 LLVM IR上的一条指令可以对应多条ISA指令，IR上一条指令的能耗=对应的所有ISA指令的能耗的和。Xcore映射实例化和协调 3个阶段： LLVM IR 标注： 编译过程产生一些symbol协助debug，这些符号传播到中间代码层和ISA代码层。XMOS编译器的前端产生这些符号。转换成LLVM metadata 然后于附在LLVM IR上。 LLVM IR代码由编译器的后端转化成ISA代码，此时debug信息以DWARF标准格式存储在LLVM IR代码中。此时：源代码→n条LLVM IR指令，源代码→m条ISA指令。 转换过程4条原则：消除→消除；转换→转移；合并→取first one；一条变多条→新指令采用它们原本的location。 2种例外：无法对应&amp;多变多。解决方法：取adjacent ISA 指令的debug lacation。 映射和能量特征：1 LLVM IR → 多 ISA；1 ISA → 1 LLVM IR；有些LLVM IR指令会消失，但是因为1 ISA → 1 LLVM IR，所以不影响energy计算。 协调以及基本块（BB）能量特征 协调：LLVM IR层的SRA预测与ISA层存在误差 LLVM IR 层无法表示FNOP，与ISA拒绝指令一样，放在同个BB的下个ISA指令位。 协调方法：phi-nodes 缺陷： case1 ：LLVM IR 的 BB1边缘的指令映射到了ISA层不同的BB case2 ：ISA层BB的突然出现或消失导致CFG结构的不同 总结：ISA层比LLVM IR层更靠近硬件，它的能耗是可以预测的，通过从ISA到LLVM IR的映射，可以求得LLVM IR层的能耗 能耗预估方法静态资源分析（SRA） low-level analysis: 从SRA层到LLVM IR层的映射，Xcore处理器行为 控制流分析 computationprofiling-based 能耗预估 计算能耗的准确值而不是bounds profiling阶段（记录BB执行轨迹） 给每个BB一个单独的ID 收集BB执行轨迹 将execution counts与每个BB关联起来 energy estimation阶段 根据每个BB的能耗特征 BB 执行计数（execution counts） 计算出程序的能耗 多线程程序的分析 平行多线程 静态。 WCET ← IPET 同步，流水线 无需计算活跃线程数，只需记录BB执行计数 实验评估 SRA结果 基于profiling的分析结果 结论 能耗界限评估（bounds）：IPET-based SRA（适用于单线程） 准确值评估：无目标的profiling technique 基于SRA的分析，以及WECT分析，适用于predictable architecture","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://linqy71.github.io/categories/论文阅读/"}],"tags":[{"name":"IoT energy LLVM-IR","slug":"IoT-energy-LLVM-IR","permalink":"https://linqy71.github.io/tags/IoT-energy-LLVM-IR/"}]},{"title":"系统分析与设计-HW1","slug":"系统分析与设计-HW1","date":"2019-03-14T13:38:28.000Z","updated":"2025-02-24T12:08:16.433Z","comments":true,"path":"2019/03/14/系统分析与设计-HW1/","link":"","permalink":"https://linqy71.github.io/2019/03/14/系统分析与设计-HW1/","excerpt":"","text":"软件工程的定义 Software engineering is “(1) the application of a systematic, disciplined, quantifiable approach to the development, operation, and maintenance of software, that is, the application of engineering to software,” and “(2) the study of approaches as in (1).” –– IEEE Standard 610.12 软件工程是：(1)将系统的、有条理的、可量化的方法应用于软件的开发、操作和维护，即工程在软件上的应用(2) 对(1)中所提到的方法的研究。 解释导致 software crisis 本质原因、表现，述说克服软件危机的方法软件危机本质原因 The software crisis was due to the rapid increases in computer power and the complexity of the problems that could not be tackled. With the increase in the complexity of the software, many software problems arose because existing methods were insufficient. – Wikipedia 软件危机是由于计算机能力的迅速增长和无法解决的问题的复杂性造成的。随着软件复杂度的增加，由于现有方法的不足，出现了很多软件问题。 软件危机的表现 Projects running over-budgetProjects running over-timeSoftware was very inefficientSoftware was of low qualitySoftware often did not meet requirementsProjects were unmanageable and code difficult to maintainSoftware was never delivered 项目运行超预算 项目运行时间过长 软件效率很低 软件质量很差 软件通常不符合要求 项目难以管理，代码难以维护 软件从未交付过 克服软件危机的方法 Various processes and methodologies have been developed over the last few decades to improve software quality management such as procedural programming and object-oriented programming. However software projects that are large, complicated, poorly specified, and involve unfamiliar aspects, are still vulnerable to large, unanticipated problems. 计算能力按摩尔定律发展，软件处理的问题也越来越广、越来约复杂，因此软件生产不只是编程技术问题，需要有系统化、与时俱进的软件工程方法，才能规避 software crisis ！ 软件危机的产生是因为计算机能力的提高超过了程序员利用这些能力的能力。在过去的几十年中，已经出现了各种过程和方法来改进软件质量管理，例如过程编程和面向对象的编程。然而，大型，复杂，指定不当以及涉及不熟悉方面的软件项目仍然容易受到大的，未预料到的问题的影响。 软件生命周期 软件生命周期一般包括可行性分析与计划、需求分析、设计(概要 设计和详细设计)、编码实现、测试、运行与维护等活动。这些活动应当以适当的方式分配到不同的阶段去完成 软件生命周期（Life Cycle）：在时间维度，对软件项目任务进行划分，又成为软件开发过程。常见有瀑布模型、螺旋模型、敏捷的模型等。 瀑布模型 SWEBoK 的 15 个知识域 Knowledge Areas Characterizing the Practice of Software Engineering（表征软件工程实践的知识领域） 软件需求 Software Requirements软件要求知识域关注软件需求的启发，协商，分析，规范和验证。软件需求表达了对软件产品的需求和限制，这些需求和约束有助于解决一些现实问题。 软件设计 Software Design设计被定义为定义体系结构、组件、接口和系统或组件的其他特性以及该过程的结果的过程（IEEE 1991）。软件设计知识域涵盖了设计过程和最终产品。 软件构建 Software Construction软件构建是指通过结合详细设计，编码，单元测试，集成测试，调试和验证来详细创建工作软件。软件构建知识域包括与满足其要求和设计约束的软件程序开发相关的主题。 软件测试 Software Testing测试是一项旨在评估产品质量并通过识别缺陷来改进产品质量的活动。软件测试涉及在有限的测试用例集上针对预期行为动态验证程序的行为。这些测试用例是从（通常非常大的）执行域中选择的。 软件维护 Software Maintenance软件维护包括增强现有功能，调整软件以在新的和修改的操作环境中运行，以及纠正缺陷。这些类别称为完善，自适应和纠正性软件维护。 软件配置管理 Software Configuration Management软件配置管理（SCM）是在不同时间点识别系统配置的规则，用于系统地控制配置的改变，以及在整个软件生命周期中维持配置的完整性和可追溯性。 软件工程管理 Software Engineering Management软件工程管理涉及规划，协调，测量，报告和控制项目或程序，以确保软件的开发和维护是系统化的，规范化的和量化的。 软件工程过程 Software Engineering Process软件工程知识域关注软件生命周期过程的定义，实施，评估，测量，管理和改进。 软件工程模型和方法 Software Engineering Models and Methods软件工程模型和方法知识域解决了涵盖多个生命周期阶段的方法; 其他知识域涵盖特定生命周期阶段的特定方法。 软件质量 Software Quality软件质量是许多SWEBOK V3 KAs中普遍存在的软件生命周期问题。 软件工程专业实践 Software Engineering Professional Practice软件工程专业实践关注软件工程师必须具备的专业，负责和道德的软件工程知识，技能和态度。 Knowledge Areas Characterizing the Educational Requirements of Software Engineering(表征软件工程教育要求的知识领域) 软件工程经济学 Software Engineering Economics软件工程经济学知识域关注的是在业务环境中做出决策，以使技术决策与组织的业务目标保持一致。 计算基础 Computing Foundations计算基础知识域涵盖了提供软件工程实践所需的计算背景的基础主题。 数学基础 Mathematical Foundations数学基础知识域涵盖了提供软件工程实践所必需的数学背景的基础主题。 工程基础 Engineering Foundations工程基础知识域涵盖了提供软件工程实践所必需的工程背景的基础主题。 简单解释 CMMI 的五个级别 Level 1 - Initial：无序，自发生产模式。 Level 2 - Managed: 管理制度化，建立了基本的管理制度和规程，管理工作有章可循. Level 3 - Defined: 开发过程，包括技术工作和管理工作，均已实现标准化、文档化。 Level 4 - Quantitatively Managed: 产品和过程已建立了定量的质量目标。可预测过程和产品质量趋势。 Level 5 - Optimizing：可集中精力改进过程，采用新技术、新方法。 用自己语言简述 SWEBok 或 CMMI软件能力成熟度模型集成（CMMI）是一个过程级别的改进培训和评估计划。其目的是帮助软件企业对软件工程过程进行管理和改进，增强开发与改进能力，从而能按时地、不超预算地开发出高质量的软件。其所依据的想法是：只要集中精力持续努力去建立有效的软件工程过程的基础结构，不断进行管理的实践和过程的改进，就可以克服软件开发中的困难。CMMI为改进一个组织的各种过程提供了一个单一的集成化框架，新的集成模型框架消除了各个模型的不一致性，减少了模型间的重复，增加透明度和理解，建立了一个自动的、可扩展的框架。因而能够从总体上改进组织的质量和效率。CMMI主要关注点就是成本效益、明确重点、过程集中和灵活性四个方面。 参考 https://en.wikipedia.org/wiki/Software_crisis https://en.wikipedia.org/wiki/Capability_Maturity_Model_Integration https://www.sebokwiki.org/wiki/An_Overview_of_the_SWEBOK_Guide https://baike.baidu.com/item/CMMI","categories":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/categories/系统分析与设计/"}],"tags":[{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/tags/系统分析与设计/"}]},{"title":"nodejs + express + mysql搭建restful风格api","slug":"express+mysql","date":"2019-01-17T18:03:23.000Z","updated":"2025-02-24T12:08:16.424Z","comments":true,"path":"2019/01/18/express+mysql/","link":"","permalink":"https://linqy71.github.io/2019/01/18/express+mysql/","excerpt":"","text":"开发前准备 安装node和express 命令行输入express + 项目名初始化项目&gt; express server 进入server文件夹安装依赖&gt; npm install 由于要使用mysql，因此，在package.json中的&quot;dependencies&quot;下添加&quot;mysql&quot;: &quot;latest&quot;，重新执行npm install 服务器上安装mysql 安装mysqlCentOS的yum源中没有mysql。没法直接 yum -y install 正确方法：参考CentOS7 64位安装mysql教程，亲测完美，包括一些初始配置也在里面。（里面还有开放root供远程连接的方法，保存备用。） 数据库相关 项目下新建database文件夹，新建DBConfig.js，写入： 123456789module.exports = &#123; mysql : &#123; host : &apos;127.0.0.1&apos;, user : &apos;root&apos;, password : yourPSW, database : yourDB, port : 3306 &#125;&#125; 创建数据库和表 创建数据库：启动mysql后输入 create database kuailing 创建表：采用导入.sql文件的形式。 封装一些数据库操作语句。（我将封装块放在了userDAO中） 123456789var userSqlMap = &#123; add: &apos;insert into user(studentid, name, realname, address, password, phone)&apos; + &apos; values(?, ?, ?, ?, ?, ?)&apos;, deleteById: &apos;delete from user where studentid = ?&apos;, update: &apos;update user set name=?, realname=?, address=?, password=?&apos; + &apos;, phone=? where studentid=?&apos;, list: &apos;select * from user&apos;, getById: &apos;select * from user where studentid=?&apos;&#125;; 封装返回结果对象。（非必要，因为想要实现api接口无需体现状态） 在model文件夹下新建result.js，返回操作结果success以及需要的数据。 123456exports.createResult = function(success, data) &#123; var result = &#123;&#125;; result.success = success; result.data = data; return result;&#125;; 封装和数据库的交互模块。新建DAO文件夹，新建userDAO.js，使用连接池防止频繁获取、释放数据库连接。写入的部分代码如下: 123456789101112131415161718192021//建立连接池var pool = mysql.createPool(DBConfig.mysql);module.exports = &#123; getById: function (studentid, callback) &#123; pool.query(userSqlMap.getById, studentid, function (err, result) &#123; if (err) throw err; console.log(result[0]); callback(result[0]); &#125;); &#125;, //添加新用户 add: function (user, callback) &#123; user = JSON.parse(user); pool.query(userSqlMap.add, [user.studentid, user.name, user.realname, user.address, user.password, user.phone], function (err, result) &#123; if (err) throw err; console.log(&apos;result :&apos; + result); callback(result.affectedRows &gt; 0); &#125;); &#125;&#125;; 业务逻辑 用户操作路由及实现业务逻辑routes/users.js: GET 12345678//解析 /users?studentid=xxxx的urlrouter.get(&apos;&apos;, function(req, res) &#123; console.log(req.query); userDAO.getById(req.query.studentid, function (user) &#123; console.log(user); res.json(user); &#125;);&#125;); POST 123456789//提交用户信息用于添加新用户router.post(&apos;/&apos;, function(req, res) &#123; var user = JSON.stringify(req.body); userDAO.add(user, function(success) &#123; var result = &#123;&#125;; result.success = success; res.json(result); &#125;);&#125;); /users/xxxx的url,获取查询参数的方式是req.params 123456789//解析 /users/xxxx的url，其中xxxx为学号,//可以采用以下方式，获取查询参数的方式是req.params。router.get(&apos;/:studentid&apos;, function (req, res) &#123; console.log(&apos;patch users called&apos;); userDAO.getById(req.params.studentid, function (user) &#123; console.log(user); res.json(user); &#125;);&#125;); 遇到的问题 启动mysql(mysql -u root -p)后使用数据库mysql(use mysql)输入show variables like &quot;%char%&quot;;想要确定是否为utf8，出现报错：ERROR 1146 (42S02): Table ‘performance_schema.session_variables’ doesn’t exis。 解决方法： 输入：mysql_upgrade -u root -p --force并重启服务。 效果： 由于以前用的都是mysql workbench，不熟悉命令行操作mysql，因此，命令行操作参考：https://www.cnblogs.com/kpengfang/p/5201285.html 关于采用post实现新增用户一直返回失败的问题。 解决方法： 获取用户信息是通过var user = JSON.stringify(req.body);，然后将这个user传递到userDAO的add方法中，user.name却变成undefine，在add方法中添加user = JSON.parse(user);将参数转化为JSON对象就解决啦。 总结以上，就完成了基本GET和POST方式的api。其余更多需要的处理在于对数据库的设计和操作，依据项目要求而进行调整。 后来查看文档发现还是有很多地方不符合规范，需要进一步的改进，参考restful api设计指南 参考https://www.cnblogs.com/thinkam/p/8299452.html","categories":[{"name":"coding","slug":"coding","permalink":"https://linqy71.github.io/categories/coding/"}],"tags":[{"name":"express nodejs mysql webapi","slug":"express-nodejs-mysql-webapi","permalink":"https://linqy71.github.io/tags/express-nodejs-mysql-webapi/"}]},{"title":"Mylist","slug":"Mylist","date":"2018-03-29T03:26:23.000Z","updated":"2025-02-24T12:08:16.417Z","comments":true,"path":"2018/03/29/Mylist/","link":"","permalink":"https://linqy71.github.io/2018/03/29/Mylist/","excerpt":"","text":"学习了现代操作系统课程，完成了Mylist应用的开发，趁有时间将实现过程总结一下。 MyList （上）Week1实验要求： 在MainPage上放置CheckBox和line两个控件，当CheckBox被勾选时line出现，取消勾选则line消失。 新建一个NewPage 点击create按钮时，检查Title、Description是否为空，DueDate是否正确（是否大于等于当前日期）。如果不正确，弹出对话框，显示错误信息。 点击Cancel按钮时，Title、Description置空，DueDate置为当前日期。 实验步骤： 在Mainpage.xaml里面添加CheckBox和Line控件，将Line的Visibility与CheckBox绑定即可： 1Visibility=&quot;&#123;Binding ElementName=Box1, Path=IsChecked&#125;&quot; 新建一个Newpage.xaml，放置一些TextBlock和TextBox控件以显示 Title，Description及其输入框，放置一个DatePicker作为DueDate的选择。自己调整布局。 在Newpage.xaml中放置两个Button空间，一个Create一个Cancle，在Newpage.xaml.cs中实现对应的Click事件： 1234567891011121314151617181920212223private void CreateTask(object sender, RoutedEventArgs e) &#123; WrongMessage = &quot;&quot;; if (Title.Text == &quot;&quot;) &#123; WrongMessage += &quot;Title can&apos;t be empty! \\n&quot;; &#125; if (Description.Text == &quot;&quot;) &#123; WrongMessage += &quot;Description can&apos;t be empty!\\n&quot;; &#125; if (dp.Date &lt; DateTime.Now.Date) &#123; WrongMessage += &quot;The due date has passed!&quot;; &#125; &#125;private void reset(object sender, RoutedEventArgs e) &#123; Title.Text = &quot;&quot;; Description.Text = &quot;&quot;; dp.Date = DateTime.Now.Date; &#125; 效果图： CheckBox与Line的绑定： 创建失败信息提示： Week2实验要求： 完成Mainpage、Newpage两个界面之间的Navigation： 点击Mainpage底部的“＋”按钮，跳转到Newpage 点击Newpage顶部的“←”按钮，跳转回Mainpage 界面优化： 界面宽度发生改变时，界面整体始终居中； 界面右侧需有滚动条。 为界面添加背景。 实验步骤： 在MainPage底部添加AppBarButton，Icon为Add，在在Newpage.xaml.cs中实现对应的Click事件： 123456&lt;Page.BottomAppBar&gt; &lt;CommandBar&gt; &lt;AppBarButton x:Name=&quot;ABB&quot; Icon=&quot;Add&quot; Label=&quot;Add&quot; Click=&quot;AddAppBarButton_Click&quot; /&gt; &lt;AppBarButton x:Name=&quot;DeleteAppBarButton&quot; Icon=&quot;Delete&quot; Label=&quot;Delete&quot; Click=&quot;DeleteButton_Clicked&quot; Visibility=&quot;Collapsed&quot;/&gt; &lt;/CommandBar&gt;&lt;/Page.BottomAppBar&gt; 1234567891011121314private void AddAppBarButton_Click(object sender, RoutedEventArgs e) &#123; if(second.Visibility == Visibility.Visible) //若主页面第二部分可见，则跳转到主页面 &#123; create.Content = &quot;Create&quot;; ViewModel.SelectedItem = null; Frame.Navigate(typeof(MainPage)); //此处为跳转到主页面，详情部分会变成空白以待输入 return; &#125; ViewModel.SelectedItem = null; Frame.Navigate(typeof(NewPage)); //否则跳转到NewPage &#125; 判断页面是否显示返回键，若显示，则点击返回键可返回主页面。 关于界面优化： 界面整体居中：Grid HorizontalAlignment=&quot;Center&quot; 右侧添加滚动条：&lt;ScrollViewer ScrollViewer.VerticalScrollBarVisibility=&quot;Auto&quot; &gt; （拥有滚动条的整体） &lt;/ScrollViewer&gt; 为界面添加背景：123&lt;Grid.Background&gt; &lt;ImageBrush ImageSource=&quot;Assets/th.jpg&quot; Stretch=&quot;Fill&quot; Opacity=&quot;0.7&quot;&gt;&lt;/ImageBrush&gt; &lt;/Grid.Background&gt; Week3实验要求： 实现自适应UI： 窗口宽度小于600只显示文字和方框 窗口宽度大于600小于800显示文字图片和方框 窗口宽度大于800显示文字图片方框以及NewPage。 窗口宽度大于800时点击+不会跳转到NewPage。（此部分代码在上面实现跳转功能时已给出） 实现数据绑定：创建MVVM模式，建立Model类和ViewModel类，Model类中保存每一个Item的数据。ViewModel保存所有的Item以及对Item列表进行增删改。 实现图片的上传，运用FileOpenPicker，BitmapImage等类。 实现步骤： 采用VisualStateGroup为MainPage设定3种状态： 12345678910111213141516171819202122232425&lt;VisualStateManager.VisualStateGroups&gt; &lt;VisualStateGroup x:Name=&quot;VisualStateGroup&quot;&gt; &lt;VisualState x:Name=&quot;VisualStateMin0&quot;&gt; &lt;VisualState.StateTriggers&gt; &lt;AdaptiveTrigger MinWindowWidth=&quot;0&quot;/&gt; &lt;/VisualState.StateTriggers&gt; &lt;VisualState.Setters&gt; &lt;Setter Target=&quot;second.(UIElement.Visibility)&quot; Value=&quot;Collapsed&quot;/&gt; &lt;Setter Target=&quot;first.(Grid.ColumnSpan)&quot; Value=&quot;2&quot;/&gt; &lt;/VisualState.Setters&gt; &lt;/VisualState&gt; &lt;VisualState x:Name=&quot;VisualStateMin800&quot;&gt; &lt;VisualState.StateTriggers&gt; &lt;AdaptiveTrigger MinWindowWidth=&quot;800&quot;/&gt; &lt;/VisualState.StateTriggers&gt; &lt;VisualState.Setters&gt; &lt;/VisualState.Setters&gt; &lt;/VisualState&gt; &lt;/VisualStateGroup&gt; &lt;/VisualStateManager.VisualStateGroups&gt; 解释一下上面的代码，首先将整个页面以宽度800为分界线，设置两种状态，以页面宽度为触发条件，大于800时不作改变，大于0小于800时将第二部分隐藏，并将标题左边的图片隐藏。 123456789101112131415161718&lt;VisualStateManager.VisualStateGroups&gt; &lt;VisualStateGroup&gt; &lt;VisualState x:Name=&quot;state2&quot;&gt; &lt;VisualState.StateTriggers&gt; &lt;AdaptiveTrigger MinWindowWidth=&quot;600&quot;/&gt; &lt;/VisualState.StateTriggers&gt; &lt;/VisualState&gt; &lt;VisualState x:Name=&quot;state1&quot;&gt; &lt;VisualState.StateTriggers&gt; &lt;AdaptiveTrigger MinWindowWidth=&quot;1&quot;/&gt; &lt;/VisualState.StateTriggers&gt; &lt;VisualState.Setters&gt; &lt;Setter Target=&quot;image.Visibility&quot; Value=&quot;Collapsed&quot;/&gt; &lt;/VisualState.Setters&gt; &lt;/VisualState&gt; &lt;/VisualStateGroup&gt; &lt;/VisualStateManager.VisualStateGroups&gt; 然后在first部分中（我将MainPage划分为了first–标题部分和second–详情部分）再以宽度600为分界线，设置两种状态，宽度大于600时正常显示first页面，宽度小于600时将标题左边的图片隐藏。 创建一个ListItem类作为Model，放在Model文件夹下，用来保存Todolist中每一项的详细信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243namespace Mylist1.Models&#123; public class ListItem &#123; public string id; public string title &#123; get; set; &#125; public string description &#123; get; set; &#125; public bool completed &#123; get; set; &#125; public DateTime date &#123; get; set; &#125; public ImageSource imageSource &#123; get; set; &#125; public ListItem(string title, string description, DateTime date, ImageSource imageSource) &#123; this.id = Guid.NewGuid().ToString(); this.title = title; this.description = description; this.imageSource = imageSource; this.date = date; this.completed = false; &#125; &#125; &#125; 创建一个ListItemViewModel放在ViewModel文件夹下，用来管理所有Item的信息。 123456789101112131415161718192021222324252627namespace Mylist1.ViewModel&#123; class ListItemViewModels &#123; private static ListItemViewModels instance; public static ListItemViewModels getInstance() &#123; if(instance == null) &#123; instance = new ListItemViewModels(&quot;Assets/EAT.jpg&quot;); &#125; return instance; &#125; private ObservableCollection&lt;Models.ListItem&gt; allItems = new ObservableCollection&lt;Models.ListItem&gt;(); public ObservableCollection&lt;Models.ListItem&gt; AllItems &#123; get &#123; return this.allItems; &#125; &#125; ...... ...... ...... &#125; &#125; 此类为单例模式，类中还包括： 构造函数：初始化集合内容。 AddListItem：新增一项Item。 RemoveListItem：减少一项Item。 UpdateListItem：更新一项Item。 getSearchItemInfo：查询Item。内容太长，详见github。 实现图片的上传。首先在MainPage.xaml 和 NewPage.xaml中添加按钮： 12&lt;AppBarButton x:Name=&quot;SelectPictureButton&quot; Icon=&quot;Pictures&quot; Label =&quot;select&quot; Click=&quot;SelectPicture_Click&quot; Height=&quot;40&quot; Width=&quot;40&quot; RelativePanel.Below=&quot;img&quot;&gt;&lt;/AppBarButton&gt; 然后在对应的.xaml.cs文件中实现Click函数： 12345678910111213141516171819202122public async void SelectPicture_Click(object sender, RoutedEventArgs e) &#123; FileOpenPicker picker = new FileOpenPicker(); picker.ViewMode = PickerViewMode.Thumbnail; picker.SuggestedStartLocation = PickerLocationId.Desktop; picker.FileTypeFilter.Add(&quot;.jpg&quot;); picker.FileTypeFilter.Add(&quot;.png&quot;); picker.FileTypeFilter.Add(&quot;.jpeg&quot;); picker.FileTypeFilter.Add(&quot;.bmp&quot;); picker.FileTypeFilter.Add(&quot;.jif&quot;); StorageFile file = await picker.PickSingleFileAsync(); if (file != null) &#123; IRandomAccessStream stream = await file.OpenAsync(FileAccessMode.Read); BitmapImage bmpimage = new BitmapImage(); bmpimage.SetSource(stream); img.Source = bmpimage; imgPath = file.Path.Substring(file.Path.LastIndexOf(&apos;\\\\&apos;) + 1); &#125; &#125; 效果图： 三种状态： 创建新Item： 点击Item显示详情并且显示Update按钮进入可更新状态: 总结：未完待续。","categories":[{"name":"coding","slug":"coding","permalink":"https://linqy71.github.io/categories/coding/"}],"tags":[{"name":"UWP C# win10","slug":"UWP-C-win10","permalink":"https://linqy71.github.io/tags/UWP-C-win10/"}]}],"categories":[{"name":"coding","slug":"coding","permalink":"https://linqy71.github.io/categories/coding/"},{"name":"论文阅读","slug":"论文阅读","permalink":"https://linqy71.github.io/categories/论文阅读/"},{"name":"文学","slug":"文学","permalink":"https://linqy71.github.io/categories/文学/"},{"name":"源码阅读","slug":"源码阅读","permalink":"https://linqy71.github.io/categories/源码阅读/"},{"name":"面经","slug":"面经","permalink":"https://linqy71.github.io/categories/面经/"},{"name":"项目管理","slug":"项目管理","permalink":"https://linqy71.github.io/categories/项目管理/"},{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/categories/系统分析与设计/"}],"tags":[{"name":"python; rocksdb;","slug":"python-rocksdb","permalink":"https://linqy71.github.io/tags/python-rocksdb/"},{"name":"DLRM, HugeCTR, embedding cache","slug":"DLRM-HugeCTR-embedding-cache","permalink":"https://linqy71.github.io/tags/DLRM-HugeCTR-embedding-cache/"},{"name":"鲁迅 且介亭杂文","slug":"鲁迅-且介亭杂文","permalink":"https://linqy71.github.io/tags/鲁迅-且介亭杂文/"},{"name":"k8s openfaas tf-serving","slug":"k8s-openfaas-tf-serving","permalink":"https://linqy71.github.io/tags/k8s-openfaas-tf-serving/"},{"name":"k8s kubernetes kubeadm gpu","slug":"k8s-kubernetes-kubeadm-gpu","permalink":"https://linqy71.github.io/tags/k8s-kubernetes-kubeadm-gpu/"},{"name":"rocksdb","slug":"rocksdb","permalink":"https://linqy71.github.io/tags/rocksdb/"},{"name":"字节跳动、阿里、腾讯","slug":"字节跳动、阿里、腾讯","permalink":"https://linqy71.github.io/tags/字节跳动、阿里、腾讯/"},{"name":"key-value cache, memcached","slug":"key-value-cache-memcached","permalink":"https://linqy71.github.io/tags/key-value-cache-memcached/"},{"name":"netbeans","slug":"netbeans","permalink":"https://linqy71.github.io/tags/netbeans/"},{"name":"cache, LSM-Tree","slug":"cache-LSM-Tree","permalink":"https://linqy71.github.io/tags/cache-LSM-Tree/"},{"name":"鲁迅 杂文","slug":"鲁迅-杂文","permalink":"https://linqy71.github.io/tags/鲁迅-杂文/"},{"name":"Redis, centos","slug":"Redis-centos","permalink":"https://linqy71.github.io/tags/Redis-centos/"},{"name":"尼采 哲学","slug":"尼采-哲学","permalink":"https://linqy71.github.io/tags/尼采-哲学/"},{"name":"Redis","slug":"Redis","permalink":"https://linqy71.github.io/tags/Redis/"},{"name":"Hbase, Bigtable, 论文","slug":"Hbase-Bigtable-论文","permalink":"https://linqy71.github.io/tags/Hbase-Bigtable-论文/"},{"name":"垃圾回收；功耗优化","slug":"垃圾回收；功耗优化","permalink":"https://linqy71.github.io/tags/垃圾回收；功耗优化/"},{"name":"Edge Computing;","slug":"Edge-Computing","permalink":"https://linqy71.github.io/tags/Edge-Computing/"},{"name":"service placement; Edge;","slug":"service-placement-Edge","permalink":"https://linqy71.github.io/tags/service-placement-Edge/"},{"name":"微信小程序","slug":"微信小程序","permalink":"https://linqy71.github.io/tags/微信小程序/"},{"name":"项目管理","slug":"项目管理","permalink":"https://linqy71.github.io/tags/项目管理/"},{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://linqy71.github.io/tags/系统分析与设计/"},{"name":"jerryscript","slug":"jerryscript","permalink":"https://linqy71.github.io/tags/jerryscript/"},{"name":"IoT energy LLVM-IR","slug":"IoT-energy-LLVM-IR","permalink":"https://linqy71.github.io/tags/IoT-energy-LLVM-IR/"},{"name":"express nodejs mysql webapi","slug":"express-nodejs-mysql-webapi","permalink":"https://linqy71.github.io/tags/express-nodejs-mysql-webapi/"},{"name":"UWP C# win10","slug":"UWP-C-win10","permalink":"https://linqy71.github.io/tags/UWP-C-win10/"}]}